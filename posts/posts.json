[
  {
    "path": "posts/2021-02-07-wonderful-wednesdays-february-2021/",
    "title": "Wonderful Wednesdays February 2021",
    "description": "The DLQI is the most frequently used method for evaluating quality of life for patients with different skin conditions. There are 10 questions, covering the following topics: symptoms, embarrassment, shopping and home care, clothes, social and leisure, sport, work or study, close relationships, sex, treatment. Each question refers to the impact of the skin disease on the patient’s life over the previous week. In the dataset DLQI has been administered in a phase 3 clinical trial to patients with psoriasis. 150 has been randomized to Placebo (Treatment A) and 450 to the active treatment (Treatment B). The treatment effect in terms of Quality of Life is assessed at Week 16 and the Psoriasis Area and Severity Index is collected at baseline. Some DLQI assessment is missing at Week 16.",
    "author": [
      {
        "name": "PSI VIS SIG",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2021-02-10",
    "categories": [
      "DLQI",
      "Wonderful Wednesdays"
    ],
    "contents": "\nDLQI data set\n\n\nExample 1. Heatmaps\nhigh resolution image\n(A summary of the discussion will be added shortly.)\nlink to code\n\nExample 2. Mixed models\n\nThe app can be found here.\n(A summary of the discussion will be added shortly.)\nlink to code\n\nExample 3. Change in mean scores\nhigh resolution image\n(A summary of the discussion will be added shortly.)\nlink to code\n\nExample 4. Histrograms\n\nhigh resolution image\n(A summary of the discussion will be added shortly.)\nlink to code\nCode\n\nExample 1. Heatmaps\n\n\nlibrary(GGally)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(patchwork)\n\nqol <- read.csv(\"Data/2021-01-13-QualityOfLife.csv\")\n\nhead(qol)\nglimpse(qol)\n\nqol2 <- qol %>% \n    mutate_if(function(x){length(unique(x)) < 6}, factor)\n\nggpairs(qol2[qol2$VISIT == \"Week 16\", c(2, 3, 15)], \n    mapping = aes(colour = TRT))\nggpairs(qol[qol$VISIT == \"Week 16\", 5:14])\nggpairs(qol2[qol2$VISIT == \"Week 16\", 5:14])\nggpairs(qol[qol$VISIT == \"Week 16\", 5:14], \n    mapping = aes(colour = qol[qol$VISIT == \"Week 16\",]$TRT))\nggpairs(qol2[qol2$VISIT == \"Week 16\", 5:14], \n    mapping = aes(colour = qol2[qol2$VISIT == \"Week 16\",]$TRT))\n\n\n#### Goal 1: Multidimensional nature of DLQI ####\n# As integers, they're all highly correlated\n# As categorical variables, need an intelligent way to summarise\n# Something like PCA or NMF, but for categories?\n# Collection of stacked bar plots?\n# Percent agreement between categories?\n# Compound Poisson model for discrete categories?\n#### Goal 2: Show the effect of treatment, incorporate multidimensionality ####\n\n\n# Attempt 1: Conditional Distributions\n\ndlq <- select(qol, starts_with(\"DLQI\")) %>% \n    select(-DLQI_SCORE)\nheatmaps <- lapply(0:3, function(w){\n    m1 <- sapply(1:10, function(x){\n        f1 <- filter(dlq, dlq[, x] == w)\n        if(nrow(f1) > 0) {\n            return(apply(f1, 2, function(y) mean(y == w, na.rm = TRUE)))\n        } else {\n            return(rep(NA, 10))\n        }\n    })\n    colnames(m1) <- rownames(m1)\n    m1 <- m1 %>% as.data.frame() %>% \n        tibble::rownames_to_column(var = \"from\") %>% \n        pivot_longer(-from, names_to = \"to\", values_to = \"both_0\")\n    return(m1)\n})\n\n\nnumwords <- c(\"Zero\", \"One\", \"Two\", \"Three\")\nwrap_plots(lapply(1:4, function(i) {\n    zeros <- apply(dlq, 2, function(x) sum(x == i - 1, na.rm = TRUE))\n    ggplot(heatmaps[[i]]) +\n        aes(x = to, y = from, fill = both_0) + \n        geom_tile() +\n        labs(x = paste0(\"...how often is this measure \", i - 1, \"?\"), \n            y = paste0(\"When this measure is \", i - 1, \"...\"),\n            title = paste0(numwords[i], \" Together\"),\n            fill = paste0(\"Both \", numwords[i])) +\n        scale_fill_viridis_c(option = \"C\") + \n        annotate(\"text\", x = 1:10, y = 1:10, label = zeros) +\n        theme(aspect.ratio = 1, \n            axis.text.x = element_text(angle = 90, vjust = 0.5))\n}))\n\n\n\nBack to blog\n\nExample 2. Mixed models\nThe R Markdown file can be found here.\nBack to blog\n\nExample 3. Change in mean scores\n\n\n# Load data\ndql <- read.csv(\"ww2020_dlqi.csv\")\nattach(dql)\nView(dql)\n\n# Load library\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(ggcharts)\nlibrary(ggalt)\n\n# Seperate treatment arms\nnew_A <- \n  dql %>% \n  filter(TRT==\"A\")\nnew_B <- \n  dql %>% \n  filter(TRT==\"B\")\n\n## Treatment A : Placebo\n\ndtA <- new_A %>%\n  # Remove missing data\n  filter(!is.na(new_A)) %>% \n  # Select relevant variables\n  select(\n    DLQI101, DLQI102, DLQI103, DLQI104, DLQI105,\n    DLQI106, DLQI107, DLQI108, DLQI109, DLQI110,\n    VISIT\n    ) %>%\n  # Summarize mean score for each question grouped by visit\n  # while also renaming variables to indicate the meaning of each score\n  group_by(VISIT) %>%\n  summarise(\n    Symptoms = mean(DLQI101, na.rm = T),\n    Embarrassment = mean(DLQI102, na.rm = T),\n   `Shopping and home care` = mean(DLQI103, na.rm = T),\n    Clothes = mean(DLQI104, na.rm = T),\n   `Social and leisure` = mean(DLQI105, na.rm = T),\n    Sport = mean(DLQI106, na.rm = T),\n    `Work and study` = mean(DLQI107, na.rm = T),\n    `Close relationships` = mean(DLQI108, na.rm = T),\n    Sex = mean(DLQI109, na.rm = T),\n    Treatment = mean(DLQI110, na.rm = T)\n   )\n\n# Tidying data\ndtA <- \n  dtA %>% \n  pivot_longer(\n    !VISIT,\n    names_to = \"Domain\",\n    values_to = \"Mean_Score\"\n    )\n\n# Seperating the visit variable into baseline and week 16\ndtA <-\n  dtA %>% \n  pivot_wider(\n    names_from = VISIT,\n    values_from = Mean_Score\n    )\n\n# Ensuring the domain levels are ordered the same\ndtA <-\n  dtA %>% \n  mutate(\n    Domain = factor(Domain,\n                    levels = c(\"Symptoms\", \"Embarrassment\",\n                               \"Shopping and home care\",\n                               \"Clothes\", \"Social and leisure\",\n                               \"Sport\", \"Work and study\",\n                               \"Close relationships\",\n                               \"Sex\", \"Treatment\"))\n    )\n\n# Constructing a dumbbell plot using ggalt package with a ggchart theme\n\n(a <- \n  ggplot()+\n  geom_dumbbell(\n    data = dtA,\n    aes(\n      y = Domain,\n      x = Baseline,\n      xend = `Week 16`\n      ),\n    size = 1.5,\n    color = \"lightgray\",\n    size_x = 3,\n    colour_x = \"violetred4\",\n    size_xend = 3,\n    colour_xend = \"maroon1\"\n    )\n  + theme_ggcharts(grid = \"Y\")\n  + labs(\n    title = \"Placebo\"\n    )\n  + theme(\n    plot.title = element_text(hjust = 0.5),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.text.y = element_text(size = 9)\n    ))\n\n## Treatment B : Active Treatment\n\ndtB <- new_B %>%\n  # Remove missing data\n  filter(!is.na(new_B)) %>% \n  # Select relevant variables\n  select(\n    DLQI101, DLQI102, DLQI103, DLQI104, DLQI105,\n    DLQI106, DLQI107, DLQI108, DLQI109, DLQI110,\n    VISIT\n    ) %>%\n  # Summarize mean score for each question grouped by visit\n  # while also renaming variables to indicate the meaning of each score\n  group_by(VISIT) %>%\n  summarise(\n    Symptoms = mean(DLQI101, na.rm = T),\n    Embarrassment = mean(DLQI102, na.rm = T),\n    `Shopping and home care` = mean(DLQI103, na.rm = T),\n    Clothes = mean(DLQI104, na.rm = T),\n    `Social and leisure` = mean(DLQI105, na.rm = T),\n    Sport = mean(DLQI106, na.rm = T),\n    `Work and study` = mean(DLQI107, na.rm = T),\n    `Close relationships` = mean(DLQI108, na.rm = T),\n    Sex = mean(DLQI109, na.rm = T),\n    Treatment = mean(DLQI110, na.rm = T)\n    )\n\n# Tidying data\ndtB <- \n  dtB %>% \n  pivot_longer(\n    !VISIT,\n    names_to = \"Domain\",\n    values_to = \"Mean_Score\"\n    )\n\n# Seperating the visit variable into baseline and week 16\ndtB <-\n  dtB %>% \n  pivot_wider(\n    names_from = VISIT,\n    values_from = Mean_Score\n    )\n\n# Ensuring the domain levels are ordered the same\ndtB <-\n  dtB %>% \n  mutate(\n    Domain = factor(Domain,\n                    levels = c(\"Symptoms\", \"Embarrassment\",\n                               \"Shopping and home care\",\n                               \"Clothes\", \"Social and leisure\",\n                               \"Sport\", \"Work and study\",\n                               \"Close relationships\",\n                               \"Sex\", \"Treatment\"))\n    )\n\n# Constructing a dumbbell plot using ggalt package with a ggchart theme\n\n(b <- \n  ggplot()+\n  geom_dumbbell(\n    data = dtB,\n    aes(\n      y = Domain,\n      x = Baseline,\n      xend = `Week 16`\n      ),\n    size = 1.5,\n    color = \"lightgray\",\n    size_x = 3,\n    colour_x = \"violetred4\",\n    size_xend = 3,\n    colour_xend = \"maroon1\")\n  + theme_ggcharts(grid = \"Y\") \n  + labs(\n    title = \"Active Treatment\"\n    ) + theme(\n    plot.title = element_text(hjust = 0.5),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.text.y = element_text(size = 9)\n        ))\n\n## Mean total score for both treatment arms\n\ntotaldt <- \n  dql %>%\n  # Remove missing data\n  filter(!is.na(dql)) %>%\n  # select and summarizing relevant variables\n  select(DLQI_SCORE, TRT, VISIT) %>%\n  group_by(TRT, VISIT) %>%\n  summarise(\n    qtotal = mean(DLQI_SCORE, na.rm = T)\n    )\n\n# Tidying data\ntotaldt <- \n  totaldt %>% \n  pivot_wider(\n    names_from = VISIT,\n    values_from = qtotal\n    )\n\ntotaldt$TRT[totaldt$TRT==\"A\"] <- \"Placebo\"\ntotaldt$TRT[totaldt$TRT==\"B\"] <- \"Active Treatment\"\n\n# Constructing a dumbbell plot using ggcharts\n\n(c <- \n  dumbbell_chart(\n    data = totaldt,\n    x = TRT,\n    y1 = Baseline,\n    y2 = `Week 16`,\n    line_color = \"lightgray\",\n    line_size = 3,\n    point_color = c(\"violetred4\", \"maroon1\"),\n    point_size = 7\n  ) + labs(\n    x = NULL,\n    y = NULL,\n    title = \"Dermatological Life Quality Index DLQI\",\n    subtitle = \"Change in mean scores from Baseline to Week 16  (Top chart is total score)\",\n    caption = \"Samah Abdelaal\"\n    ) + theme(\n    axis.text.y = element_text(face = \"bold\"),\n    plot.title = element_text(size = 14,\n                              face = \"bold\"),\n    plot.subtitle = element_text(size = 12),\n    plot.caption = element_text(size = 11,\n                                face = \"italic\"),\n    legend.position = \"bottom\"\n    ))\n\n# Compine all three plots\nlibrary(gridExtra)\n\ngrid.arrange(c, arrangeGrob(b, a, ncol = 2), nrow = 2)\n\n\n\nBack to blog\n\nExample 4. Histrograms\n\n\n# Load data\ndql <- read.csv(\"ww2020_dlqi.csv\")\nattach(dql)\nView(dql)\nsummary(dql)\n\n# Load Library\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(ggcharts)\n\n# Select relevant variables\ndql_renamed <-\n  dql %>%\n  select(\n    TRT, VISIT, DLQI_SCORE\n    )\n\n# Rename treatment levels\ndql_renamed$TRT[dql_renamed$TRT==\"A\"] <- \"Placebo\"\ndql_renamed$TRT[dql_renamed$TRT==\"B\"] <- \"Active Treatment\"\n\n# Seperate visits\n\n# Baseline visit\ntotalbaseline <- \n  dql_renamed %>% \n  filter(VISIT==\"Baseline\")\n\n# Construct a histogram for each treatment arm at baseline visit\n(d <- \n  ggplot(\n    data = totalbaseline,\n    aes(\n      x = DLQI_SCORE\n      ))\n  + geom_histogram(\n    binwidth = 1.5,\n    color = \"grey\",\n    fill = \"deeppink3\"\n    ) +\n  facet_grid(~ TRT)\n  + theme_ng(grid = \"X\")\n  + labs(\n    x = \"DLQI Score\",\n    y = \"Count\",\n    title = \"Total DLQI Score\",\n    subtitle = \"At Baseline\",\n    caption = \"Samah Abdelaal\")\n  + theme(\n    axis.title.x = element_blank(),\n    plot.title = element_text(size = 20,\n                              face = \"bold\"),\n    plot.subtitle = element_text(size = 18),\n    plot.caption = element_text(size = 15,\n                                face = \"bold.italic\")\n    ))\n\n\n# Week 16 visit\ntotalweek16 <- \n  dql_renamed %>% \n  filter(VISIT==\"Week 16\")\n\n(e <- \n  ggplot(\n    data = totalweek16,\n    aes(\n      x = DLQI_SCORE\n      )\n    )\n  + geom_histogram(\n    binwidth = 1.5,\n    color = \"grey\",\n    fill = \"deeppink3\"\n    ) +\n  facet_grid(~ TRT)\n  + theme_ng(grid = \"X\")\n  + labs(\n    x = \"DLQI Score\",\n    y = \"Count\",\n    subtitle = \"At Week 16\"\n    ) +\n  theme(\n    plot.subtitle = element_text(size = 18)\n    ))\n\n# Compine plots\nlibrary(gridExtra)\n\ngridExtra::grid.arrange(d, e, nrow = 2)\n\n\n\nBack to blog\n\n\n\n",
    "preview": "posts/2021-02-07-wonderful-wednesdays-february-2021/./images/Condistr - Devan Becker.png",
    "last_modified": "2021-02-07T15:29:20+01:00",
    "input_file": {},
    "preview_width": 1000,
    "preview_height": 1000
  },
  {
    "path": "posts/2021-01-11-wonderful-wednesdays-january-2021/",
    "title": "Wonderful Wednesdays January 2021",
    "description": "The data set is about a retrospecitve study on finding \"Predictors of Residual Tumor in Breast-Conserving Therapy\". There are 500 subjects included. The outcome variable is reexcision and it describes, if there has been a reexcision necessary after the (initial) surgery. In a first step, a prediction model for reexcission needed to be set up. The goal of this exercise was to visualize the results. The audience was intended to be a \"non-technical\" one.",
    "author": [
      {
        "name": "PSI VIS SIG",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2021-01-13",
    "categories": [
      "Prediction",
      "Wonderful Wednesdays"
    ],
    "contents": "\nPrediction dataset\n\nExample 1. Exploratory analysis, correlation, and prediction\nhigh resolution imagehigh resolution image\nhigh resolution imagehigh resolution imagehigh resolution imagehigh resolution imagehigh resolution imagehigh resolution imagehigh resolution imagehigh resolution imagehigh resolution image\n(A summary of the discussion will be added shortly.)\nlink to code\n\nExample 2. Classification tree\nhigh-resolution image\n(A summary of the discussion will be added shortly.)\nlink to code\n\nExample 3. Nomogram\n\nhigh-resolution image\n(A summary of the discussion will be added shortly.)\nlink to code\n\nExample 4. Interactive Model Studio\n\nThe html file can be found here.\n(A summary of the discussion will be added shortly.)\nlink to code\n\nExample 5. Prediction app\n\nThe html file can be found here.\n(A summary of the discussion will be added shortly.)\nlink to code\nCode\n\nExample 1. Exploratory analysis, correlation, and prediction\n\n#!/usr/bin/env python\n# coding: utf-8\n\n# In[1]:\n\n\n###### #Following instructions in DataCamp course:\n \n#https://campus.datacamp.com/courses/generalized-linear-models-in-python/modeling-binary-data?ex=15\n#https://towardsdatascience.com/a-quick-guide-on-descriptive-statistics-using-pandas-and-seaborn-2aadc7395f32\n#https://github.com/VIS-SIG/Wonderful-Wednesdays/tree/master/data/2020/2020-12-09\n\n\n#Import libraries\n \nimport statsmodels.api as sm #Array based model\n \nfrom statsmodels.formula.api import glm\n \nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#from lifelines import KaplanMeierFitter\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n# In[2]:\n\n\nimport seaborn as sns\n\n\n# In[3]:\n\n\nimport pandas as pd\n\n\n# In[4]:\n\n\nimport os\nprint(os.getcwd()) #/Users/zahraSari\n\n\n# In[23]:\n\n\n\ncwd=os.chdir('/Users/zahraSari/Desktop/') \n\n#Change directory\n\nFiles = os.listdir(cwd) \n\n\n# In[24]:\n\n\n#Data from Github : \n#https://github.com/VIS-SIG/Wonderful-Wednesdays/blob/master/data/2020/2020-12-09/Reexcision.csv    \n\ndata= pd.read_csv('Book.csv')\n\nprint(data)\n \n#age\n#tumorsize\n#histology (hist; 0: others, 1: Invasive-duct./ductal-lob.)\n#Multifocality (mult.foc; 0: no, 1: yes)\n#Accomp. in situ (acc.in.situ; 0: others, 1: DCIS and LCIS)\n#Lymphovascular invasion (lymph.inv; 0: no, 1: yes)\n#Estrogen-receptor (estr.rec; 0: no, 1: yes)\n#Progesterone-receptor (prog.rec; 0: no, 1: yes)\n\n\n# In[25]:\n\n\n\nprint(data.columns.tolist()) #View the column names\n \n\n\n# In[26]:\n\n\ndata.info() # Tumor size has 9 unknown variables\n \n\n\n# In[27]:\n\n\ndata.mean()\n\n\n# In[28]:\n\n\ntotal_rows=len(data.axes[0])\ntotal_cols=len(data.axes[1])\nprint(\"Number of Rows: \"+str(total_rows))\nprint(\"Number of Columns: \"+str(total_cols))\n\n\n# In[29]:\n\n\n\ndata['tumorsize']= pd.to_numeric(data['tumorsize'])\n\n\n# In[30]:\n\n\ndata=data.dropna() #Removing the 9 unknown variables from Data Frame\n \n\n\n# In[31]:\n\n\ndata.mean()\n\n\n# In[32]:\n\n\n\n# Plot the age variable\nsns.distplot(data['age'])\n\nplt.axvline(np.median(data['age']),color='b', linestyle='--') \n\nplt.axvline(np.mean(data['age']),color='b', linestyle='-') \n\n#Display the plot\nplt.show()\n \ndata.age.mean()\n\n\n# In[33]:\n\n\n\n# Plot first variable\n\nsns.distplot(data['tumorsize'])\n \nplt.axvline(np.median(data['tumorsize']),color='b', linestyle='--') \n\nplt.axvline(np.mean(data['tumorsize']),color='b', linestyle='-') \n    \n    \n# Display the\n\nplt.show()\n\ndata.tumorsize.mean()\n \n\n\n# In[34]:\n\n\n#Interpretation: People with re-exision \n\ng = sns.FacetGrid(data, col='RE')\ng.map(plt.hist, 'tumorsize', bins=20)\n\n\n# In[35]:\n\n\n\ng = sns.FacetGrid(data, col='RE')\ng.map(plt.hist, 'age', bins=20)\n\n\n# # Pivoting Features\n\n# In[57]:\n\n\ndata['hist'].value_counts().sort_values()\n\n\n# In[58]:\n\n\nsns.countplot(x='hist',data=data,palette='hls')\nplt.show()\n\n\n# In[56]:\n\n\nsns.countplot(x='RE',data=data,palette='hls')\nplt.show()\n\n\n# In[48]:\n\n\n\n# Summary Chart Re-excision\n\nax = ((100 *data[\"RE\"].value_counts() / len(data))).plot.bar(rot=0)\nax.set( ylabel=\"%\", title=\"Re-excision\")\n\nplt.show()\n\n# Summary Chart hist\n\nax = ((100 *data[\"hist\"].value_counts() / len(data))).plot.bar(rot=0)\nax.set( ylabel=\"%\", title=\"hist\")\n\nplt.show()\n\n# Summary Chart multfoc\n\nax = ((100 *data[\"multfoc\"].value_counts() / len(data))).plot.bar(rot=0)\nax.set( ylabel=\"%\", title=\"multfoc\")\n\nplt.show()\n\n\n# In[38]:\n\n\n\ndata.groupby(['RE']).mean() #Mean of variables for RE of 0 or 1\n\n\n# In[39]:\n\n\n\n#Interpretation: Age distribution for patinets who had Re-excision is lower than those with \n\nget_ipython().run_line_magic('matplotlib', 'inline')\n\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(10,8))\nax = sns.boxplot( x='RE',y='age', data=data, orient=\"v\")\n\n\n# In[40]:\n\n\n\nget_ipython().run_line_magic('matplotlib', 'inline')\n\nsns.set(style=\"whitegrid\")\n\nplt.figure(figsize=(10,8))\nax = sns.boxplot(y='tumorsize' , x='RE', data=data, orient=\"v\")\n\n#The box plot shows you how a feature's values spread out for each class. \n#It's a compact representation of the distribution, showing the extreme high value, \n#upper quartile, median, lower quartile and extreme low value.\n\n\n# In[41]:\n\n\ndf = df.convert_objects(convert_numeric=True)    \nsub_df = df.groupby(['RECL_LCC','RECL_PI'])['COUNT'].sum().unstack()\nsub_df.plot(kind='bar',stacked=True)\n\n\n# # Correlating categorical features\n\n# In[42]:\n\n\n\ngrid = sns.FacetGrid(data, row='accinsitu', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'hist', 'RE' , 'lymphinv', palette='deep')\ngrid.add_legend()\n\n\n# In[43]:\n\n\nprint(data.corr)\n\n\n# # Correlation\n\n# In[44]:\n\n\n####Correlation Plot#######\n\ncorr=data.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 13))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\n\n# # Statistical Model - Logistic Model\n\n# In[ ]:\n\n\n\n#########Statistical Model############\n\n#Fit logistic regression model\n#Logistic regression is an improved version of linear regression.\n\n\n# In[17]:\n\n\n\nmodel = sm.GLM.from_formula(\"RE ~ hist + age + tumorsize + hist + multfoc + accinsitu + lymphinv + estrrec + progrec \", family = sm.families.Binomial(), data=data)\nresult = model.fit()\nresult.summary()\n\n#Based on p-value being less than 0.05, \n#Significant variables are: hist, tumorsize, accinsitu, lymphinv\n#Age is very close to 0.05 so speculuative whether it is significant, \n#Similarly for Intercept, p-value is very close to 0.05 but doesn't pass\n\n\n#Coef for hist: (Thinking of linear regression formula Y = AX + B) \n#where A= -1.2014 , B is 0 since it is non-significant. \n#If a person’s hist is 1 unit more s/he will have a 0.052 (coefficient with age in the table above) unit more \n#chance of having heart disease based on the p-value in the table.\n\n#Generally, positive coefficients indicate that the event becomes more likely as the predictor increases. \n#Negative coefficients indicate that the event becomes less likely as the predictor increases.\n\n\n# In[67]:\n\n\n#Removing non-significant variables and re-fitting the model\n#Age seems to be significant now\n\nmodel = sm.GLM.from_formula(\"RE ~ hist + age + tumorsize + accinsitu + lymphinv  -1 \", family = sm.families.Binomial(), data=data)\nresult = model.fit()\nresult.summary()\n\n#coeffiecnt -1.2849 for hist shows increase of odds\n#for ones with hist=1 than ones with hist=0\n\n#According to this fitted model, older people are more\n#likely to have Reexicision than younger people. The \n#log odds for heart disease increases by 0.0545 units for each year.\n#If a person is 10 years older his or her chance of having RE\n#increases by 0.0545 * 10 = 0.545 units.\n\n\n# In[68]:\n\n\n\ndata[['RE','hist', 'age' , 'tumorsize' , 'accinsitu' , 'lymphinv']].corr()\n\n\n# # Visualization of the Fitted Model\n\n# In[91]:\n\n\n#https://towardsdatascience.com/logistic-regression-model-fitting-and-finding-the-correlation-p-value-z-score-confidence-8330fb86db19\n#With help from this site\n\n\n# In[92]:\n\n\nfrom statsmodels.sandbox.predict_functional import predict_functional\n\n\n# In[104]:\n\n\nvalues = {\"hist\": 0, \"tumorsize\": 50, \"accinsitu\":0 , \"lymphinv\" :0 }\n\n\n# In[105]:\n\n\npr, cb, fv = predict_functional(result, \"age\", values=values, ci_method=\"simultaneous\")\n\n\n# In[106]:\n\n\nax = sns.lineplot(fv, pr, lw=4)\nax.fill_between(fv, cb[:, 0], cb[:, 1], color='grey', alpha=0.4)\nax.set_xlabel(\"age\")\nax.set_ylabel(\"Re-excision\")\n\nax.set_title('Fitted Model: Log-odd probability of Age by Re-excision')\n\n#This plot of fitted log-odds  visualizes the effect of age on reexcision for \n#hist=0, tumorsize=23, accinsitu=0 and lumphinv=0 by the glm fitted model\n#Slight negative correlation of age and RE are visible in this plot\n#For the specific described variables\n\n\n# In[ ]:\n\n\n\n\n\n# In[100]:\n\n\nfrom statsmodels.sandbox.predict_functional import predict_functional\nvalues = {\"hist\": 0, \"age\": 45, \"accinsitu\":0 , \"lymphinv\" :0 }\npr, cb, fv = predict_functional(result, \"tumorsize\", values=values, ci_method=\"simultaneous\")\n\nax = sns.lineplot(fv, pr, lw=4)\nax.fill_between(fv, cb[:, 0], cb[:, 1], color='grey', alpha=0.4)\nax.set_xlabel(\"Tumor Size\")\nax.set_ylabel(\"Re-excision\")\n\nax.set_title('Fitted Model: Log-odd probability of Tumorsize by Re-excision')\n\n#This plot of fitted log-odds  visualizes the effect of tumorsize on reexcision for \n#hist=0, age=45, accinsitu=0 and lumphinv=0 by the glm fitted model\n#Clear Positive correlation of tumorsize and RE are visible in this plot\n\n\n# In[ ]:\n\n\n\n\n\n# In[ ]:\n\n\n\n\n\n# In[103]:\n\n\n\nimport seaborn as sns\n \n#Plot the relationship between two variables in a DataFrame and \n#add overlay with the logistic fit\n\n\nsns.regplot(x = 'tumorsize', y = 'RE',\n            y_jitter = 0.03,\n            data = data,\n            logistic = True,\n            ci = 95)\n\nplt.title('Fitted Plot for Re-excision vs. Tumorsize')\n\n# Display the plot\nplt.show()\n\n#Interpretation: the lower tumor sizes are associated with value 0 for Reexcision, \n#higher values of tumorsize.\n#Tumor sizes of over 55 are associated with value of 1 for Reexicision.\n#The confidence interval gets wider as the value of the predictor increases. The \n#wide interval is partly due to the small amount of data for larger tumor size.\n\n\n# In[101]:\n\n\n#Plot the relationship between two variables in a DataFrame and add overlay with the logistic fit\n\nsns.regplot(x = 'age', y = 'RE',\n            y_jitter = 0.03,\n            data = data,\n            logistic = True,\n            ci = 95)\n \n# Display the plot\nplt.show()\n\n#Interpretation: the lower values age is associated with value 0 for Reexcision, higher values of tumorsize\n#eg. tumor size of over 55 are associated with value of 1 for Reexicision.\n#The confidence interval gets wider as the value of the predictor increases. The \n#wide interval is partly due to the small amount of data for larger lower and higher ages.\n\n\n# In[ ]:\n\n\n# Compute predictions for the test sample df and save as prediction\nprediction = model_fit.predict(exog = data)\n\n\n# In[ ]:\n\n\n# Add prediction to the existing data frame df and assign column name prediction\ndata['prediction'] = prediction\n\n\n# In[ ]:\n\n\n# Examine the first 5 computed predictions\nprint(data[['RE',  'hist', 'multfoc', 'accinsitu', 'lymphinv', 'estrrec', 'progrec']].head())\n\n\n# In[ ]:\n\n\n\n# Define the cutoff\ncutoff = 0.5\n\n# Compute class predictions: y_prediction\ny_prediction = np.where(prediction > cutoff, 1, 0)\n\n\n# # Machine Learning\n\n# In[ ]:\n\n\n#Random Forest\n\n\n# In[ ]:\n\n\n\nfrom sklearn.model_selection import train_test_split\n\n\n# In[ ]:\n\n\n\ny=data['RE']\n\n\n# In[ ]:\n\n\n\ntrain_df = data.drop(['RE'], axis=1)\n\n\n# In[ ]:\n\n\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nX, y = np.arange(10).reshape((5, 2)), range(5)\nX\nlist(y)\n\n\n# In[ ]:\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nX_train\n\n\n# In[ ]:\n\n\ny_train\n\n\n# In[ ]:\n\n\nX_test\n\n\n# In[ ]:\n\n\ny_test\n\n\n# In[ ]:\n\n\n\n#print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n\n#train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n#test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n#combine = [train_df, test_df]\n\n#\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape\n\n\n# In[ ]:\n\n\n\ntrain_df = data.drop(['RE'], axis=1)\n\n\n# In[ ]:\n\n\ndf = pd.DataFrame(np.random.randn(100, 2))\n\nmsk = np.random.rand(len(df)) < 0.8\n\ntrain = df[msk]\n\ntest = df[~msk]\n\nlen(test)\nlen(train)\n\n\n# In[ ]:\n\n\n#####################DATACAMP#################\n\n# Import train_test_split function\n#from sklearn.model_selection import train_test_split\n\n#X=data[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n#y=data['species']  # Labels\n\n# Split dataset into training set and test set\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n\n\n\n\n# Import train_test_split function\nfrom sklearn.model_selection import train_test_split\n\nX=data[['age' , 'tumorsize' , 'hist',  'multfoc' , 'accinsitu',  'lymphinv',  'estrrec' , 'progrec']]  # Features\ny=data['RE']  # Labels\n\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n\n\n\n# In[ ]:\n\n\n\n\n\n# In[ ]:\n\n\n\n\n#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred=clf.predict(X_test)\n\n\n# In[ ]:\n\n\n\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n\n\n# In[ ]:\n\n\n\nRandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)\n\n\n# In[ ]:\n\nBack to blog\n\nExample 2. Classification tree\n\n\n# Prediction data:\n##################\n\n# Classification tree:\n# ====================\n\nsetwd(\"/home/lorenz/Wonderful_Wednesday_Webinars/2021-01/\")\ndat <- read.csv(\"Reexcision.csv\")\nfor (i in 1:ncol(dat)) {\n  if (length(unique(dat[, i])) < 5) {\n    dat[, i] <- factor(dat[, i])\n  }\n}\n\ndat$RE <- factor(dat$RE, levels = c(0, 1), labels = c(\"no\", \"yes\"))\n\nrequire(rpart)\nrequire(rpart.plot)\ndat_tree <- rpart(RE~., dat, model = TRUE)\npng(\"tree.png\", height = 4, width = 6, res = 150, units = \"in\")\nprp(dat_tree, type = 4, extra = 6, cex = 0.5, varlen = 0,\n    main = 'Classification tree for reexcission:\n    Accomp. in situ, Tumor size, and histology seem to be the most important predictors.\n    Each box shows the predicted value and the relative frequency of the category RE=yes.')\ndev.off()\n\n\n\nBack to blog\n\nExample 3. Nomogram\n\n\n# Nomogram:\n# =========\n\nsetwd(\"/home/lorenz/Wonderful_Wednesday_Webinars/2021-01/\")\ndat <- read.csv(\"Reexcision.csv\")\nfor (i in 1:ncol(dat)) {\n  if (length(unique(dat[, i])) < 5) {\n    dat[, i] <- factor(dat[, i])\n  }\n}\n\ndat$RE <- factor(dat$RE, levels = c(0, 1), labels = c(\"no\", \"yes\"))\n\nrequire(rms)\n\n# attach(dat)\n# ddist <- datadist(age, tumor.size, hist, mult.foc, acc.in.situ, lymph.inv, estr.rec, prog.rec)\nddist <- datadist(dat)\noptions(datadist='ddist')\n# detach(dat)\nfit <- lrm(RE ~ ., data = dat)\n\npng(\"nomogram.png\", height = 8, width = 10, res = 150, units = \"in\")\npar(xpd = T)\nplot(nomogram(fit, fun = function(x) 1/(1 + exp(-x)),\n              funlabel = \"Probability for reexcission\",\n              fun.at = c(.001, 0.01, 0.05, seq(.1, .9, by = .1), .95, .99, .999)),\n     label.every = 1)\ntext(0.4, 1.07, \"Nomogram based on RE data:\n     Read out the points for each predictor and sum them up.\n     Then, the probability for re-excission can be read out.\")\ndev.off()\n\n\n\nBack to blog\n\nExample 4. Interactive Model Studio\n\n\n# LINKS\n# modelStudio github: https://github.com/ModelOriented/modelStudio\n# modelStudio package: https://modelstudio.drwhy.ai/index.html\n# book: Explanatory Model Analysis Explore, Explain, and Examine Predictive Models: http://ema.drwhy.ai/\n# website: https://modeloriented.github.io/DrWhy/\n\n# location\nrstudioapi::getSourceEditorContext()$path %>% \n  dirname() %>% \n  setwd()\n\n# Import & Reshape\npacman::p_load(tidyverse)\n\nd1 <- read.csv(\"https://raw.githubusercontent.com/VIS-SIG/Wonderful-Wednesdays/master/data/2020/2020-12-09/Reexcision.csv\") %>% \n  mutate( hist         = factor(hist, labels = c(\"Others\", \"Invasive-duct./ductal-lob.\")) %>% \n            fct_rev(),\n          mult.foc     = factor(mult.foc, labels = c(\"No\",\"Yes\")),\n          acc.in.situ  = factor(acc.in.situ, labels = c(\"Others\",\"DCIS & LCIS\")),\n          lymph.inv    = factor(lymph.inv, labels = c(\"No\",\"Yes\")) %>% \n            fct_rev(),\n          estr.rec     = factor(estr.rec, labels = c(\"No\",\"Yes\")),\n          prog.rec     = factor(prog.rec, labels = c(\"No\",\"Yes\")) ) %>% \n  rename(`Residual_Tumor` = RE, \n         `Age` = age,\n         `Tumor_Size` = tumor.size,\n         `Histology` = hist,\n         `Multifocality` = mult.foc,\n         `Accomp_in_situ` = acc.in.situ,\n         `Lymphovascular` = lymph.inv,\n         `Estrogen_receptor` = estr.rec,\n         `Progesterone_receptor` = prog.rec) \n\n# Logistic Regression w/ Interactions\nf2 <- glm(Residual_Tumor ~ Age + Tumor_Size + Histology + \n            Multifocality + Accomp_in_situ + Lymphovascular +              \n            Age*Lymphovascular + Accomp_in_situ*Lymphovascular, \n          data = d1, family = \"binomial\")\n\n# Model Studio\npacman::p_load(modelStudio)\npacman::p_load(DALEX)\n\n# Explain\nexplainer <- explain(f2,\n                     data = d1,\n                     y = d1$Residual_Tumor,\n                     type = 'classification',\n                     verbose = FALSE,\n                     precalculate = FALSE)\n\n# Interactive\nmodelStudio(explainer,\n            facet_dim = c(1,1),\n            new_observation = d1[140:150,],\n            eda       = FALSE,\n            show_info = FALSE,\n            options = ms_options(w = 500, h = 400,\n                                 margin_left = 200,\n                                 show_boxplot = FALSE,\n                                 show_subtitle = TRUE,\n                                 ms_title    = \"Interactive Model Studio\",\n                                 ms_subtitle = \"Predictors of Residual Tumor in Breast-Conserving Therapy\",\n                                 positive_color = '#1a9641',\n                                 negative_color = '#d7191c',\n                                 default_color  = '#404040',\n                                 bd_title     = 'Break-down Plot for Logistic Regression model',\n                                 bd_subtitle = 'Shows contributions of every variable to a final prediction',\n                                 fi_subtitle = '')) %>% \n  r2d3::save_d3_html(file = \"viz_ms.html\",\n                     selfcontained = TRUE)\n\n# Upload to RPubs\n# markdown::rpubsUpload(title = \"Interactive Model Studio\", \n#                       htmlFile = \"viz_ms_edited.html\")\n\n\n\nBack to blog\n\nExample 5. Prediction app\nThe rmd file can be found here.\nBack to blog\n\n\n\n",
    "preview": "posts/2021-01-11-wonderful-wednesdays-january-2021/./images/viz_ms_edited - Agustin Calatroni.png",
    "last_modified": "2021-01-11T18:27:12+01:00",
    "input_file": {},
    "preview_width": 1011,
    "preview_height": 906
  },
  {
    "path": "posts/2020-12-21-festive-reindeer-plots/",
    "title": "Festive Reindeer Plots",
    "description": "In this entry, we do a little festive fun. We hope you will enjoy it!",
    "author": [
      {
        "name": "Steve Mallett",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2020-12-21",
    "categories": [
      "Christmas",
      "Rudolph"
    ],
    "contents": "\nBackground\nHere is a little festive fun, to illustrate the idea of “storytelling” with data. It is based on a longitudinal cohort study of species Rangier tarandus (reindeer). A cohort of n=8 reindeer were studied over 7 days, with primary endpoint of Reindeer Popularity Index (RPI). RPI is a validated measure of social acceptance by the herd, on a scale of 0 to 10.\nExcel Grouped Bar Chart\nThis chart was produced using Excel, showing popularity scores for each participant over the 7 day study period. This chart uses many of the default settings available in Excel, and the design of the graph has a number of shortcomings. The amount of information presented is overwhelming, and while the results for Rudolph appear atypical, there are a lot of improvements that could be made to gain insights into the data.\n\nR Spaghetti Plot\nThe remaining graphs were drawn using the ggplot2 package in R. In this example, RPI scores for each reindeer are drawn as lines on a common X-axis. It’s easy to see why this type of plot is called a spaghetti plot, and discerning any pattern in the data is challenging (although Rudolph is showing signs of being different from the other reindeer).\n\nlink to code\n\nDecluttered Spaghetti Plot\nAn important stage in creating a clear data story is to remove “chart junk”, i.e. any elements in the graph that might distract from the overall message. By experimenting with R “themes” we obtain a cleaner design. A consideration in data visualisation is the “cognitive load” we are placing on our audience, and in this case the viewer is having to work hard to move backward and forward between the lines and the legend.\n\nlink to code\n\nFocussed Spaghetti Plot\nAt this stage, we’ve decided that the “story” here is Rudolph, with a low RPI score at the start of the study (consistent with other reindeer laughing and calling him names), who gains popularity prior to the end of the study period on 25th December.\nHere we use “pre-attentive” attributes to focus the attention of the viewer, by use of a strong red colour representing Rudolph (consistent with the abnormal nasal colouration of this subject). We can lose the legend, and apply muted tones for the other study participants, the identities of which are not essential to the story.\nBecause interest lies in the relative RPI scores between subjects, a decision was made to remove the vertical axis in order to further simplify the design. However consideration always needs to be given to the audience; a more quantitative audience may require absolute RPI scores to be retained on the plot.\n\nlink to code\n\nCompleted Graph\nFinally, we add a title with our key message. Rudolph’s surge in popularity towards the end of the study coincides with a foggy night, and red shiny noses are thought to provide navigational assistance to airborne sleighs in these conditions [citation needed].\nThe final graph is certainly very effective in telling the audience our data “story”. This was achieved by choosing the right chart type (line plot instead of bar chart), removing unnecessary clutter, and using design features (e.g. use of colour for highlighting and muted tones for de-emphasizing) to focus the attention of our viewer.\n\nlink to code\n\nRudolph Animation\nIn this visualization, the number of packages (or presents) to be delivered within the last 2.5h before Christmas (midnight) is being presented over time by the region where the packages are supposed to arrive. Note that the local time is shown and, thus, it looks like a simultaneous delivery (due to the different time zones). In fact, this means that the package delivery starts in the Eastern regions and ends in the Western regions. The blue asteriscs seem to have some horizontal movement on their way down to zero. However, this is due to the nature of how the updates are done per time point. If there has been no update in a specific region but in the one next to it, the asterisc seems to be moving horizontically, but in fact it is an update in the near neighborhood.\nThis visualization is informative and helps to better understand Rudolph’s stressful time just before Christmas. However, there are some issues which should be fixed. The region on the x axis is lacking some details (which might be due to the need for anonymization of the exact region). Furthermore, the color and the shape of the “dots” are somewhat irritating and you might lose your focus. Simple black dots would have been the better choice to avoid unnecessary clutter. Speaking about clutter: The background picture is certainly distracting and does not add any value to the visualization as it contains no additional information. Overall, it might still serve as an insight into the number of packages arriving just in time.\n (The background picture has been downloaded from https://pixabay.com/ and slightly modified.)\nlink to code\nCode\n\nR Spaghetti Plot\n\n\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readxl)\n\n# Get data, and transpose into long format\n\ndata <- read_excel(\"/shared/175/arenv/arwork/gsk1278863/mid209676/present_2020_01/code/RPI/reindeer_data.xlsx\") %>%\n  pivot_longer(!SUBJECT, names_to = \"Date\", values_to = \"RPI\") %>%\n  mutate(flag = (SUBJECT == \"Rudolph\"))\n\n# Basic line plot (default grey theme)\n\nplot01 <- ggplot() +\n  geom_line(data = data, aes(x = Date, y = RPI, group=factor(SUBJECT), color=factor(SUBJECT)), size = 1) +\n  scale_y_continuous(\"RPI\",\n                     breaks=c(0:10),\n                     limits=c(0, 10)) +\n  labs(title=\"Reindeer Popularity Index Over Time\",\n       color=\"Reindeer Name\") +\n  xlab(\"December\")\n\nggsave(\"/shared/175/arenv/arwork/gsk1278863/mid209676/present_2020_01/code/RPI/R_example01.png\", plot01, width=12, height=8, dpi=300)\n\n\n\nBack to blog\n\nDecluttered Spaghetti Plot\n\n\nplot02 <- ggplot() +\n  geom_line(data = data, aes(x = Date, y = RPI, group=factor(SUBJECT), color=as.factor(SUBJECT)), size = 1) +\n  scale_y_continuous(\"RPI\",\n                     breaks=c(0:10),\n                     limits=c(0, 10)) +\n  labs(title=\"Reindeer Popularity Index Over Time\",\n       color=\"Reindeer Name\") +\n  xlab(\"December\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 16),\n        axis.title = element_text(size = 16),\n        axis.text = element_text(size = 14),\n        legend.title = element_text(size = 14),\n        legend.text = element_text(size = 12)) \n\nggsave(\"/shared/175/arenv/arwork/gsk1278863/mid209676/present_2020_01/code/RPI/R_example02.png\", plot02, width=12, height=8, dpi=300)\n\n\n\nBack to blog\n\nFocussed Spaghetti Plot\n\n\nplot03 <- ggplot() +\n  geom_line(data = data, aes(x = Date, y = RPI, group=factor(SUBJECT), color=as.factor(flag), size = flag)) +\n  scale_x_discrete(\"December\",\n                     labels = c(\"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\"),\n                   expand = c(0.02, 0.02)) +\n  scale_y_continuous(\" \",\n                     breaks=c(0:10),\n                     limits=c(0, 10)) +\n  scale_color_manual(values=c(\"#d9d9d9\", \"#e41a1c\")) +\n  scale_size_manual(values=c(1, 1.5)) +\n  labs(title=\"Reindeer Popularity Index Over Time\",\n       color=\"Reindeer Name\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 16, color = \"#525252\"),\n        axis.title.x = element_text(size = 16, color = \"#525252\"),\n        axis.text.x = element_text(size = 14, color = \"#525252\"),\n        axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.line.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        legend.position = \"none\"\n        ) +\n  annotate(\"text\", label = \"Rudolph\", x = 6.7, y = 9, color = \"#e41a1c\", size=6)\n\nggsave(\"/shared/175/arenv/arwork/gsk1278863/mid209676/present_2020_01/code/RPI/R_example03.png\", plot03, width=12, height=8, dpi=300)\n\n\n\nBack to blog\n\nCompleted Graph\n\n\nplot04 <- ggplot() +\n  geom_line(data = data, aes(x = Date, y = RPI, group=factor(SUBJECT), color=as.factor(flag), size = flag)) +\n  scale_x_discrete(\"December\",\n                   labels = c(\"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\"),\n                   expand = c(0.02, 0.02)) +\n  scale_y_continuous(\"RPI\",\n                     breaks=c(0:10),\n                     limits=c(0, 11),\n                     expand = c(0, 0.02)) +\n  scale_color_manual(values=c(\"#d9d9d9\", \"#e41a1c\")) +\n  scale_size_manual(values=c(1, 1.5)) +\n  geom_hline(yintercept=10, color = \"#f46d43\", linetype = \"longdash\") + \n  geom_hline(yintercept=1, color = \"#f46d43\", linetype = \"longdash\") + \n  labs(title=\"Summary of Reindeer Popularity Index Over Time\\n \\nKey Message: Reindeer with shiny noses gain popularity on foggy nights\") +\n  xlab(\"December\") +\n  theme_classic() +\n  theme(plot.title = element_text(size = 18, color = \"#253494\"),\n        axis.title.x = element_text(size = 16, color = \"#525252\"),\n        axis.text.x = element_text(size = 14, color = \"#525252\"),\n        axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.line.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        legend.position = \"none\"\n  ) +\n  annotate(\"text\", label = \"Rudolph\", x = 6.7, y = 9, color = \"#e41a1c\", size=6) +\n  annotate(\"rect\", xmin=5, xmax = 6, ymin=0, ymax = 10, fill = \"#9ecae1\", alpha = 0.5) +\n  annotate(\"text\", label = \"Foggy\", x = 5.5, y = 4, color = \"#0570b0\", size=5.5) +\n  annotate(\"text\", label = \"Weather\", x = 5.5, y = 3, color = \"#0570b0\", size=5.5) +\n  annotate(\"text\", label = \"Conditions\", x = 5.5, y = 2, color = \"#0570b0\", size=5.5) +\n  annotate(\"text\", label = \"Goes down in history\", x = 1.6, y = 9.4, color = \"#f46d43\", size=6) +\n  annotate(\"text\", label = \"Unpopular\", x = 1.3, y = 1.6, color = \"#f46d43\", size=6) \n\nggsave(\"/shared/175/arenv/arwork/gsk1278863/mid209676/present_2020_01/code/RPI/R_example04.png\", plot04, width=12, height=8, dpi=300)\n\n\n\nBack to blog\nRudolph Animation\n\n\n\nrequire(gganimate)\nrequire(gapminder)\nrequire(ggpubr)\nrequire(png)\n\n# Simulate data:\nset.seed(12345)\ny <- c()\nfor (j in 1:10) {\n  for (i in 1:150) {\n    y <- c(y, rnorm(10, 150-j*5-i))\n  }\n}\n\ny[which(y < 0)] <- 0\n\nx <- runif(10, 0, 1)\nfor (i in 1:((length(y)/10)-1)) {\n  for (j in 1:10) {\n    x <- c(x, x[(i-1)*10 + j] + rnorm(1, 0, 0.025))\n  }\n}\nc.n <- paste0(0, 0:9)\nz <- rep(paste0(\"09:\", 31:59), each = 10)\nz <- c(z, rep(paste0(\"10:\", c(c.n, 10:59)), each = 10))\nz <- c(z, rep(paste0(\"11:\", c(c.n, 10:59)), each = 10))\nz <- c(z, rep(\"Midnight\", 10))\nz <- rep(z, 10)\n\ndat <- data.frame(x, y, z)\n\n# Import background image:\nimg <- png::readPNG(\"Rudolph_cut.png\")\n\n# Create the plot:\np <- ggplot(dat, aes(x = x, y = y)) + theme_bw() +\n    background_image(img) +\n    theme(axis.line = element_line(colour = \"white\"),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.border = element_blank(),\n        panel.background = element_blank(),\n        axis.ticks = element_blank(),\n        text = element_text(size=15)) +\n    scale_x_continuous(name = \"Region\", limits = c(-1, 2), breaks = c(-1, 2),\n                       labels = c(\"West\", \"East\")) +\n    scale_y_continuous(name = \"No. of presents (million)\", limits = c(0, 100),\n                       breaks = c(0, 25, 50, 75, 100), labels = c(\"0\", \"2.5\", \"5\", \"7.5\", \"10\")) +\n    geom_point(shape = 8, color = \"lightblue\", size = 3)\n\n# Transform it into an animated plot:\nanim <- p + transition_states(states = z) + shadow_wake(wake_length = 0.1, alpha = T) +\n  labs(title = \"Number of presents to be delivered\n       within 2.5h to Christmas.\",\n       subtitle = \"Time: {closest_state}pm\")\n\nanimate(anim, nframes = 300, height = 450, width = 550)\nanim_save(\"rudolph.gif\")\n\n\n\nBack to blog\n\n\n\n",
    "preview": "posts/2020-12-21-festive-reindeer-plots/./images/R_example04.png",
    "last_modified": "2020-12-21T18:39:48+01:00",
    "input_file": {},
    "preview_width": 3600,
    "preview_height": 2400
  },
  {
    "path": "posts/2020-12-03-wonderful-wednesdays-december-2020/",
    "title": "Wonderful Wednesdays December 2020",
    "description": "Mark Baillie guides us through the submissions for the meta-analysis data set. The purpose of the challenge was to explore how data visualisation can be deployed to find insights when faced with big data. Big data in the pharma setting typically means wide data i.e. more variables than observations. We went through a number of interesting submissions from a shiny application of a forest plot, an interactive application to explore relationships between variables, an application that provides a workflow for developing a prognostic model, through to exploratory plots using small multiple ridge and scatter plots. A lesson from the challenge is to always visualise your data to avoid surprises.",
    "author": [
      {
        "name": "Mark Baillie",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2020-12-09",
    "categories": [
      "Meta-analysis",
      "Wonderful Wednesdays"
    ],
    "contents": "\nExample meta-analysis dataset\nThe meta-analysis data set introduced some of the challenges faced when working with pooled or integrated clinical trial data. This is often referred to as meta-analysis.\nMeta-analyses concerning integrated data throw up a number of challenges typically as the data sets are “found” i.e. not designed by the team performing the analysis or designed for the question of interest. This is often the typical task of a data science project.\nKey issues where data visualisation can help are around the investigation of whether studies can or should be combined due to study heterogeneity among individual trials. This throws up questions such as:\nwhat graphical tools can be used to assess heterogeneity, describing the fixed and random-effects?\nwhat variables are potentially prognostic or predictive of outcome, etc?\nwhere can graphical methods provide some general recommendations?\nLets go through the submissions and how they tackled some of these questions.\n\nExample 1. Forest plot\nhigh-resolution image\nThis is an example of a forest plot displaying the within study results based on two outcomes comparing treatment effect on patient blood pressure response at 1-year using odds ratio and relative risk measures. The treatment effect is displayed as a table and visualisation by study as well as the overall fixed effect size. The size of the study is also encoded in the size of the “point estimate”. The agreement or overlap between each study is also highlighted through bands.\nThere are nice interactive options that allow the switching between odds ratio and relative risk. This can help with comparisons or essentially a sensitivity analysis, comparing different assumptions. Another option is to be able to resize the plot, which is a great feature if the plot has to be presented at different forums or media (i.e. report or powerpoint).\nThe banding to display the overlap or agreement between studies is an interesting idea, but is not intuitive. Often banding is used to encode uncertainty.\nAnother potential addition to this plot would be annotation to indicate the overall random or fixed effect, to help draw comparisons across study with the full model.\nThe shiny app can be found here.\nlink to code\n\nExample 2. Explorer app\n\nThe second submission is an example of the open source subscreen shiny app applied to the problem of exploring integrated data. The application provides a number of options to explore the relationship between explanatory and dependent variables. With wide data, the combinations between variables can become overwhelming. This is where such an application helps with systematically exploring the data to look for potential issues or trends that require further investigation.\nlink to code\n\nExample 3. Prognostic model workflow shiny app\n\nhigh-resolution image\nThe app can be found here.\nThis submission was a carefully thought through example of how visualisations can be embedded into the workflow of the development of a model. The app is developed to support a 2-stage meta-analysis approach to detect baseline variables that are predictive of mean systolic blood pressure (mm Hg) measured at 1-year. A number of visualisations are provided to support each phase of the workflow.\nWhat is nice about this app is that plots such as a ranking of variable importance is placed alongside other supporting visualisations that provide supporting context. In this case a scatter plot of the observed and predictive outcome. This provides an instant overview of the model.\nThe second step provides both the forest plot of within study estimates with a GOSH plot to explore the heterogeneity of each study and the impact of including or not including a study within the model. Again, both plots side by side provide context that support the workflow.\nPlease click on the link to explore for yourself.\nlink to code\n\nExample 4. Comparison of blood pressure by study\n\nThis submission is a selection of plots that uses small multiples to explore the within study relationship between key variables related to baseline and outcome. In this case the relationship between blood pressure measured at baseline and 1-year. Small multiples provide an instant overview and a visual check for potential differences.\nThe first set of plots use ridge plots to explore the distribution by treatment. This is an example of the outcome variable (BP at 1-year). Ridge plots provide a visual check and comparison. However, the comparison is by treatment, where plotting the treatment difference could be more informative. The ridge plots also create a slight “3d” effect, where the upper placed treatment is “higher” in value compared to the lower; this could be potentially misleading when comparing across treatments.\n\nThe second set of plots use scatter plots to explore the relationship between baseline and 1-year by treatment. The plots are designed to provide a message. In this case, further checking of the data is required for studies 1 and 3.\n\nCloser examination identifies systematic patterns in the data that may indicate we would want to exclude those studies from a “full model”, or at least query the issue further. This is a good example of why visualisations are important to identify issues with the data, and to identify “insights”.\nhigh-resolution image high-resolution image high-resolution image high-resolution image\nlink to code\n\nExample 5. Baseline characteristics\nhigh-resolution image\nlink to code\nThe final submission explored the use of ridge plots again to replace the typical “table one” with a visual representation. As a quick overview, this provides an instant overview of the distribution of many continuous variables. However, the treatment comparisons between ridges also suffer from this “3d” effect. Another potential problem is how to scale the distributions so that comparisons with skewed distributions with data points with extreme values can be displayed.\nCode\n\nExample 1. Forest plot\nThe following code only shows the app code. The complete code can be found here (zip folder).\n\n\nlibrary(shiny)\nlibrary(shinythemes)\nlibrary(r2d3)\nlibrary(shinyhelper)\n\nui <- fluidPage(\n  theme = shinytheme('united'),\n  title = 'Visualizing Heterogeneity in Meta-Analyses',\n\n  tags$style('\n    body {\n      margin: auto 30px;\n    }\n    footer {\n      padding: 5px;\n      text-align: right;\n    }\n    .shinyhelper-container i {\n      font-size: 20px;\n    }\n    #control-panel {\n      display: flex;\n      align-items: center;\n    }\n    #forest-container {\n      display: flex;\n      flex-direction: column;\n      align-items: center;\n    }\n  '),\n  \n  div(class = 'page-header',\n      h1('Visualizing Heterogeneity in Meta-Analyses'),\n      h3('Forest Plot with Heterogeneity Bands')),\n  \n  wellPanel(style = 'margin: 20px auto;',\n            fluidRow(id = 'control-panel',\n                     column(2,\n                            radioButtons('summary_measure',\n                                         label = 'Summary measure:',\n                                         choices = list('Odds ratio' = 'or',\n                                                        'Risk ratio' = 'rr'))),\n                     column(5,\n                            sliderInput('d3_width',\n                                        'Plot width:',\n                                        value = 850,\n                                        min = 750,\n                                        max = 1300,\n                                        step = 10,\n                                        post = ' px')),\n                     column(5,\n                            sliderInput('d3_height',\n                                        'Plot height:',\n                                        value = 500,\n                                        min = 350,\n                                        step = 10,\n                                        max = 800,\n                                        post = ' px')))),\n  \n  helper(content = 'interpretation',\n         colour = 'teal',\n         buttonLabel = 'OK',\n         div(id ='forest-container',\n             style = 'min-height: 350px;',\n             d3Output('d3Forest'))),\n  \n  hr(),\n  tags$footer('Built by',\n              a(' Waseem Medhat',\n                href = 'https://linkedin.com/in/waseem-medhat'),\n              ' for ',\n              a('Wonderful Wednesdays',\n                href = 'https://psiweb.org/sigs-special-interest-groups/visualisation/welcome-to-wonderful-wednesdays')))\n\nserver <- function(input, output) {\n  observe_helpers()\n  \n  observe({\n    metadata <- readRDS(\n      sprintf('data/metadata_%s.rds', input$summary_measure)\n    )    \n    \n    removeUI('#d3Forest', immediate = TRUE)\n    \n    insertUI(\n      selector = '#forest-container',\n      where = 'beforeEnd',\n      ui = d3Output('d3Forest', height = input$d3_height, width = input$d3_width)\n    )\n    \n    output$d3Forest <- renderD3({\n      r2d3(metadata, script = 'src/forestWithBands.js')\n    })\n  })\n  \n}\n\nshinyApp(ui = ui, server = server)\n\n\n\nBack to blog\n\nExample 2. Explorer app\n\n\n# EC subscreen presentation\n\nrm(list=ls())\nsetwd(\"o:/1_Global_Biostatistics/Biostatistics Innovation Center/BIC Project - Subgroup Analyses/Screening/_archive/WW/\")\n\nsuppressPackageStartupMessages(library(dplyr)) \nlibrary(survival)\nlibrary(subscreen)\n\nA=read.csv(file=\"BIG_DATA_PSI_WW_DEC2020.csv\", sep=\",\", dec=\".\", na.strings = \"\", header=TRUE)\n\nA$CHG <- as.numeric(A$CHG)\nA$PCHG <- as.numeric(A$PCHG)\nA$AVALCAT1N <- as.numeric(A$AVALCAT1N)\nA$AVALCAT2N <- as.numeric(A$AVALCAT2N)\n\nA %>% group_by(Base_SBP) %>% count()\n\n#dychotomisation/categorisation of continuous variables\n\nA$HEIGHT <- as.numeric(A$HEIGHT)\nhei.median <- median(A$HEIGHT, na.rm=TRUE)\nA$Height_gr[A$HEIGHT <  171] <- \"A) < 171 cm (median)\"\nA$Height_gr[A$HEIGHT >= 171] <- \"B) >=171 cm\"\nA$Height_gr[is.na(A$HEIGHT)] <- \"C) missing\"\n\nA$WEIGHT <- as.numeric(A$WEIGHT)\nwei.median <- median(A$WEIGHT, na.rm=TRUE)\nA$Weight_gr[A$WEIGHT <  60] <- \"A) < 60 kg\"\nA$Weight_gr[A$WEIGHT >= 60] <- \"B) 60-90 cm\"\nA$Weight_gr[A$WEIGHT >  90] <- \"C) > 90 cm\"\nA$Weight_gr[is.na(A$WEIGHT)] <- \"D) missing\"\n\nA$BMI <- as.numeric(A$BMI)\nbmi.median <- median(A$BMI, na.rm=TRUE)\nA$BMI_gr[A$BMI <  18.5] <- \"A) < 18.5 (WHO)\"\nA$BMI_gr[A$BMI >= 18.5] <- \"B) 18.5-24.9 (WHO)\"\nA$BMI_gr[A$BMI >=  25]  <- \"C) 25-29.9 (WHO)\"\nA$BMI_gr[A$BMI >=  30]  <- \"D) >=30 (WHO)\"\nA$BMI_gr[is.na(A$BMI)]  <- \"E) missing\"\n\nA$Age_gr[A$AGE <  30] <- \"A) < 30 years\"\nA$Age_gr[A$AGE >= 30] <- \"B) 30-59 cm\"\nA$Age_gr[A$AGE >= 60] <- \"C) 60-75 cm\"\nA$Age_gr[A$AGE >  75] <- \"D) > 75 cm\"\n\nA$CHD10R1[A$CHD10R1==\"High (>20%)\"] <- \"Mx High (>20%)\"\n\nA$ALBSI <- as.numeric(A$ALBSI)\nmedian(A$ALBSI, na.rm=TRUE)\nA$ALB_med[A$ALBSI <  45] <- \"A) <  45 (median)\"\nA$ALB_med[A$ALBSI >= 45] <- \"B) >= 45 (median)\"\nA$ALB_med[is.na(A$ALBSI)]  <- \"C) missing\"\n\nA$BASOSI <- as.numeric(A$BASOSI)\nmedian(A$BASOSI, na.rm=TRUE)\nA$BASO_med[A$BASOSI <  0.02] <- \"A) <  0.02 (median)\"\nA$BASO_med[A$BASOSI >= 0.02] <- \"B) >= 0.02 (median)\"\nA$BASO_med[is.na(A$BASOSI)]  <- \"C) missing\"\n\nA$BICARSI <- as.numeric(A$BICARSI)\nmedian(A$BICARSI, na.rm=TRUE)\nA$BICAR_med[A$BICARSI <  24] <- \"A) <  24 (median)\"\nA$BICAR_med[A$BICARSI >= 24] <- \"B) >= 24 (median)\"\nA$BICAR_med[is.na(A$BICARSI)]  <- \"C) missing\"\n\nA$BILISI <- as.numeric(A$BILISI)\nmedian(A$BILISI, na.rm=TRUE)\nA$BILI_med[A$BILISI <  7] <- \"A) <  7 (median)\"\nA$BILI_med[A$BILISI >= 7] <- \"B) >= 7 (median)\"\nA$BILI_med[is.na(A$BILISI)]  <- \"C) missing\"\n\nA$BUNSI <- as.numeric(A$BUNSI)\nmedian(A$BUNSI, na.rm=TRUE)\nA$BUN_med[A$BUNSI <  4.64] <- \"A) <  4.64 (median)\"\nA$BUN_med[A$BUNSI >= 4.64] <- \"B) >= 4.64 (median)\"\nA$BUN_med[is.na(A$BUNSI)]  <- \"C) missing\"\n\nA$CASI <- as.numeric(A$CASI)\nmedian(A$CASI, na.rm=TRUE)\nA$CA_med[A$CASI <  2.38] <- \"A) <  2.38 (median)\"\nA$CA_med[A$CASI >= 2.38] <- \"B) >= 2.38 (median)\"\nA$CA_med[is.na(A$CASI)]  <- \"C) missing\"\n\nA$CHOL_HDL <- as.numeric(A$CHOL_HDL)\nmedian(A$CHOL_HDL, na.rm=TRUE)\nA$CHOL_HDL_med[A$CHOL_HDL <  4] <- \"A) <  4 (median)\"\nA$CHOL_HDL_med[A$CHOL_HDL >= 4] <- \"B) >= 4 (median)\"\nA$CHOL_HDL_med[is.na(A$CHOL_HDL)]  <- \"C) missing\"\n\nA$CHOLSI <- as.numeric(A$CHOLSI)\nmedian(A$CHOLSI, na.rm=TRUE)\nA$CHOL_med[A$CHOLSI <  4.95] <- \"A) <  4.95 (median)\"\nA$CHOL_med[A$CHOLSI >= 4.95] <- \"B) >= 4.95 (median)\"\nA$CHOL_med[is.na(A$CHOLSI)]  <- \"C) missing\"\n\nA$CREATSI <- as.numeric(A$CREATSI)\nmedian(A$CREATSI, na.rm=TRUE)\nA$CREAT_med[A$CREATSI <  77] <- \"A) <  77 (median)\"\nA$CREAT_med[A$CREATSI >= 77] <- \"B) >= 77 (median)\"\nA$CREAT_med[is.na(A$CREATSI)]  <- \"C) missing\"\n\nA$EOSLESI <- as.numeric(A$EOSLESI)\nmedian(A$EOSLESI, na.rm=TRUE)\nA$EOSLE_med[A$EOSLESI <  2] <- \"A) <  2 (median)\"\nA$EOSLE_med[A$EOSLESI >= 2] <- \"B) >= 2 (median)\"\nA$EOSLE_med[is.na(A$EOSLESI)]  <- \"C) missing\"\n\nA$EOSSI <- as.numeric(A$EOSSI)\nmedian(A$EOSSI, na.rm=TRUE)\nA$EOS_med[A$EOSSI <  0.16] <- \"A) <  0.16 (median)\"\nA$EOS_med[A$EOSSI >= 0.16] <- \"B) >= 0.16 (median)\"\nA$EOS_med[is.na(A$EOSSI)]  <- \"C) missing\"\n\nA$GGTSI <- as.numeric(A$GGTSI)\nmedian(A$GGTSI, na.rm=TRUE)\nA$GGT_med[A$GGTSI <  25] <- \"A) <  25 (median)\"\nA$GGT_med[A$GGTSI >= 25] <- \"B) >= 25 (median)\"\nA$GGT_med[is.na(A$GGTSI)]  <- \"C) missing\"\n\nA$GLUCPSI <- as.numeric(A$GLUCPSI)\nmedian(A$GLUCPSI, na.rm=TRUE)\nA$GLUCP_med[A$GLUCPSI <  5.2] <- \"A) <  5.2 (median)\"\nA$GLUCP_med[A$GLUCPSI >= 5.2] <- \"B) >= 5.2 (median)\"\nA$GLUCP_med[is.na(A$GLUCPSI)]  <- \"C) missing\"\n\nA$HCT <- as.numeric(A$HCT)\nmedian(A$HCT, na.rm=TRUE)\nA$HCT_med[A$HCT <  0.43] <- \"A) <  0.43 (median)\"\nA$HCT_med[A$HCT >= 0.43] <- \"B) >= 0.43 (median)\"\nA$HCT_med[is.na(A$HCT)]  <- \"C) missing\"\n\nA$HDLSI <- as.numeric(A$HDLSI)\nmedian(A$HDLSI, na.rm=TRUE)\nA$HDL_med[A$HDLSI <  1.22] <- \"A) <  1.22 (median)\"\nA$HDL_med[A$HDLSI >= 1.22] <- \"B) >= 1.22 (median)\"\nA$HDL_med[is.na(A$HDLSI)]  <- \"C) missing\"\n\nA$HDT <- as.numeric(A$HDT)\nmedian(A$HDT, na.rm=TRUE)\nA$HDT_med[A$HDT <  1.1] <- \"A) <  1.1 (median)\"\nA$HDT_med[A$HDT >= 1.1] <- \"B) >= 1.1 (median)\"\nA$HDT_med[is.na(A$HDT)]  <- \"C) missing\"\n\nA$HGBSI <- as.numeric(A$HGBSI)\nmedian(A$HGBSI, na.rm=TRUE)\nA$HGB_med[A$HGBSI <  146] <- \"A) <  146 (median)\"\nA$HGB_med[A$HGBSI >= 146] <- \"B) >= 146 (median)\"\nA$HGB_med[is.na(A$HGBSI)]  <- \"C) missing\"\n\nA$KSI <- as.numeric(A$KSI)\nmedian(A$KSI, na.rm=TRUE)\nA$K_med[A$KSI <  4.3] <- \"A) <  4.3 (median)\"\nA$K_med[A$KSI >= 4.3] <- \"B) >= 4.3 (median)\"\nA$K_med[is.na(A$KSI)]  <- \"C) missing\"\n\nA$LDLSI <- as.numeric(A$LDLSI)\nmedian(A$LDLSI, na.rm=TRUE)\nA$LDL_med[A$LDLSI <  3.11] <- \"A) <  3.11 (median)\"\nA$LDL_med[A$LDLSI >= 3.11] <- \"B) >= 3.11 (median)\"\nA$LDL_med[is.na(A$LDLSI)]  <- \"C) missing\"\n\nA$LPASI <- as.numeric(A$LPASI)\nmedian(A$LPASI, na.rm=TRUE)\nA$LPA_med[A$LPASI <  0.21] <- \"A) <  0.21 (median)\"\nA$LPA_med[A$LPASI >= 0.21] <- \"B) >= 0.21 (median)\"\nA$LPA_med[is.na(A$LPASI)]  <- \"C) missing\"\n\nA$LYMLESI <- as.numeric(A$LYMLESI)\nmedian(A$LYMLESI, na.rm=TRUE)\nA$LYMLE_med[A$LYMLESI <  26] <- \"A) <  26 (median)\"\nA$LYMLE_med[A$LYMLESI >= 26] <- \"B) >= 26 (median)\"\nA$LYMLE_med[is.na(A$LYMLESI)]  <- \"C) missing\"\n\nA$LYMSI <- as.numeric(A$LYMSI)\nmedian(A$LYMSI, na.rm=TRUE)\nA$LYM_med[A$LYMSI <  1.76] <- \"A) <  1.76 (median)\"\nA$LYM_med[A$LYMSI >= 1.76] <- \"B) >= 1.76 (median)\"\nA$LYM_med[is.na(A$LYMSI)]  <- \"C) missing\"\n\nA$MONOLSI <- as.numeric(A$MONOLSI)\nmedian(A$MONOLSI, na.rm=TRUE)\nA$MONOL_med[A$MONOLSI <  6] <- \"A) <  6 (median)\"\nA$MONOL_med[A$MONOLSI >= 6] <- \"B) >= 6 (median)\"\nA$MONOL_med[is.na(A$MONOLSI)]  <- \"C) missing\"\n\nA$TRIGFSI <- as.numeric(A$TRIGFSI)\nmedian(A$TRIGFSI, na.rm=TRUE)\nA$TRIGF_med[A$TRIGFSI <  1.41] <- \"A) <  1.41 (median)\"\nA$TRIGF_med[A$TRIGFSI >= 1.41] <- \"B) >= 1.41 (median)\"\nA$TRIGF_med[is.na(A$TRIGFSI)]  <- \"C) missing\"\n\nA$URATESI <- as.numeric(A$URATESI)\nmedian(A$URATESI, na.rm=TRUE)\nA$URATE_med[A$URATESI <  357] <- \"A) <  357 (median)\"\nA$URATE_med[A$URATESI >= 357] <- \"B) >= 357 (median)\"\nA$URATE_med[is.na(A$URATESI)]  <- \"C) missing\"\n\nA$WBCSI <- as.numeric(A$WBCSI)\nmedian(A$WBCSI, na.rm=TRUE)\nA$WBC_med[A$WBCSI <  7.1] <- \"A) <  7.1 (median)\"\nA$WBC_med[A$WBCSI >= 7.1] <- \"B) >= 7.1 (median)\"\nA$WBC_med[is.na(A$WBCSI)]  <- \"C) missing\"\n\nA$BASE <- as.numeric(A$BASE)\nmedian(A$BASE, na.rm=TRUE)\nA$Base_SBP[A$BASE <  132] <- \"A) < 132 mmHg\"\nA$Base_SBP[A$BASE >= 132] <- \"B) 132-145 mmHg\"\nA$Base_SBP[A$BASE >= 145] <- \"C) >= 145 mmHg\"\nA$Base_SBP[is.na(A$BASE)]  <- \"D) missing\"\n\n\n#names(A)[names(A) == \"AGEGR1\"]   <- \"\"\n\n\nfactors=c(\"STUDYID\", \"SEX\", \"RACE\", \"ETHNIC\", \"Height_gr\", \"Weight_gr\", \"BMI_gr\", \"Age_gr\", \n          \"Base_SBP\", \"CHD10R1\", \"ALB_med\", \"BASO_med\", \"BICAR_med\", \"BILI_med\", \"BUN_med\", \"CA_med\",\n          \"CHOL_HDL_med\", \"CHOL_med\", \"CREAT_med\", \"EOSLE_med\", \"EOS_med\", \"GGT_med\", \"GLUCP_med\", \"HCT_med\",\n          \"HDL_med\", \"HDT_med\", \"HGB_med\", \"K_med\", \"LDL_med\", \"LPA_med\", \"LYMLE_med\", \"LYM_med\",\n          \"MONOL_med\", \"TRIGF_med\", \"URATE_med\", \"WBC_med\")\n\n### analysis function \"auwe\" to be filled in with the statistical evaluation\nauwe<- function(D){\n  \n  Mean.Change.SBP.SoC <- round(mean(D$CHG[D$TRT01PN == 0], na.rm=TRUE),2)\n  Mean.Change.SBP.Int <- round(mean(D$CHG[D$TRT01PN == 1], na.rm=TRUE),2)\n  Diff.Change.SBP     <- Mean.Change.SBP.SoC - Mean.Change.SBP.Int\n  \n  Mean.PctChange.SBP.SoC <- round(mean(D$PCHG[D$TRT01PN == 0], na.rm=TRUE),2)\n  Mean.PctChange.SBP.Int <- round(mean(D$PCHG[D$TRT01PN == 1], na.rm=TRUE),2)\n  Diff.PctChange.SBP     <-  Mean.PctChange.SBP.Int - Mean.PctChange.SBP.SoC\n  \n  N.SoC  <- sum(D$TRT01PN==0)\n  N.Int  <- sum(D$TRT01PN==1)\n\n  Responder.120.SoC    <- sum(D$AVALCAT1N[D$TRT01PN == 0] == 1, na.rm=TRUE)\n  Responder.120.Int    <- sum(D$AVALCAT1N[D$TRT01PN == 1] == 1, na.rm=TRUE)\n\n  Prop.Responder.120.SoC <- round(Responder.120.SoC/sum(!is.na(D$AVALCAT1N[D$TRT01PN == 0]), na.rm=TRUE)*100,2)\n  Prop.Responder.120.Int <- round(Responder.120.Int/sum(!is.na(D$AVALCAT1N[D$TRT01PN == 1]), na.rm=TRUE)*100,2)\n\n  Diff.Responder.120     <- Prop.Responder.120.Int - Prop.Responder.120.SoC\n  OR.Responder.120       <- limit(round((Responder.120.Int * (N.SoC-Responder.120.SoC))/(Responder.120.SoC * (N.Int-Responder.120.Int)),3), high=100)\n  RelRisk.Responder.120  <- limit(round((Responder.120.Int * N.SoC)/(Responder.120.SoC * N.Int),3), high=100)\n  \n  Responder.132.SoC    <- sum(D$AVALCAT2N[D$TRT01PN == 0] == 0, na.rm=TRUE)\n  Responder.132.Int    <- sum(D$AVALCAT2N[D$TRT01PN == 1] == 0, na.rm=TRUE)\n  \n  Prop.Responder.132.SoC <- round(Responder.132.SoC/sum(!is.na(D$AVALCAT2N[D$TRT01PN == 0]), na.rm=TRUE)*100,2)\n  Prop.Responder.132.Int <- round(Responder.132.Int/sum(!is.na(D$AVALCAT2N[D$TRT01PN == 1]), na.rm=TRUE)*100,2)\n  \n  Diff.Responder.132     <- Prop.Responder.132.Int - Prop.Responder.132.SoC\n  OR.Responder.132       <- limit(round((Responder.132.Int * (N.SoC-Responder.132.SoC))/(Responder.132.SoC * (N.Int-Responder.132.Int)),3))\n  RelRisk.Responder.132  <- limit(round((Responder.132.Int * N.SoC)/(Responder.132.SoC * N.Int),3))\n  \n  \n  return(data.frame(Diff.Change.SBP, Mean.Change.SBP.SoC, Mean.Change.SBP.Int,\n                    Diff.PctChange.SBP, Mean.PctChange.SBP.SoC, Mean.PctChange.SBP.Int, \n                    Diff.Responder.120, OR.Responder.120, RelRisk.Responder.120, Prop.Responder.120.SoC, Prop.Responder.120.Int,\n                    Diff.Responder.132, OR.Responder.132, RelRisk.Responder.132, Prop.Responder.132.SoC, Prop.Responder.132.Int,\n                    N.SoC, N.Int\n                    ))\n\n}\n\n#limit function / truncation of large or small estimates\nlimit <- function(x, low=0.05, high=20){\n  if (!is.na(x)) y=min(high, max(low,x)) else y=NA\n  return (y)\n}\n\nresults <- subscreencalc(data=A,\n                    eval_function=auwe,\n                    endpoints=c(\"CHG\", \"PCHG\", \"AVALCAT1N\", \"AVALCAT2N\"),\n                    treat=\"TRT01PN\",\n                    subjectid=\"USUBJD\",\n                    factors=factors,\n                    min_comb=1,\n                    max_comb=2,\n                    nkernel=16,\n                    par_functions = \"limit\",\n                    factorial = TRUE,\n                    use_complement =FALSE, \n                    verbose=T)\n\n\n#setwd(\"O:/1_Global_Biostatistics/Biostatistics Innovation Center/BIC Project - Subgroup Analyses/Screening/16244\")\n#save(results, file = \"o:/1_Global_Biostatistics/Biostatistics Innovation Center/BIC Project - Subgroup Analyses/Screening/_archive/WW/sgs3.RData\")\n# rm(\"results\")\n# load(\"o:/1_Global_Biostatistics/Biostatistics Innovation Center/BIC Project - Subgroup Analyses/Screening/_archive/WW/sgs3.RData\")\n\nsubscreenshow(results, port=14444)\n\n\n\nBack to blog\n\nExample 3. Meta-analysis shiny app\nBack to blog\n\nExample 4. Comparison of blood pressure by study\n\n\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(Hmisc)\nlibrary(hrbrthemes)\nlibrary(ggtext)\nlibrary(rlang)\n\n\n# Functions originally from Cedric Scherer  \n# https://cedricscherer.netlify.app/2019/08/05/a-ggplot2-tutorial-for-beautiful-plotting-in-r/\nelement_textbox_highlight <- function(..., hi.labels = NULL, hi.fill = NULL,\n                                      hi.col = NULL, hi.box.col = NULL, hi.family = NULL) {\n  structure(\n    c(element_textbox(...),\n      list(hi.labels = hi.labels, hi.fill = hi.fill, hi.col = hi.col, hi.box.col = hi.box.col, hi.family = hi.family)\n    ),\n    class = c(\"element_textbox_highlight\", \"element_textbox\", \"element_text\", \"element\")\n  )\n}\n\nelement_grob.element_textbox_highlight <- function(element, label = \"\", ...) {\n  if (label %in% element$hi.labels) {\n    element$fill <- element$hi.fill %||% element$fill\n    element$colour <- element$hi.col %||% element$colour\n    element$box.colour <- element$hi.box.col %||% element$box.colour\n    element$family <- element$hi.family %||% element$family\n  }\n  NextMethod()\n}\n\n\n## Read data and manipulate\ndata <- read_csv(\"BIG_DATA_PSI_WW_DEC2020.csv\") %>%\n  mutate(\n    TRT01PC = if_else(TRT01P == \"INT\", \"Intensive treatment\", \"Standard of care\"),\n    STUDYIDC = paste0(\"Study \", STUDYID)\n  )\n\n# Check color palettes \n# RColorBrewer::display.brewer.all()\n\n\n\n#-------------------------------------------------------\n# Small multiples of BASE by Study\n\n\n\nplot1a <-\n  ggplot(data, aes(x = BASE, y = TRT01PC, fill = TRT01PC)) +\n  geom_density_ridges(scale = 4,\n                      jittered_points = TRUE,\n                      position = position_points_jitter(width = 0.05, height = 0),\n                      point_shape = '|', point_size = 3, point_alpha = 1, alpha = 0.7) + \n  scale_y_discrete(expand = c(0, 0)) +   \n  scale_x_continuous(expand = c(0, 0)) + \n  scale_fill_brewer(palette = \"Dark2\") +\n  coord_cartesian(clip = \"off\") + \n  theme_ipsum_rc(base_size = 16) +\n  labs(x = \"DBP [mmHg] at 1-year\") +\n  facet_wrap(~STUDYIDC) +\n  labs(\n    x = \"Mean systolic blood pressure at baseline [mmHg]\",\n    fill = \"Treatment\",\n    title = \"Comparison of mean systolic blood pressure measured at 1-year by study\",\n    subtitle = \"There is some evidence of a bi-modal distribution in studys 1 and 3\",\n    caption = \"Data: BIG_DATA_PSI_WW_DEC2020.csv\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\nggsave(\"eda-plot1a.png\", plot1a, height = 8, width = 12, dpi = 250)\n\n\n\n\n#-------------------------------------------------------\n# Small multiples of AVAL by Study\n\n\n\nplot1b <-\n  ggplot(data, aes(x = AVAL, y = TRT01PC, fill = TRT01PC)) +\n  geom_density_ridges(scale = 4,\n                      jittered_points = TRUE,\n                      position = position_points_jitter(width = 0.05, height = 0),\n                      point_shape = '|', point_size = 3, point_alpha = 1, alpha = 0.7) + \n  scale_y_discrete(expand = c(0, 0)) +   \n  scale_x_continuous(expand = c(0, 0)) + \n  scale_fill_brewer(palette = \"Dark2\") +\n  coord_cartesian(clip = \"off\") + \n  theme_ipsum_rc(base_size = 16) +\n  labs(x = \"DBP [mmHg] at 1-year\") +\n  facet_wrap(~STUDYIDC) +\n  labs(\n    x = \"Mean systolic blood pressure at 1-year [mmHg]\",\n    fill = \"Treatment\",\n    title = \"Comparison of mean systolic blood pressure measured at 1-year by study\",\n    subtitle = \"There is some evidence of a bi-modal distribution in studys 1 and 3\",\n    caption = \"Data: BIG_DATA_PSI_WW_DEC2020.csv\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\nggsave(\"eda-plot1b.png\", plot1a, height = 8, width = 12, dpi = 250)\n\n\n\n\n#-------------------------------------------------------\n# Small multiples of AVAL vs BASE by Study\n\nplot2a <-\n  data %>% ggplot(aes(\n    x = BASE,\n    y = AVAL,\n    group = TRT01PC,\n    color = TRT01PC\n  )) +\n  geom_abline(\n    intercept = 0,\n    slope = 1,\n    color = \"grey\",\n    size = 1,\n    alpha = 0.5\n  ) +\n  geom_smooth(\n    method = \"lm\",\n    formula = y ~ splines::bs(x, 3),\n    se = TRUE,\n    alpha = 0.55\n  ) +\n  geom_point(alpha = 0.45, size = 0.6) +\n  facet_wrap( ~ STUDYIDC, ncol = 3) +\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 5)) +\n  labs(\n    x = \"SBP [mmHg] at randomisation\",\n    y = \"SBP [mmHg] at 1-year\",\n    color = \"Treatment\",\n    title = \"Comparison of pre-post mean systolic blood pressure (SBP) measured at baseline and 1-year\",\n    subtitle = \"Study 1 and 3 may have data quality issues - further investigation required\",\n    caption = \"The by-treatment relationship also disaplyed using a cubic splines.\\ny = x reference line also displayed.\\nData: BIG_DATA_PSI_WW_DEC2020.csv\"\n  )  +\n  theme_ipsum_rc(base_size = 16) +\n  theme(\n    strip.text = element_textbox_highlight(\n      size = 12,\n      face = \"bold\",\n      fill = \"white\",\n      box.color = \"white\",\n      color = \"gray40\",\n      halign = .5,\n      linetype = 1,\n      r = unit(0, \"pt\"),\n      width = unit(1, \"npc\"),\n      padding = margin(2, 0, 1, 0),\n      margin = margin(0, 1, 3, 1),\n      hi.labels = c(\"Study 1\", \"Study 3\"),\n      hi.family = \"Bangers\",\n      hi.fill = \"firebrick\",\n      hi.box.col = \"firebrick\",\n      hi.col = \"white\"\n    ),\n    legend.position = \"bottom\"\n  )\n\n\nggsave(\"eda-plot2a.png\", plot2a, height = 8, width = 12, dpi = 250)\n\n\n\n\n#---------------------------------------\n# Plot study1 and 3 only \n\nplot2b <-\n  data %>%\n  filter(STUDYID == c(1, 3)) %>% \n  ggplot(aes(\n    x = BASE,\n    y = AVAL,\n    group = TRT01PC,\n    color = TRT01PC\n  )) +\n  geom_abline(\n    intercept = 0,\n    slope = 1,\n    color = \"grey\",\n    size = 1,\n    alpha = 0.5\n  ) +\n  geom_point(alpha = 0.7, size = 1) +\n  facet_grid(TRT01PC  ~ STUDYIDC) +\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 5)) +\n  labs(\n    x = \"Mean systolic blood pressure [mmHg] at randomisation\",\n    y = \"Mean systolic blood pressure [mmHg] at 1-year\",\n    color = \"Treatment\",\n    title = \"The intensive treatment arm for study 1 and 3 displayed patterns of interest\",\n    subtitle = \"It is always important to plot data many ways\",\n    caption = \"http://robertgrantstats.co.uk/drawmydata.html \\nData: BIG_DATA_PSI_WW_DEC2020.csv\"\n  )  +\n  theme_ipsum_rc(base_size = 16) +\n  theme(\n    strip.text = element_textbox_highlight(\n      size = 12,\n      face = \"bold\",\n      fill = \"white\",\n      box.color = \"white\",\n      color = \"gray40\",\n      halign = .5,\n      linetype = 1,\n      r = unit(0, \"pt\"),\n      width = unit(1, \"npc\"),\n      padding = margin(2, 0, 1, 0),\n      margin = margin(0, 1, 3, 1),\n      hi.labels = c(\"Study 1\", \"Study 3\"),\n      hi.family = \"Bangers\",\n      hi.fill = \"firebrick\",\n      hi.box.col = \"firebrick\",\n      hi.col = \"white\"\n    ),\n    legend.position = \"bottom\"\n  )\n\n\nggsave(\"eda-plot2b.png\", plot2b, height = 8, width = 12, dpi = 250)\n\n\n\nBack to blog\n\nExample 5. Correlation plot\n\n\nlibrary(tidyverse)\nlibrary(ggridges)\nlibrary(readr)\nlibrary(ggtext)\nlibrary(rlang)\n\n## Read data and manipulate\ndata <- read_csv(\"BIG_DATA_PSI_WW_DEC2020.csv\") %>%\n  mutate(\n    TRT01PC = if_else(TRT01P == \"INT\", \"Intensive treatment\", \"Standard of care\"),\n    STUDYIDC = paste0(\"Study \", STUDYID)\n  )\n\n\nplot_data <-\n  data %>%\n  pivot_longer(\n    cols = c(\n      AGE,\n      ALBSI,\n      BASOSI,\n      BASE,\n      BICARSI,\n      BILISI,\n      BMI,\n      BUNSI,\n      CHOL_HDL,\n      CHOLSI,\n      CREATSI,\n      EOSSI,\n      GGTSI,\n      GLUCPSI,\n      HCT,\n      HDLSI,\n      HDT,\n      HGBSI,\n      KSI,\n      LDLSI,\n      LPASI,\n      LYMLESI,\n      LYMSI,\n      TRIGFSI,\n      URATESI,\n      WBCSI\n    ),\n    names_to = \"var\",\n    values_to = \"val\"\n  )\n\n\nridge_plot <- \n  plot_data %>%\n  ggplot(aes(\n    x = val,\n    y = factor(STUDYID),\n    fill = paste(STUDYIDC, TRT01PC)\n  )) +\n  geom_density_ridges(alpha = .4,\n                      rel_min_height = .01,\n                      color = \"white\") +\n  scale_fill_cyclical(\n    values = c(\"tomato\", \"dodgerblue\"),\n    name = \"\",\n    labels = c(`Study 1 Intensive treatment` = \"Intensive treatment\",\n               `Study 1 Standard of care` = \"Standard of care\"),\n    guide = \"legend\"\n  ) +\n  theme_ridges(grid = FALSE) +\n  facet_wrap( ~ var, scales = \"free\", ncol = 5) +\n  labs(\n    x = \"\",\n    y = \"Study\",\n    fill = \"Treatment\",\n    title = \"Visualising baseline characteristics and demographics by study\",\n    subtitle = \"Presented are a selection of continously measured variables\",\n    caption = \"Data: BIG_DATA_PSI_WW_DEC2020.csv\"\n  ) +\n  theme(legend.position = \"bottom\")\n\nggsave(\n  \"ridge_plot.png\",\n  ridge_plot,\n  height = 12,\n  width = 16,\n  dpi = 330\n)\n\n\n\nBack to blog\n\n\n\n",
    "preview": "posts/2020-12-03-wonderful-wednesdays-december-2020/./images/forest_plot_with_bands - Waseem Medhat.png",
    "last_modified": "2021-02-07T14:56:14+01:00",
    "input_file": {},
    "preview_width": 872,
    "preview_height": 545
  },
  {
    "path": "posts/2020-11-10-wonderful-wednesdays-november-2020/",
    "title": "Wonderful Wednesdays November 2020",
    "description": "Zachary Skrivanek guides through a number of data visualisations explaining a mediated treatment effect on patient reported quality of life. In addition the problem of missing data should be handled within the graphical representation. A Lollipop plot and a bar chart were presented as well as multiplot solutions using correlation plots or a combination of scatter plots, modelling plots and distribution plots. A point of discussion was the usability of a parallel coordinates plot. Another proposal used a Bayesian model displaying the results in an impressive grable – a combination of graphic and table. The last approach used an innovative way of storytelling with data called scrollytelling.",
    "author": [
      {
        "name": "Zachary Skrivanek",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2020-11-11",
    "categories": [
      "Mediation analysis",
      "Wonderful Wednesdays"
    ],
    "contents": "\nMediator effect example data set\nThe purpose of this exercise is to develop data visualization techniques to illustrate that one variable is a mediator for a treatment effect and that this mediator effect is stronger than in other variables. A more detailed description and link to the data can be found here.\n\nExample 1. Mediation on treatment effect\nhigh-resolution image\nThis graphic addresses the question of which variable is mediating the treatment effect the most by plotting the reduction in treatment effect after accounting for the variable. One shortcoming of lollipop charts is that they do not allow for a visulization of uncertainty. link to code\n\nExample 2. Bayesian model\n\nThe html file can be found here.\nThis is a well done “grapple” - a graphic embeded in a table. This table summarizes all essential information in the data to address the mediaton effect of all three variables being considered. The posterior distrubtions are relevant and to the point. It is well annotated, uses color and bold face judiciously to highlight key findings and is organized to let the reader draw the correct conclusion without having to spell it out in the title. This graphic is ready for a journal. The question is: What type of journal? If it is a medical journal then the author might want to exclude the sensitivity analysis results (LOCF or completers) and just pick the appropriate method for handling missing data since this is not of interest to a medical audience. On the other hand if this is for a statistics journal this is quite appropriate. The author is not only showing the key results but the robustness of the results. (And part of the exercise was to account for missingness, so we cannot really blame the author for including this.)\nlink to code\n\nExample 3. Barplot\n\nhigh-resolution image\nThis graphic is similar to the first one except it uses a barchart instead of a lollipop chart and it includes a completers analysis. The title explains the results and the reference line for the marginal treatment effect provides a good reference for the reader.\nlink to code\n\nExample 4. Parallel coords\nhigh-resolution image\nThe parallel coordinate plot is a classic way to analyze multi-variate data. The correlation between itch and DLQI is apparent by the fact that there are so many horizontal parallel lines connecting the two axes. This is a plot where two key parameters have to be fine tuned to bring out any patterns: the order of the axes and the scaling. By separating Rx and placebo into two different panels and scaling them separately we lose the treatment effect on DLQI. They look quite similar in fact, but that is because they were scaled independently. The author chose to color by LOCF, but this revealed no clear pattern. It would be interesting to combine the two treatment groups and color by treatment to see if that creates a distinct grouping for Rx vs placebo.\nThe advantage of this graphic over the barchart and lollipop chart is that we can see the individual variation. But this can be a downside because it can lead to overplotting. Making this interactive where the user could select a set of lines and move the axes could make this plot very powerful.\nlink to code\n\nExample 5. Correlation plot\nhigh-resolution image\nThis is a succinct summary of the correlations between all of the variables, whether they are based on all data including LOCF imputed or just completers. The use of color in addition to shave of the ellipses is a nice application of redundancy. You do not need to read a legend to realize that blue encodes a positive correlation and red encodes a negative correlation and the level of transparency encodes the magnitude of the correlation.\nlink to code\n\nExample 6. Scatter matrices\n\n\nhigh-resolution image high-resolution image high-resolution image\nThese 3 graphics provide an exhaustive amount of information. The 3 graphics address the different ways of treating the missing data. Each graph is a matrix where the upper triangle models the data by treatment and covariate, the lower triangle shows the individual data and the diagonal shows the marginal distributions. The title clearly leads the reader to the conclusion the DLQI is highly correlated with itch and when the reader looks at the panel with two splines, one for each treatment, of DLQI against itch the reader can see that the treatment effect on DLQI is neglible once itch is included in the model.\nlink to code\nCode\n\nExample 1. Mediation on treatment effect\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(mediation)\nlibrary(grid)\nlibrary(gridExtra)\nlibrary(haven)\nlibrary(ggplot2)\nlibrary(cowplot)\n\ndata <- read_csv(\"/shared/175/arenv/arwork/gsk1278863/mid209676/present_2020_01/code/mediation/TRT.csv\")\n\n# Summarise data\nsum <- data %>%\n  group_by(TRT) %>%\n  summarise(avg=mean(DLQI))\nsort <- c(1,2)\nsum <- cbind(sum, sort)\n\n# Plot Mean DLQI\nplot01 <- ggplot(data=sum) +\n  geom_text(aes(x=-5, y=sort, label=TRT, color=TRT), size=10) +\n  geom_segment(aes(x=0, xend=avg, y=sort, yend=sort, color=TRT)) +\n  geom_vline(aes(xintercept=0)) + \n  geom_point(aes(x=avg, y=sort, color=TRT), alpha=0.7, size=10) +\n  scale_x_continuous(\"Mean DLQI at Week 24\",\n                     labels=c(\" \", \"0\", \"10\", \"20\", \"30\"),\n                     breaks=c(-10, 0, 10, 20, 30),\n                     limits=c(-10, 30)) +\n  scale_y_continuous(\" \",\n                     labels=c(\" \", \" \", \" \"),\n                     breaks=c(1,2,3),\n                     limits=c(0, 3)) +\n  labs(title=\"Rx reduces DLQI by approx. 5 units. The treatment effect is \\n\n              reduced by approx. 4 units when Itch is added to the model. \\n\n              Therefore the treatment effect of Rx is mediated primarily by itch.\\n\") +\n  theme_minimal() +\n  theme(legend.position=\"none\",\n        text = element_text(size = 20),\n        axis.ticks.x = element_blank(),\n\n        axis.text.y =  element_blank(),        \n        axis.ticks.y = element_blank(),\n        axis.title.x = element_text(size = 20),\n        plot.title = element_text(hjust = 0.5, size = 25),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=0.25),\n        panel.grid = element_blank())\n\n# Mediation analysis (itch)\nmodel.I <- lm(itch ~ TRT, data)\nmodel.Yi <- lm(DLQI ~ TRT + itch, data)\nmed.itch <- mediate(model.I, model.Yi, treat='TRT', mediator='itch',\n                   boot=TRUE, sims=500)\nitch <- (med.itch$d0)*(-1)\n\n# Mediation analysis (BSA)\nmodel.B <- lm(BSA ~ TRT, data)\nmodel.Yb <- lm(DLQI ~ TRT + BSA, data)\nmed.BSA <- mediate(model.B, model.Yb, treat='TRT', mediator='BSA',\n                    boot=TRUE, sims=500)\nBSA <- (med.BSA$d0)\n\n# Mediation analysis (redness)\nmodel.R <- lm(redness ~ TRT, data)\nmodel.Yr <- lm(DLQI ~ TRT + redness, data)\nmed.redness <- mediate(model.R, model.Yr, treat='TRT', mediator='redness',\n                   boot=TRUE, sims=500)\nredness <- (med.redness$d0)\n\n# Combine ACME values\nsort <- c(1, 2, 3)\nV1 <- \" \"\nA <- data.frame(cbind(itch, BSA, redness))\nA2 <- gather(A, var, val)\nA3 <- cbind(A2, sort, V1)\n\n# Overall treatment effect\nvar = \"Effect\"\nsort = 1\ncoeff <- data.frame(cbind(summary(model.0 <- lm(DLQI ~ TRT, data))$coefficients[2,1]*(-1), var)) %>%\n  mutate(val=as.numeric(V1)) \ncoeff2 <- cbind (coeff, sort)\n\n# Plot treatment effect\nplot02 <- ggplot() +\n  geom_vline(aes(xintercept=0)) +  \n  geom_text(data=coeff2, aes(x=-0.75, y=sort), label=\"Rx Effect\", color=\"blue\", size=10) +\n  geom_segment(data=coeff2, aes(x=0, xend=val, y=sort, yend=sort), color=\"blue\") +\n  geom_point(data=coeff2, aes(x=val, y=sort), color=\"Blue\", alpha=0.7, size=10) +\n  scale_x_continuous(\"Treatment Effect (placebo - Rx)\",\n                     labels=c(\" \", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"),\n                     breaks=c(-1, 0, 1, 2, 3, 4, 5, 6),\n                     limits=c(-1, 6)) +\n  scale_y_continuous(\" \",\n                     labels=c(\" \"),\n                     breaks=c(1),\n                     limits=c(1)) +\n  theme_minimal() +\n  theme(text = element_text(size = 20),\n        axis.ticks.x = element_blank(),\n        axis.text.y =  element_blank(),        \n        axis.ticks.y = element_blank(),\n        axis.title.x = element_text(size = 20),\n        plot.title = element_text(hjust = 0.5, size = 25),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=0.25),\n        panel.grid = element_blank(),\n        plot.caption=element_text(hjust = 0)) \n\n# Plot mediation effect\nplot03 <- ggplot() +\n  geom_text(data=A3, aes(x=-0.75, y=sort, label=var), color=\"black\", size=10) +\n  geom_segment(data=A3, aes(x=0, xend=val, y=sort, yend=sort)) +\n  geom_point(data=A3, aes(x=val, y=sort), color=\"black\", alpha=0.7, size=10, shape=1) +\n  scale_x_continuous(\"Reduction in Treatment Effect (Mediation Effect)\",\n                     labels=c(\" \", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"),\n                     breaks=c(-1, 0, 1, 2, 3, 4, 5, 6),\n                     limits=c(-1, 6)) +\n  scale_y_continuous(\" \",\n                     labels=c(\" \", \" \", \" \"),\n                     breaks=c(1, 2, 3),\n                     limits=c(0, 4)) +\n  theme_minimal() +\n  theme(text = element_text(size = 20),\n        axis.ticks.x = element_blank(),\n        axis.text.y =  element_blank(),        \n        axis.ticks.y = element_blank(),\n        axis.title.x = element_text(size = 20),\n        plot.title = element_text(hjust = 0.5, size = 25),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=0.25),\n        panel.grid = element_blank(),\n        plot.caption=element_text(hjust = 0)) +\n  ggtitle(label = \" \") \n\np <- plot_grid(plot01, plot02, plot03, align = \"v\", nrow = 3, rel_heights = c(1.5, 0.6, 1.2))\n\nggsave(\"/shared/175/arenv/arwork/gsk1278863/mid209676/present_2020_01/code/mediation/DLQI_mediation_mallett.png\", p, width=12, height=12, dpi=300)\n\nBack to blog\n\nExample 2. Bayesian model\nThe code can be found here.\nNote that this is an R markdown file and you might need a proper editor to open it.\nA txt file with the code can be found here.\nBack to blog\n\nExample 3. Barplot\n\n\n# Baplots to show the reduction in treatment effect on DLQI.\n# ==========================================================\n\n# Read in the data set:\ndat <- read.csv(\"mediation_data.csv\")\n\n\nfit <- lm(DLQI ~ TRT, data = dat)\nt.val.pure <- coef(summary(fit))[2, 3]\n\nt.val.vec <- numeric(3)\nj <- 1\nfor (i in c(2, 4, 6)) {\n  fit <- lm(dat$DLQI ~ dat[, i] + dat$TRT)\n  t.val.vec[j] <- coef(summary(fit))[3, 3]\n  j <- j + 1\n}\n\n# Redo without imputed data:\nt.val.vec.re <- numeric(3)\nj <- 1\nfor (i in c(2, 4, 6)) {\n  dat.re <- dat[which(dat[, i+1] == F), ]\n  fit <- lm(dat.re$DLQI ~ dat.re[, i] + dat.re$TRT)\n  t.val.vec.re[j] <- coef(summary(fit))[3, 3]\n  j <- j + 1\n}\n\n# Combine both vectors:\nt.vals <- c(t.val.vec.re[3], t.val.vec[3],\n            t.val.vec.re[2], t.val.vec[2],\n            t.val.vec.re[1], t.val.vec[1])\n\n# Calculate difference:\nt.vals - t.val.pure\n\n# Calculate the difference:\nt.val.diff <- t.vals - t.val.pure\nt.val.mat <- matrix(t.val.diff, ncol = 3)\nfit <- lm(DLQI ~ TRT, dat)\nt.val.mat.pr <- t.val.mat/abs(coef(summary(fit))[2, 3]) * 100\n\npng(\"barplot.png\", width = 7, height = 5, res = 300, units = \"in\")\npar(xpd = T, cex.main = 0.9)\nbarplot(t.val.diff, horiz = T, col = c(\"darkcyan\", \"blue\"), xlim = c(0, 5),\n        space = rep(c(0.25, 0), 3),\n        main = \"Adjusting for itch leads to the greatest reduction\n        in the absolute standardized treatment effect on DLQI (unadjusted effect: 4.7).\n        Removing the LOCF imputed data diminishes the differences.\",\n        xlab = \"Reduction in the absolute standardized treatment effect\")\ny.coord <- c(1.25, 3.5, 5.75)\ntext(-0.25, y.coord[3], \"itch\")\ntext(-0.25, y.coord[2], \"BSA\")\ntext(-0.35, y.coord[1], \"redness\")\nfor (i in 1:nrow(t.val.mat)) {\n  for (j in 1:ncol(t.val.mat)) {\n    t.val <- paste0(format(round(t.val.mat[i, j], 1), nsmall = 1), \" (\",\n                    format(round(t.val.mat.pr[i, j], 1), nsmall = 1), \"%)\")\n    text(t.val.mat[i, j] + .45, y.coord[j] + i - 1.5, t.val,\n         col = c(\"darkcyan\", \"blue\")[i])\n  }\n}\nlegend(\"topright\", legend = c(\"LOCF\", \"Observed\"), fill = c(\"blue\", \"darkcyan\"), bty = \"n\")\ndev.off()\n\nBack to blog\n\nExample 4. Parallel coords\n\n\n## function to scale data\nscale_this <- function(x) {\n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}\n\n\nlibrary(tidyverse)\n\n## read in data\nfinal_in <- read_csv(\"mediation_data.csv\")\n\n## check data \nfinal_in %>% glimpse()\n\n## scale data and put in long format\ndata <- \n  final_in %>% \n  select(!c(\"itch_LOCF\", \"BSA_LOCF\", \"redness_LOCF\", \"DLQI_LOCF\")) %>%\n  mutate(id = row_number(),\n         itch = scale_this(itch),\n         BSA = scale_this(BSA),\n         redness = scale_this(redness),\n         DLQI = scale_this(DLQI)) %>%\n  pivot_longer(!c(TRT, id), names_to = \"var\", values_to = \"val\") \n\n### add an indicator for LOCF variables \nmissing <- \n  final_in %>% \n  select(c(\"TRT\", \"itch_LOCF\", \"BSA_LOCF\", \"redness_LOCF\", \"DLQI_LOCF\")) %>%\n  mutate(id = row_number()) %>%\n  pivot_longer(!c(TRT, id), names_to = \"var\", values_to = \"LOCF\") %>%\n  mutate(var = str_remove(var, \"_LOCF\"))\n\n## join to main data set\ndata <- \n  data %>%\n  left_join(missing)\n\n## check data set\ndata %>% glimpse()\n\n## check LOCF vals\ntable(data$LOCF)\n\n\n## plot data \ndata %>%\n  mutate(\n    name = fct_relevel(var,\n                       \"DLQI\", \"itch\", \"redness\",\n                       \"BSA\"),\n    TRT = fct_relevel(TRT, \"Rx\", \"placebo\")\n  ) %>%\n  ggplot(aes(\n    x = name,\n    y = val,\n    group = id,\n    colour = LOCF\n  )) +\n  geom_hline(yintercept = 0, colour = \"black\", alpha = 0.4, size = 1.1) +\n  geom_point(alpha = 0.7, size = 0.5) +\n  geom_line(alpha = 0.25, size = 0.5) +\n  labs(title = \"Relationship between outcome, treatment and LOCF imputation\",\n       subtitle = \"Measurements are scaled (lower is a better) by outcome\",\n       caption = \"\\n The solid black line at zero represents the mean outcome (irrespective of treatment).\\nA larger number of patients reported a better BSA and redness profile in the Rx arm.\\nThe missing data pattern differs across groups, requiring further investigation.\") +\n  xlab(\"\") +\n  ylab(\"\") +\n  facet_wrap( ~ TRT, ncol = 1) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n## Save plot\npage_width <- 200\npage_height <- 150\nd_dpi <- 300\nggsave(file = paste0(\"parallel_coords.png\"), \n       width = page_width, height = page_height, \n       units = \"mm\", dpi = d_dpi)\n\nBack to blog\n\nExample 5. Correlation plot\n\n\n#########################################\n##  Warning this code requires a re-factor\n## and put repeated steps in to a function\n#########################################\n\nlibrary(corrplot)\nlibrary(tidyverse)\n\n## read in data\nfinal_in <- read_csv(\"mediation_data.csv\")\n\n#plot on one page\npar(mfrow = c(2, 3))\npar(cex = 0.75)\n\n##-----------------------------------------------------\n## Overall correlations\ntitle <- \"How do all outcomes relate overall?\"\n\ncorrs <- final_in %>%\n  dplyr::select(\"itch\", \"BSA\", \"redness\", \"DLQI\") %>%\n  filter(complete.cases(.)) %>%\n  dplyr::mutate_all(as.numeric)\n\nM <- cor(corrs)\ncol <-\n  colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))\ncorrplot(\n  M,\n  method = \"ellipse\",\n  col = col(200), tl.cex = 1/par(\"cex\"),\n  type = \"upper\",\n  order = \"hclust\",\n  number.cex = .7,\n  title = title,\n  addCoef.col = \"black\",\n  # Add coefficient of correlation\n  tl.col = \"black\",\n  tl.srt = 90,\n  # Text label color and rotation\n  # hide correlation coefficient on the principal diagonal\n  diag = FALSE,\n  mar = c(0, 0, 3, 0)\n)\n\n\n\n##-----------------------------------------------------\n### - By Rx arm\ntitle <- \"How do all outcomes relate within Rx?\"\n\ncorrs <- final_in %>%\n  filter(TRT == \"Rx\") %>%\n  dplyr::select(\"itch\", \"BSA\", \"redness\", \"DLQI\") %>%\n  dplyr::mutate_all(as.numeric)\nM <- cor(corrs)\ncol <-\n  colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))\n\ncorrplot(\n  M,\n  method = \"ellipse\",\n  col = col(200), tl.cex = 1/par(\"cex\"),\n  type = \"upper\",\n  order = \"hclust\",\n  number.cex = .7,\n  title = title,\n  addCoef.col = \"black\",\n  # Add coefficient of correlation\n  tl.col = \"black\",\n  tl.srt = 90,\n  diag = FALSE,\n  mar = c(0, 0, 3, 0)\n)\n\n\n##-----------------------------------------------------\n## By Placebo\ncorrs <- final_in %>%\n  filter(TRT == \"placebo\") %>%\n  dplyr::select(\"itch\", \"BSA\", \"redness\", \"DLQI\") %>%\n  dplyr::mutate_all(as.numeric)\nM <- cor(corrs)\ncol <-\n  colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))\n\ntitle <- \"How do all outcomes relate within Placebo?\"\ncorrplot(\n  M,\n  method = \"ellipse\",\n  col = col(200), tl.cex = 1/par(\"cex\"),\n  type = \"upper\",\n  order = \"hclust\",\n  number.cex = .7,\n  title = title,\n  addCoef.col = \"black\",\n  # Add coefficient of correlation\n  tl.col = \"black\",\n  tl.srt = 90,\n  # Text label color and rotation\n  # hide correlation coefficient on the principal diagonal\n  diag = FALSE,\n  mar = c(0, 0, 3, 0)\n)\n\n\n##-----------------------------------------------------\n## Overall and complete cases\n\ncorrs <- final_in %>%\n  filter(itch_LOCF == FALSE &\n           BSA_LOCF == FALSE & redness_LOCF == FALSE & DLQI_LOCF == FALSE) %>%\n  filter(complete.cases(.)) %>%\n  dplyr::select(\"itch\", \"BSA\", \"redness\", \"DLQI\") %>%\n  dplyr::mutate_all(as.numeric)\n\nM <- cor(corrs)\n\ncol <-\n  colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))\n\n\n\ntitle <-\n  \"How do all outcomes relate overall\\n(excluding patients with imputed data)?\"\ncorrplot(\n  M,\n  method = \"ellipse\",\n  col = col(200), tl.cex = 1/par(\"cex\"),\n  type = \"upper\",\n  order = \"hclust\",\n  number.cex = .7,\n  title = title,\n  addCoef.col = \"black\",\n  # Add coefficient of correlation\n  tl.col = \"black\",\n  tl.srt = 90,\n  # Text label color and rotation\n  # hide correlation coefficient on the principal diagonal\n  diag = FALSE,\n  mar = c(0, 0, 3, 0)\n)\n\n\n##-----------------------------------------------------\n### By Rx and complete cases\ncorrs <- final_in %>%\n  filter(TRT == \"Rx\") %>%\n  filter(itch_LOCF == FALSE &\n           BSA_LOCF == FALSE & redness_LOCF == FALSE & DLQI_LOCF == FALSE) %>%\n  filter(complete.cases(.)) %>%\n  dplyr::select(\"itch\", \"BSA\", \"redness\", \"DLQI\") %>%\n  dplyr::mutate_all(as.numeric)\nM <- cor(corrs)\ncol <-\n  colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))\n\ntitle <- \"How do all outcomes relate within Rx?\\n(Complete cases)\"\ncorrplot(\n  M,\n  method = \"ellipse\",\n  col = col(200), tl.cex = 1/par(\"cex\"),\n  type = \"upper\",\n  order = \"hclust\",\n  number.cex = .7,\n  title = title,\n  addCoef.col = \"black\",\n  # Add coefficient of correlation\n  tl.col = \"black\",\n  tl.srt = 90,\n  # Text label color and rotation\n  # hide correlation coefficient on the principal diagonal\n  diag = FALSE,\n  mar = c(0, 0, 3, 0)\n)\n\n\n##-----------------------------------------------------\n### Placebo and complete cases\n\ncorrs <- final_in %>%\n  filter(TRT == \"placebo\") %>%\n  filter(itch_LOCF == FALSE &\n           BSA_LOCF == FALSE & redness_LOCF == FALSE & DLQI_LOCF == FALSE) %>%\n  filter(complete.cases(.)) %>%\n  dplyr::select(\"itch\", \"BSA\", \"redness\", \"DLQI\") %>%\n  dplyr::mutate_all(as.numeric)\nM <- cor(corrs)\ncol <-\n  colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))\n\ntitle <-\n  \"How do all outcomes relate within placebo?\\n(Complete cases)\"\ncorrplot(\n  M,\n  method = \"ellipse\",\n  col = col(200), tl.cex = 1/par(\"cex\"),\n  type = \"upper\",\n  order = \"hclust\",\n  number.cex = .7,\n  title = title,\n  addCoef.col = \"black\",\n  # Add coefficient of correlation\n  tl.col = \"black\",\n  tl.srt = 90,\n  # Text label color and rotation\n  # hide correlation coefficient on the principal diagonal\n  diag = FALSE,\n  mar = c(0, 0, 3, 0)\n)\n\nBack to blog\n\nExample 6. Correlation matrices\na) Overview\n\n\nlibrary(tidyverse)\nlibrary(ggforce)\n\n## Save plot\npage_width <- 350\npage_height <- 250\nd_dpi <- 400\n\n## read in data\nfinal_in <- read_csv(\"mediation_data.csv\")\n\n\n## Plot overall\nggplot(final_in, aes(x = .panel_x, y = .panel_y, colour = TRT, fill = TRT)) +\n  geom_autopoint(alpha = 0.6) +\n  geom_autodensity(alpha = 0.2) +\n  geom_smooth(method = lm, formula = y ~ splines::bs(x, 3)) +\n  facet_matrix(vars(DLQI, itch, redness, BSA), layer.diag = 2, layer.upper = 3, \n               grid.y.diag = FALSE) +\n  labs(title = \"Itch has a strong positive association with DLQI.\",\n       subtitle = \"There is evidence that the DLQI treatment effect is mediated through itch.\",\n       caption = \"\\n Cubic splines are presented in the top-right layer regressing y on x.\\nScatter-plots of the same relationship are displayed in the bottom-left later.\\nThe marginal distribution by treatment are displayed on the diagonal.\") +  \n  theme_light(base_size = 14) +\n  theme(legend.position = \"bottom\")\n\n## save plot\nggsave(file = paste0(\"scatter-matrix-final.png\"), \n       width = page_width, height = page_height, \n       units = \"mm\", dpi = d_dpi)\n\nb) LOCF and CC:\n\n\nlibrary(tidyverse)\nlibrary(ggforce)\n\n## Save plot\npage_width <- 350\npage_height <- 250\nd_dpi <- 400\n\n## read in data\nfinal_in <- read_csv(\"mediation_data.csv\")\n\n\n## Plot overall\nggplot(final_in, aes(x = .panel_x, y = .panel_y, colour = TRT, fill = TRT)) +\n  geom_autopoint(alpha = 0.6) +\n  geom_autodensity(alpha = 0.2) +\n  geom_smooth(method = lm, formula = y ~ splines::bs(x, 3)) +\n  facet_matrix(vars(DLQI, itch, redness, BSA), layer.diag = 2, layer.upper = 3, \n               grid.y.diag = FALSE) +\n  labs(title = \"Investigating the assocation between outcomes and treatment\",\n       subtitle = \"With LOCF imputation\",\n       caption = \"\\n Cubic splines are presented in the top-right layer regressing y on x.\\nScatter-plots of the same relationship are displayed in the bottom-left later.\\nThe marginal distribution by treatment are displayed on the diagonal.\") +  \n  theme_light(base_size = 14) +\n  theme(legend.position = \"bottom\")\n\n## save plot\nggsave(file = paste0(\"scatter-matrix-locf.png\"), \n       width = page_width, height = page_height, \n       units = \"mm\", dpi = d_dpi)\n\n\n## Plot complete cases\nfinal_in %>%\n  filter(itch_LOCF == FALSE & BSA_LOCF == FALSE & redness_LOCF == FALSE & DLQI_LOCF == FALSE) %>%\n  ggplot(aes(x = .panel_x, y = .panel_y, colour = TRT, fill = TRT)) +\n  geom_autopoint(alpha = 0.6) +\n  geom_autodensity(alpha = 0.2) +\n  geom_smooth(method = lm, formula = y ~ splines::bs(x, 3)) +\n  facet_matrix(vars(DLQI, itch, redness, BSA), layer.diag = 2, layer.upper = 3, \n               grid.y.diag = FALSE) +\n  labs(title = \"Investigating the assocation between outcomes and treatment\",\n       subtitle = \"Complete cases analysis\",\n       caption = \"\\n Cubic splines are presented in the top-right layer regressing y on x.\\nScatter-plots of the same relationship are displayed in the bottom-left later.\\nThe marginal distribution by treatment are displayed on the diagonal.\") +  \n  theme_light(base_size = 14) +\n  theme(legend.position = \"bottom\")\n\n## save plot\nggsave(file = paste0(\"scatter-matrix-cc.png\"), \n       width = page_width, height = page_height, \n       units = \"mm\", dpi = d_dpi)\n\nBack to blog\n\n\n",
    "preview": "posts/2020-11-10-wonderful-wednesdays-november-2020/./images/DLQI_mediation_mallett2 - Steve Mallett.png",
    "last_modified": "2020-11-13T17:21:17+01:00",
    "input_file": {},
    "preview_width": 3600,
    "preview_height": 3600
  },
  {
    "path": "posts/2020-10-21-wonderful-wednesdays-october-2020/",
    "title": "Wonderful Wednesdays October 2020",
    "description": "Abi Williams presented data visualisations on co-occurrence of adverse events. How to display events that occur at the same time in the same patient and highlight differences of treatment or gender? A variety of very different approaches was discussed. The first visualisation was a heatmap for the frequency of co-occurrences. A Lollipop plot combined the frequency with the overlap time. Then a Shiny App made interactive exploration of up to 4 co-occurring events possible. The presentation of an UpSet plot brought up a discussion on the advantages over the vinn diagram. The shiny app AdEPro was referred to as an useful exploration tool for adverse event in general. Another tool for exploring the co-occurrence in particular was the force directed network graph. The final approach was embedded in a PowerBI Dashboard.",
    "author": [
      {
        "name": "Steve Mallett",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2020-10-14",
    "categories": [
      "Adverse events",
      "Co-occurence",
      "Wonderful Wednesdays"
    ],
    "contents": "\nAdverse Event Co-Occurrence Challenge\nThis month’s challenge was based on a clinical trial for the treatment of Type II diabetes in adults that cannot manage their blood glucose control with a single oral therapy. The primary outcome in the trial was mean HbA1c at 6 months, and adverse events (AEs) were monitored and collected for the entire course of the study.\nThe data visualisation objectives were focussed on AEs, and were defined as follows:\nTo quickly identify groupings of AEs that occur in the same patients at the same time in Treatment A.\nDo these groupings occur in Treatment B?\nIs there a difference based on sex?\nAre adverse events in these groupings severe?\nThe dataset is available here.\n\nExample 1. Heat Map\n\nIncluded here is one of two heat map charts that were submitted. The graph shows pairs of AE terms represented as a grid, with one of each pair included on either the horizontal or vertical axis, and with the frequency of co-occurrences of each pair of terms being colour-coded. The plot shows quite clearly that Nausea and Vomiting are terms that co-occur at the highest frequency.\nThe judging panel suggested a few possible enhancements. There is quite a lot of white space in this plot, and it was felt this plot might be more useful for exploring a larger dataset containing many co-occurring terms. It would then be useful to be able to limit the data displayed to only include pairs of terms with a frequency above a cut-off value, to focus on the more prevalent co-occurrences. A more meaningful method of sorting the AE terms might also be helpful. A comment was made that the eye tends to be drawn towards the dark blue areas of the plot, whereas these only represent a relatively small number of patients. The real “story” in this plot, i.e. co-occurrence of Nausea/Vomiting, would perhaps come through more strongly if darker tones were used for increasing frequency. Also, adding some additional contextual information to the plot would help the user to better understand what is being shown (for example that the frequency relates to co-occurrences of the pairs of AE terms.)\nA general comment on heatmaps is that representing a variable on a continuous colour scale can make it difficult for the user to accurately translate the frequencies into a quantitative value. Therefore a further enhancement might be to create ordered categories for frequency of occurrence, comprising perhaps 5-7 bins.\nlink to code\n\nExample 2. Lollipop Chart\n\nThis plot also shows the frequencies of co-occurring pairs of AE terms, but includes the additional dimension of showing the median time of co-occurrence as a lollipop chart. When representing a quantitative measure as the distance along an axis, common choices of chart type are often either bar charts or dot plots. The latter is sometimes preferred because of the lower “data to ink ratio” (as proposed by Edward Tufte) which may produce a plot with a clearer message. The lollipop chart is a compromise between these two options, where the length of the “stick” represents, in this case, the median overlap time. This leads to the possibility of using the stick to encode an additional variable, e.g. adding colour or line thickness, although care would be needed not to overcomplicate the graph.\nThe panel appreciated the fact that the title includes the key message that the chart is communicating. An enhancement might be to remove the “n=” labels above each “lollipop”, as this information is already encoded in the size of the bubble, and would produce a cleaner looking plot. Also, the switching to a vertical format would make the labels easier to read, and meaningful sorting (e.g. by bubble size or median overlap) would enhance the chart. Also, perhaps applying a cut-off value (e.g. to remove the pairs of terms that only co-occur in a single patient) would be helpful. The above features are seen in some of the other submitted graphs (for example the Shiny App described in the next section). The graph is not providing a comparison of the two treatment groups, so this would be a further enhancement (e.g. splitting the graph into two panels in a vertical format).\nlink to code\n\nExample 3. RShiny App\n\nThis Shiny App can be accessed by clicking here. The previous plots have focussed on pairs of co-occurring AE terms, but this app provides the ability to choose the number of co-occurring terms, i.e. 2-4 terms. The initial screen displays diverging bar charts, showing mean duration of co-occurring terms on the left side and number of patients with overlapping occurrences on the right side, split by treatment group. The AE terms can be sorted by mean duration or frequency of co-occurrences, and the data can also be split by treatment and gender. The app can also display individual patient-level profiles with various display and filtering options.\nThe app was well received as a very useful and flexible tool for exploring the data. One of the design features that were appreciated included the inclusion of the statistic at the end of the bars. For the diverging bar charts, a legend is shown representing treatment group categories, but this colour-coding only seems to apply to the right-hand side of the diverging bar chart, i.e. showing the frequency of co-occurrences. However it wasn’t clear whether bar chart on left-hand side, showing the mean duration, were also split by treatment, and if so, what colour-coding scheme would apply to this part of the chart. (This is not clear because no combinations of AE terms occurred in more than one treatment group)\nA further enhancement might be for the user to be able to choose cut-off values for the number of co-occurring terms (e.g. >=2 terms, >=3 terms) rather than having to choose the exact number of terms. A further comment on the design is that the numbers at the top of the screen, showing the total number of patients and total number of AEs occurring at the same time, are disproportionately large and reminiscent of an “infographic” style (which is not popular with some members of the panel). These numbers could be moved elsewhere (e.g. panel on the left containing a lot of blank space) to draw more attention to the main plot.\n\nExample 4. Upset Plot\n\nThis is a useful plot for displaying frequency counts where there is interest in the intersections of different categories, having a similar function to a Venn diagram but being much more practical where there are more than three categories. (It will always be possible to produce an Upset plot, regardless of the number of categories, whereas a Venn diagram quickly becomes impossible to produce or interpret beyond 4 or 5 categories.) The vertical bar chart shows the size of the various intersections (which is highlighting that Nausea and Vomiting is the most frequently-occurring pair of terms), and the horizontal bar chart shows the frequency of each individual category (showing that overall, Nasopharyngitis, Nausea and Vomiting are the most frequent, with a dramatic drop-off in the frequencies of other terms).\nThe plot requires a fair amount of explanation, and would work well with stakeholders who are already familiar with the format. It wouldn’t work so well at a conference, for example, where there isn’t the opportunity to explain the graph. Improved labelling (e.g. interpretation of “Intersection Size”) would make the graph easier to understand.\nWhere there is a large number of categories (as in this example), displaying all of the combinations of categories is limited by the display area of the plot. In this case a “cut-off” has been applied to limit to an intersection size of 20. Ideally the graph would include interactivity, to allow the user to define which categories are displayed. In addition, the aspect ratio is challenging to display in a landscape screen, so flexibility in the layout of the various charts would be useful.\nlink to code\n\nExample 5. ADEPRO\n\nThis app provides interactive exploration of AE data at the individual patient level. Each patient is represented as a grey circle, with coloured wedges within each circle mapped to different adverse event terms. Clicking the play button starts an animation running, with the elapsed time since the start of the study shown as a blue bar at the top of the screen. As time progresses, filled coloured wedges appear within the grey circles at the appropriate time of onset of each respective AE. Coloured outline wedges represents AEs have occurred at a previous time during the study but have resolved.\nApplying this app to the current challenge, co-occurring AE terms can be viewed by running the animation and observing circles with more than one coloured wedge at the same time. The outlined wedges, representing resolved AEs, did not necessarily co-occur, so the app relies on the user manually identifying the co-occurring AEs in real time as the animation progresses. The app doesn’t provide an overall summary, so requires some input from the user to produce any required statistics, e.g. frequency counts, after viewing the animation.\nlink to code\n\nExample 6. Network\n\nThe network diagram shown is a screenshot from an interactive app, which produces a network diagram displaying AE terms as nodes. The size of each node represents the incidence rate, and nodes are connected according to whether they co-occur in the same subject. The thickness of the lines represents the strength of the association in terms of frequency of co-occurrences. The nodes are colour-coded to represent the severity of the AEs. When each node in the network is clicked on, this displays all other AE terms that co-occurred with the selected term. The app also includes options for filtering the data, selecting the minimum and maximum frequency, and also defining the time window used for co-occurrences (e.g. AEs at exactly the same , within a +/- 2 day window etc.). Further filter options include severity and gender. The app also includes useful display options, e.g. font size.\nAlthough the plot is visually complex in terms of the large number of AE terms with overlapping terms and many connecting lines, in this case the message is quite clear because only four AE terms are dominant in the graph.\n\nExample 7. Apriori Algorithm\n\nThis is an example of a Power BI dashboard, with a set of interactive filters on the left part of the screen, and right panel displaying the output from an algorithm called Apriori. The right panel displays a series of coloured nodes of varying size and colour saturation, and with arrows entering and leaving the circles at various points. The dynamic updating of the plot, by clicking on the filters, was a useful feature that was appreciated by the panel, as were several aspect of the design that are visually appealing and quite effective.\nHowever the algorithm behind the plot was not familiar to the panel, who therefore struggled to interpret the message behind the graph. It was concerning that some of the associations that were strongly identified in some of the other plots (e.g. strong co-occurrence of Nausea and Vomiting) was not clearly shown in this plot.\nCode\n\nExamples 1 and 2. Heat Map and Lollipop Plot\n\n\nlibrary(tidyverse)\n#Colour scheme\nOrange <- \"#EF7F04\"\nGreen <- \"#68B937\"\nBlue <- \"#00A6CB\"\nGrey <- \"#4E5053\"\nDarkblue <- \"#003569\"\nYellow <- \"#FFBB2D\" \nGreyedOut <- \"#D3D3D3\"\n\nsetwd(\"C:/Users/Q1062810/Documents/Wonderful Wednesday/AE2\")\n\n# Read in the data and make a unique subject ID based on the subjid and treatment\nAE <- read.csv(\"AE.csv\") %>%\n  mutate(USUBJID = paste(Treatment, Subject, sep = '_')) %>%\n  mutate(Adverse = as.character(Adverse))\n\n#Make a dataset where subjects have more than one event (because we are looking for co-occurring events)\nAE_events <- AE %>%\n  group_by(USUBJID) %>%\n  filter(n() > 1) %>%\n  ungroup() %>%\n  select(c(2,4,5,7,8,9)) %>% # Select the columns we care about\n  rename(Adverse2=Adverse) %>% # Rename all the relevant variables  with a \"2\" as we will merge these back on to the initial dataset \n  rename(Start2 = Start) %>%\n  rename(End2=End) %>%\n  rename(System2=System) %>%\n  rename(Severity2=Severity)\n  \n# Match merge the filtered data set onto the original data set by subject ID. \n# This gives us a data set which has every combination of AEs for all subjects which have more than 1 AE\nAE_combined <- left_join(AE,AE_events) %>%\n  rownames_to_column(\"combination_ID\") %>%\n  mutate(overlap = if_else(condition = Start >= Start2 & Start <= End2,true = 1, # Makes a flag to capture the events with overlap\n                           false = if_else(condition=End >= Start2 & End <= End2, true = 1, \n                                           false = if_else(condition=Start2 >= Start & Start2 <= End, true = 1,\n                                                           if_else(condition=End2 >= Start & End2 <= End, true = 1,false = 0))))) %>%\n  mutate(different = if_else(condition= Adverse==Adverse2,true = 0,false = 1)) %>% # Makes a flag for all events where the AEs are duplicated as part of the merge process. this helps us remove these events\n  mutate(Co_start = pmax(Start,Start2)) %>% \n  mutate(Co_end = pmin(End,End2)) %>%\n  mutate(Time =Co_end - Co_start) %>% # Create a variable representing total overlap time\n  filter(overlap==1 & different==1) %>% # filter just overlapping AEs  \n  select(c(\"USUBJID\",\"Adverse\",\"Adverse2\", \"Time\",\"Treatment\")) %>% # Select relevant columns\n  arrange(Adverse,Adverse2)\n\n\n\nlibrary(plyr)\nAE_crosstab <- count(AE_combined, c('Adverse','Adverse2'))\n\n\n\nplot <- ggplot(data = AE_crosstab, mapping = aes(x = Adverse,\n                                       y = Adverse2,\n                                       fill = freq)) +\n  geom_tile() +\n  xlab(label = \"Adverse Event Name\") +\n  ylab(label = \"Adverse Event Name\") +\n  theme(axis.text.x = element_text(angle =90, vjust =0.5, hjust=1))\n\n\nplot \nggsave(\"Co-occurance heat map v1.png\",width = 35, height = 20, units = \"cm\")\n\n#create function to sort within rows and make new var\nf = function(x,y) {paste(sort(c(x, y)), collapse = \" - \")}\nf = Vectorize(f)\n\n\nAE_crosstab <- AE_crosstab %>% mutate(dedup = f(Adverse, Adverse2))  %>%\n  distinct(dedup, .keep_all=TRUE) %>%\n  select(-dedup)\n\nplot2 <- ggplot(data = AE_crosstab, mapping = aes(x = Adverse,\n                                                 y = Adverse2,\n                                                 fill = freq)) +\n  geom_tile() +\n  xlab(label = \"Adverse Event Name\") +\n  ylab(label = \"Adverse Event Name\") +\n  theme_classic() +\n  theme(axis.text.x = element_text(angle =90,size=12, vjust =0.5, hjust=1, face=\"bold\"), axis.text.y = element_text(size=14, face=\"bold\"))+\n  theme(plot.title = element_text(size=22)) +\n  theme(plot.subtitle = element_text(size=15)) +\n  theme(axis.title=element_text(size=14,face=\"bold\"))\n\nplot2\n\nggsave(\"Co-occurance heat map v2.png\",width = 35, height = 20, units = \"cm\")\n\n######TRY GGCORRPLOT #############\n\nAE_combined2 <- AE_combined %>% mutate(dedup = f(Adverse, Adverse2)) %>%\n  arrange(dedup,Time) %>% \n  group_by(USUBJID) %>%\n  distinct(dedup, .keep_all=TRUE)%>%\n  ungroup() %>%\n  group_by(dedup) %>%\n  mutate(position=rank(Time,ties.method = \"first\")) %>%\n  ungroup() %>%\n  rownames_to_column(\"Row\")%>%\n  mutate(Row=as.integer(Row))\n\nAE_combined3 <- AE_combined %>% mutate(dedup = f(Adverse, Adverse2)) %>%\n  arrange(dedup,Time) %>% \n  group_by(USUBJID) %>%\n  distinct(dedup, .keep_all=TRUE)%>%\n  ungroup() %>%\n  group_by(dedup) %>%\n  dplyr::summarise(Median_time = median(Time), patients = n()) %>%\n  ungroup() \n # %>%\n # filter(dedup!=\"Nausea - Vomiting\")\n\n\ndata_label <- paste(\"n=\",AE_combined3$patients,sep=\"\")\n\nplot5 <- ggplot(data = AE_combined3, mapping = aes(x = dedup,\n                                                  y = Median_time)) +\n  geom_segment(aes(x=dedup, xend=dedup, y=0, yend=Median_time)) +\n  geom_point(aes(size=patients), color=Darkblue, fill=ggplot2::alpha(Green, 0.3), alpha=0.7, shape=21, stroke=2) +\n  scale_size_area(max_size = 15) +\n  geom_text(aes(label=data_label),size=4, vjust=-2.5, fontface=\"bold\") +\n  ylim(0, 22)+\n  labs(y= \"Median Overlap of Adverse Events (days)\", x = \"Adverse Event Pairs\", title=\"The median length of time that adverse events co-occur together\", subtitle = \"Of all AE pairs, Nausea and Vomitting consistently co-occured with one another, but had a low median co-occurance (< 5 days)\") +\n  theme_classic() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle =90,size=12, vjust =0.5, hjust=1, face=\"bold\"), axis.text.y = element_text(size=14, face=\"bold\"))+\n  theme(plot.title = element_text(size=22)) +\n  theme(plot.subtitle = element_text(size=15)) +\n  theme(axis.title=element_text(size=14,face=\"bold\"))\n\n\nplot5 \n\nggsave(\"Co-occurance v2.png\",width = 35, height = 20, units = \"cm\")\n\nAE_combined4 <- AE_combined3 %>%\n  group_by(patients) %>%\n  arrange(Median_time) %>%\n  rownames_to_column()\n\nplot6 <- ggplot(data = AE_combined4, mapping = aes(x = dedup,\n                                                   y = Median_time)) +\n  geom_segment(aes(x=reorder(dedup, rowname), xend=dedup, y=0, yend=Median_time)) +\n  geom_point(aes(x=reorder(dedup, rowname), size=patients), color=Darkblue, fill=ggplot2::alpha(Green, 0.3), alpha=0.7, shape=21, stroke=2) +\n  scale_size_area(max_size = 15) +\n  geom_text(aes(x=reorder(dedup, rowname),label=data_label),size=4, vjust=-2.5, fontface=\"bold\") +\n  ylim(0, 22)+\n  labs(y= \"Median Overlap of Adverse Events (days)\", x = \"Adverse Event Pairs\", title=\"The median length of time that adverse events co-occur together\", subtitle = \"Of all AE pairs, Nausea and Vomitting consistently co-occured with one another, but had a low median co-occurance (< 5 days)\") +\n  theme_classic() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle =90,size=12, vjust =0.5, hjust=1, face=\"bold\"), axis.text.y = element_text(size=14, face=\"bold\"))+\n  theme(plot.title = element_text(size=22)) +\n  theme(plot.subtitle = element_text(size=15)) +\n  theme(axis.title=element_text(size=14,face=\"bold\"))\n\nBack to blog\n\nExample 4. Upset Plot\n\n\n# packages\npacman::p_load(tidyverse, rio)\npacman::p_load(labelled)\n# devtools::install_github(\"krassowski/complex-upset\")\nlibrary(ComplexUpset)\n\n# import & recode ID & sort\nae <- import(\"https://raw.githubusercontent.com/VIS-SIG/Wonderful-Wednesdays/master/data/2020/2020-09-09/2020-09-09-fake-data_aes.csv\") %>% \n   mutate(id = str_remove(Subject,\"FAKE-DATA-\") %>% \n             as.numeric(), \n          .after = Subject) %>% \n   arrange(id)\n\n# 1 Duplicate\nae   %>% filter(id == 10084) %>% filter(`Adverse Event` == \"Diarrhea\")\n\n# Remove Duplicate\nae <- ae %>% \n   distinct()\n\n# export fixed file\nae %>% \n   export(\"C:/R/Wonderful-Wednesdays/2020-09-09/2020-09-09-fake-data_aes.csv.rds\")\n\n# extend to all days between adverse events\nae_l <- ae %>% \n   select(-Subject) %>% \n   pivot_longer(cols = 2:3,\n                values_to = \"day\") %>% \n   group_by(id, `Adverse Event`, `Treatment`, System, Severity, Sex ) %>% \n   complete(day = seq(min(day), max(day), by = 1)) %>% \n   select(-name) %>% \n   ungroup() %>% \n   arrange(id, day)\n\n# Add variables to wide data\nae_w2 <- ae_l %>% \n   select(id, day, Sex, Treatment, Severity, `Adverse Event`) %>%\n   mutate(value = 1) %>%\n   pivot_wider(id_cols = c(\"id\",\"day\",\"Treatment\",\"Sex\"),\n               names_from = \"Adverse Event\",\n               values_from = \"value\",\n               values_fill  = 0) %>% \n   mutate(Treatment = factor(Treatment, labels = c(\"A\",\"B\")))\n# You cannot do the analysis using severity because at each day there can be diverse severerities for\n# different AE's overalapping\n\n# Figure 2.1\nupset(\n   data = ae_w2,\n   intersect = names(ae_w2)[-c(1:4)],\n   min_size = 20,\n   width_ratio = 0.25,\n   height_ratio = 1,\n   name  = NULL,\n   queries=list(\n      upset_query(\n         intersect=c(\"Nausea\",\"Vomiting\"),\n         color=  \"#E41A1C\",\n         fill  =  \"#E41A1C\",\n         \n         only_components=c('intersections_matrix', 'Intersection size')\n      )\n   ),\n   annotations = list(\n      'Intersection Size\\n(Treatment %)' = list(\n         aes = aes(x=intersection, fill=Treatment ),\n         geom = list(\n            geom_bar(stat='count', position='fill'),\n            geom_hline(yintercept = 0.5, col='gray90'),\n            scale_y_continuous(labels=scales::percent_format()),\n            scale_fill_brewer(palette = \"Dark2\")\n         )\n      ),\n      'Intersection Size\\n(Sex %)' = list(\n         aes = aes(x=intersection, fill=Sex),\n         geom = list(\n            geom_bar(stat='count', position='fill'),\n            geom_hline(yintercept = 0.5, col='gray90'),\n            scale_y_continuous(labels=scales::percent_format()),\n            scale_fill_manual(values = c(\"#E78AC3\",\"#8DA0CB\"))\n         )\n      )\n   ),\n   themes=upset_modify_themes(\n      list('overall_sizes'= theme(axis.ticks.x = element_line()))\n   )\n) +\n   labs(title = 'Co-Occurence of Daily AE Symptoms',\n        caption = 'Symptoms with more than 20 days by Frequency: Total pool is 148 individuals for 2575 Daily AE Symptoms \\n Lex, Alexander, et al. \"UpSet: visualization of intersecting sets.\" IEEE transactions on visualization and computer graphics 20.12 (2014): 1983-1992.') +\n   ggsave(\"C:/R/Wonderful-Wednesdays/2020-09-09/UpSet_plot.png\",\n          width = 11, height =10, units = \"in\")\n\nBack to blog\n\nExample 5. ADEPRO\n\n\n##########################################################################################\n## AdEPro for Wonderful Wednesday Webinar                                               ##\n## Main purpose of this program: Restructure the example dataset to read it into AdEPro ##\n##########################################################################################\n\n# setwd(\"\") # insert link to working directory\n\n# read dataset and attribute column names\ndat <- read.csv(\"2020-09-09-fake-data_aes.csv\", sep=\";\", header=TRUE)\ncolnames(dat) <- c(\"SUBJID\", \"AESTDY\", \"AEENDY\", \"AEDECOD\", \"TRT01A\", \"SOC\", \"AESEV\", \"SEX\")\n\nn <- nrow(dat) # number of rows in dataset\n\n## AE intensity must be numeric/integer and missing intensities are imputed with Moderate (2)\nAESEVN <- as.integer(dat$AESEV); AESEVN[is.na(AESEVN)] <- 2\n\n# Subject ID is not unique per treatment group, therefore the Subject ID receives a leading one for treatment A,\n# and a leading 2 for treatment B, and only the numeric part of the original name is kept\nTRT <- as.numeric(dat$TRT01A)\nSJ <- substr(dat$SUBJID, 11, 15)\nSUBJIDN <- as.integer(sapply(1:n, function(x) as.numeric(paste(TRT[x],SJ[x],sep=\"\"))))\n\n# other required variables for AdEPro are added: safety analysis set flag (assumed as Yes), death date (always missing),\n# last visit date (date of overall last AE end date for all patients), treatment start date (set to 1 for all patients),\n# treatment-emergent, serious and study drug related flag (always assumed as Yes)\ndat.rest <- data.frame(SAFFN=as.integer(rep(1,n)), DTHDT=as.factor(rep(\".\",n)), LVDT=rep(max(dat$AEENDY),n), \n                       TRTSDT=as.integer(rep(1,n)),\n                       SUBJIDN=SUBJIDN, AETRTEMN=as.integer(rep(1,n)), AESEVN=AESEVN, \n                       AESERN=as.integer(rep(1,n)), AERELN=as.integer(rep(1,n)))\n\n# merge all together and write out AE dataset\ndat_all <- cbind(dat, dat.rest)[,c(13,4,2,3,15,14,5,12,11,10,8,9,1,16,17)]\nwrite.csv(dat_all, file=\"2020-09-09-fake-data_aes_modified.csv\", row.names=FALSE, na=\".\")\n# the generated dataset should be used under \"Upload Adverse Event data\" after starting the adepro app\n\n\n# create additional subject level dataset to get all combinations of subject ID and treatment group \n\nsubjects <- sort(unique(SJ)); N <- length(subjects) # all unique subjects\nsubjects_trt <- c(paste(1,subjects,sep=\"\"),paste(2,subjects,sep=\"\")) # all combinations subjects - treatment\nsubjects2 <- rep(paste(\"FAKE-DATA-\",subjects,sep=\"\"),2)\n\n# get all AE data to merge with subject-treatment combinations\ndat_all_sub <- unique(dat_all[,c(8:13)])\ndat_sj0 <- data.frame(SUBJIDN=subjects_trt, SUBJID=subjects2,\n                      TRT01A=rep(c(\"Treatment A\", \"Treatment B\"), each=N))\ndat_sj <- merge(dat_sj0, dat_all_sub, by = \"SUBJID\")\n\nwrite.csv(dat_sj, file=\"2020-09-09-fake-data_subjects.csv\", row.names=FALSE, na=\".\")\n# the generated dataset should be used under \"Upload Subject Level data\" after starting the adepro app\n\n\n# Load AdEPro\nlibrary(adepro)\nlaunch_adepro() # launches the adepro app\n# after the page is loaded, one can upload the adverse event and subject level dataset in the \"Upload data\" panel\n\nBack to blog\n\n\n",
    "preview": "posts/2020-10-21-wonderful-wednesdays-october-2020/./images/plot01.png",
    "last_modified": "2020-10-30T20:09:38+01:00",
    "input_file": {},
    "preview_width": 4133,
    "preview_height": 2362
  },
  {
    "path": "posts/2020-10-17-wonderful-wednesdays-september-2020/",
    "title": "Wonderful Wednesdays September 2020",
    "description": "How to display safety data? This month's challenge has shown there are very different ways to visualize adverse event data. Although the example data set was from a two-arm study and relatively simple, the display of type of AE, frequency, timing, severity and seriousness is not easily combined in one plot.",
    "author": [
      {
        "name": "Lorenz Uhlmann",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2020-09-10",
    "categories": [
      "Adverse events",
      "Wonderful Wednesdays"
    ],
    "contents": "\nAdverse event example data set\nThe adverse events (AEs) example data set is based on a clinical trial for treatment of Type II diabetes in adults that cannot manage their blood glucose control with a single oral therapy. The primary outcome was mean HbA1c at 6 months. AEs were monitored and collected for the entire course of the study. A more detailed description and link to the data can be found here.\n\nExample 1. Triangles, pie chart, boxplots\n\nThis visualisation has been submitted as an html file and can be found here. It is a compilation of three different plots. The first one shows a triangle for each AE where the height of the triangle represents the duration of the AE. The x axis, represents a time axis. Furthermore, we the AEs are split into three categories based on the severity: mild, moderate, and severe. Each categories is plotted in a separate line of the plot. The treatment group (placebo vs. intervention) is color-coded. One additional feature is the hover over effect which provides some useful additional information.\nThis is a very innovative plot and not common for representing AEs. The title covers the message of the plot and, hence, it is very helpful. Additionally, there is a subtitle which provides some additional useful information even though the second part (saying that severe AEs were resolved the quickest) cannot be seen clearly from the plot.\nUsing the height of the triangles to represent the duration is a bit challenging because we already have the x axis representing the time. Having that said, we see that the x axis (date of the AE) is not ordered chronologically. This is a bit surprising and it is not clear what the dates are ordered by. The alpha scaling that has been used in a sensible way to make all triangles visible.\nThe second visualisation is similar to a pie chart in its appearance. There is a lot of information included in this plot. We see all AEs represented in categories. it also provides a hover over functionality which gives you some more information.\nThe advantage of this plot is that it shows a lot of information in a very compact design. However, since it is a round design, it is a little bit hard to compare the height of the bars. So, it comes with some challenges, but it is definitely eye-catching.\nThe third visualisation is a pair of boxplots comparing the two treatment groups in terms of the duration of AEs. It is a rather “simple” or standard plot. It is often a good idea to keep it simple, so there is definitely nothing wrong with it. In addition, there are dots included which are be color-coded and seem to represent the frequency of the events. One comment would be that the type of AEs is not being considered in this plot. So, it might be a good idea to stratify this plot by system organ class.\nlink to code\n\nExample 2. Triangles - updated version\nhigh-resolution image\nThis visualisation is ment to be an update of the first visualisation of Example 1. The main update is that the x axis is used as a time axis in chronological order. Now, the width of the triangles is being used to represent the duration of the AEs. The height represents the severity. Furthermore, the treatment group is represented by color and also by the direction the triangle point to. This is not a fully developed plot but rather a quick draft to show what it could look like updated some design features of the original plot.\nlink to code\n\nExample 3. Tendril plot\n\nhigh-resolution image\nThis is a very innovative visualisation. It is presented in a publication from 2018. You can see branches which represent one AE each. The branch itself represents the time path. Changes to the direction of the path depend on the treatment arm the AE occured in. Thus, it is kind of a car driving experience and it depends on the occurence of AE in each treatment arm where you end up.\nIn this plot, the paths are color coded and each branch represents a body system (and not only one single type of AE). Looking at the pink path (representing blood and lymphatic), we see that in the beginning, most of the AEs occur in the placebo, later on we see a lot more AEs occuring in the treatment group and, thus, the path ends up far to the right.\nOne comment is some AEs might become very influential if they happen at a rather late point in time. Furthermore, a hover over function (or some other type of interactivity) might make the plot very powerful. Also, the color coding could be used differently, for example, to represent the odds ratio.\nlink to code\n\nExample 4. AdEPro app\n\nThis is definitely more than just a visualisation - it’s a tool. You can upload your data and all AEs are represented in the middle pane. Each patient is represented by a circle / pie chart. You can kick it off by pushing the go button and the app will show you the development of AEs over time. Each AE is represented by a “slice of the pie” and the color as well as the location of it will tell you which AE is showing. If an AE disappears, it will still be shown as an “empty slice”. The size of the slice represents the severity. You have several different options you can work with, like changing which AEs will be shown (color coded), stop at a specific point in time, etc. You can even switch to a barplot representation instead of pie charts.\nThis is a fully developed app and thus, it is very useful and innovative. Its interactivity brings additional benefits to the user. Furthermore, this is available as an R package called “AdEPro”.\nlink to code\n\nExample 5. Adverse event explorer\n\nThis is again an interactive app. It can be found here. It shows a list of categories of AEs. You can see the results in the different treatment groups in different colors. Furthermore, the freqzency and the treatment difference is represented by dots and an treatment effect with a confidence interval, respectively. You can click on the plus sign next to the categories to further assess the AEs in more detail. You can find more details about the AE explorer here.\nIt is a very clear representation of AEs. The coloring is very straightforward and helpful. It is a tool to explore the data and thus, it does not come with a message by itself. However, this is not the aim of this tool. It is made to “play” with the data and assess your AEs in a very efficient way. Something that might be a useful extension would be addition of reference lines to make it easier to see which results correspond to which category or AE.\nlink to code\n\nExample 6. Volcano plots\n\n\nhigh-resolution imagehigh-resolution image\nIt is an innovative idea to use this plot to visualise AE data. On the x axis we see the risk difference and on the y axis, the p-values are represented. The colors represent the treatment group and the saturation of the color corresponds to the p-value as well. The size of the dots is proportional to the number of events (in both arms). It is a very comprehensive and nice overview over the results.\nOne comment is that the colors might be switched, because the red one are might be seen as the more critical ones. However, those correspond to increased risk in the placebo group.\nlink to code\nCode\n\nExample 1. Triangles, pie chart, boxplots (html)\n\n\n<!doctype html>\n<html lang=\"en\">\n  <head>\n    <!-- Required meta tags -->\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n    <title>Visualizing eczema trial data<\/title>\n\n    <!-- Bootstrap CSS/JS/then Popper.js -->\n    <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css\" integrity=\"sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T\" crossorigin=\"anonymous\">\n    <script src=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js\" integrity=\"sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM\" crossorigin=\"anonymous\"><\/script>\n    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js\" integrity=\"sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1\" crossorigin=\"anonymous\"><\/script>\n\n    <!-- Load D3 -->\n    <script src=\"https://d3js.org/d3.v4.min.js\"><\/script>\n\n    <!-- load fonts -->\n    <link href=\"https://fonts.googleapis.com/css2?family=PT+Sans:ital,wght@0,400;0,700;1,400;1,700&family=PT+Serif:ital,wght@0,400;0,700;1,400&display=swap\" rel=\"stylesheet\">\n\n    <!-- Embed Flourish graphics -->\n    <script src=\"https://public.flourish.studio/resources/embed.js\"><\/script>\n\n    <!-- css -->\n    <style>\n            .path.domain {\n              display: none;\n            }\n            .label {\n              font-size: 10px;\n              font-family: sans-serif;\n              text-anchor: middle;\n            }\n\n          #tooltip  {\n           position: absolute;\n            height: auto;\n            padding: 10px;\n            background-color: rgba(255,255,255,0.7);\n              border-radius: 3px;\n            pointer-events: none;\n          }\n\n          #tooltip.hidden {\n            display: none;\n          }\n\n          #tooltip p  {\n            margin: 0;\n            font-size: 14px;\n            line-height: 18px;\n          }\n\n          #container  {\n            position: inherit;\n          }\n\n          .graph-hed{\n            font-family: 'PT Serif', serif;\n            font-size: 0.90rem;\n            font-weight: 700;\n          }\n\n          .graph-subhed{\n            font-family: 'PT Serif', sans-serif;\n            font-size: 0.80rem;\n            font-weight: 400;\n          }\n\n          .hed  {\n            font-family: 'PT Serif', serif;\n            font-size: 2.25rem;\n            font-weight: 700;\n            text-align: center;\n            width: 70%;\n          }\n\n          .byline {\n            font-family: 'PT Sans', sans-serif;\n            font-size: 1rem;\n            font-style: italic;\n          }\n\n          .insight  {\n            font-family: 'PT Sans', sans-serif;\n            font-size: 1.2rem;\n            font-style: italic;\n            text-transform: uppercase;\n          }\n\n          .copy {\n            font-family: 'PT Sans', serif;\n            font-size: 1rem;\n            font-weight: 400;\n          }\n\n          .copy-link  {\n            border-bottom: 2px solid black;\n            color: black;\n          }\n\n          .copy-link:hover  {\n            border-bottom: 2px solid #cc0000;\n            color: #cc0000;\n            text-decoration: none;\n          }\n    <\/style>\n\n    <\/head>\n\n    <body>\n      <div class=\"container\" style=\"padding-top: 5%;\"><\/div>\n\n      <div class=\"container-fluid\">\n        <div class=\"row d-flex justify-content-center\" style=\"margin-bottom: 0px;\">\n          <p class=\"hed\">Analysis finds intervention treatment arm takes longer, on average, to resolve adverse events<\/p>\n        <\/div>\n\n        <div class=\"row d-flex justify-content-center\">\n        <div id=\"container\"><\/div>\n\n          <!-- place for tooltip -->\n          <div id=\"tooltip\" class=\"hidden\"><\/div>\n\n          <script>\n                var margin = {top: 100, right: 40, bottom: 250, left: 150},\n                    width = 1440 - margin.left - margin.right,\n                    height = 650 - margin.top - margin.bottom;\n\n                var overlap = 15;\n\n                var x = d3.scaleBand()\n                          .range([0, width])\n                          .padding(0.1);\n                var y = d3.scaleLinear()\n                          .range([height, 2*height/3]);\n\n                var svg = d3.select(\"#container\")\n                    .append(\"svg\")\n                    .attr(\"width\", width + margin.left + margin.right)\n                    .attr(\"height\", height + margin.top + margin.bottom)\n                    .append(\"g\")\n                    .attr(\"transform\",\n                          \"translate(\" + margin.left + \",\" + margin.top + \")\");\n\n                //create labels for each of the horizontal axes, i.e. Mild, Moderate, Severe\n                svg.append(\"text\")\n                   .text(\"Mild\")\n                   .attr(\"transform\",\n                        \"translate(\" + (-65) + \",\" + \"60)\");\n\n                svg.append(\"text\")\n                   .text(\"Moderate\")\n                   .attr(\"transform\",\n                        \"translate(\" + (-95) + \",\" + \"170)\");\n\n                svg.append(\"text\")\n                   .text(\"Severe\")\n                   .attr(\"transform\",\n                        \"translate(\" + (-70) + \",\" + \"275)\");\n\n                //graph-hed\n                svg.append(\"text\")\n                   .text(\"=> Most adverse events were mild in severity, while severe adverse events were resolved the quickest.\")\n                   .attr(\"x\", \"0\")\n                   .attr(\"y\", 0-2*height/7+25)\n                   .classed(\"graph-hed\", true);\n\n               //graph-hed\n               svg.append(\"text\")\n                  .text(\"Height of triangle represents duration of adverse event.\")\n                  .attr(\"x\", \"20\")\n                  .attr(\"y\", 0-2*height/7+45)\n                  .classed(\"graph-subhed\", true);\n\n                //create Placebo label\n                svg.append(\"text\")\n                   .text(\"Placebo\")\n                   .attr(\"x\", width-225)\n                   .attr(\"y\", 0-2*height/7+43);\n\n                //create placebo box (red)\n                svg.append(\"rect\")\n                   .attr(\"x\", width-250)\n                   .attr(\"y\", 0-2*height/7+30)\n                   .attr(\"fill\", \"rgba(255,0,0,0.2)\")\n                   .attr(\"height\", \"15px\")\n                   .attr(\"width\", \"15px\");\n\n              //create Intervention label\n               svg.append(\"text\")\n                  .text(\"Intervention\")\n                  .attr(\"x\", width-125)\n                  .attr(\"y\", 0-2*height/7+43);\n\n                //create box for Intervention (black/gray)\n                 svg.append(\"rect\")\n                    .attr(\"x\", width-145)\n                    .attr(\"y\", 0-2*height/7+30)\n                    .attr(\"fill\", \"rgba(0,0,0,0.2)\")\n                    .attr(\"height\", \"15px\")\n                    .attr(\"width\", \"15px\");\n\n                    //load data from GitHub\n                d3.csv(\"https://raw.githubusercontent.com/vivrao9/Wonderful-Wednesdays/master/data/2020/2020-08-12/cleaned_df.csv\", function(error, data) {\n                      if (error) throw error;\n\n                      //format data accordingly\n                      data.forEach(function(d) {\n                        d.severity = +d.severity;\n                        d.aestdat = d3.timeParse(\"%d/%m/%Y\")(d.aestdat);\n                        d.aestdat = d3.timeFormat(\"%m/%d/%Y\")(d.aestdat);\n                        d.dur = +d.dur;\n                        d.armn = +d.armn;\n                      });\n\n                      x.domain(data.map(function(d) { return d.aestdat; }));\n                      y.domain([0, d3.max(data, function(d) { return d.severity; })/3.5]); //divide by 3.5 to add more scale to triangle heights\n\n                      svg.selectAll(\".bar\")\n                          .data(data)\n                          .enter()\n                          .append(\"polygon\")\n                          .attr(\"points\",function(d) {\n\n                            //create different coordinates for each polygon based on which axis they lie on\n                              if (d.aesevn == 1)  { //if Mild, we'd want to add bar to the first axis\n                                var left = x(d.aestdat) - overlap;\n                                var top = y(d.dur + height/11.25);\n                                var bottom = height/3; //350 = 500 - 100 - 50\n                              } else if (d.aesevn == 2) { //if Moderate, add bar to second axis\n                                var left = x(d.aestdat) - overlap;\n                                var top = y(d.dur + height/22);\n                                var bottom = 2*height/3; //350 = 500 - 100 - 50\n                              } else  { //if Severe, we'd want to add bar to the third axis\n                                var left = x(d.aestdat) - overlap;\n                                var top = y(d.dur);\n                                var bottom = height; //350 = 500 - 100 - 50\n                              }\n\n                              return left + ',' + bottom + ' '\n                                 + (left + x.bandwidth()/2 + overlap) + ',' + top + ' '\n                                 + (left + x.bandwidth() + (2 * overlap)) + ',' + bottom;\n                          })\n                          .attr(\"fill\", function(d) {\n                        if (d.armn == 0)  {\n                          //if event is placebo, then color red\n                          return \"#CC0000\";\n                        }\n                      })\n                          .style(\"opacity\", \"0.2\")\n                          //show tooltip on hover\n                          .on(\"mouseover\", function(d)  {\n                        var xPos = d3.event.pageX;\n                        var yPos = d3.event.pageY;\n\n                        //Update the tooltip position and value\n                                    d3.select(\"#tooltip\")\n                                        .style(\"left\", xPos + \"px\")\n                                        .style(\"top\", yPos + \"px\")\n                            .html(\"<p><b>Randomization date: <\/b>\" + d.rando_date + \"<br /><p><b>High level event: <\/b>\" + d.aebodsys + \"<\/p><p><b>Low level event: <\/b>\" + d.aept + \"<\/p><p><b>Duration: <\/b>\" + d.dur + \" days<\/p><p>This subject has reported <b>\" + (d.repeatnum-1) + \"<\/b> adverse events before this.<\/p>\");\n\n                        //add highlight to active polygon\n                          d3.select(this)\n                            .attr(\"stroke\", \"rgba(0,0,0,1)\")\n                            .attr(\"stroke-width\", \"2px\")\n                            .attr(\"opacity\", \"0.8\");\n\n                                    //Show the tooltip\n                                    d3.select(\"#tooltip\").classed(\"hidden\", false);\n                      })\n\n                      .on(\"mouseout\", function() {\n                                    //Hide the tooltip\n                                    d3.select(\"#tooltip\").classed(\"hidden\", true);\n\n                          //remove highlight from active polygon\n                          d3.select(this)\n                            .attr(\"stroke\", \"none\")\n                            .attr(\"stroke-width\", \"0px\");\n                               });\n\n                  //first axis\n                      svg.append(\"g\")\n                          .attr(\"transform\", \"translate(-7.5,\" + 2*height/3 + \")\")\n                          .call(d3.axisBottom(x)\n                          .tickValues([]));\n\n                  //second axis\n                      svg.append(\"g\")\n                          .attr(\"transform\", \"translate(-7.5,\" + height/3 + \")\")\n                          .call(d3.axisBottom(x)\n                          .tickValues([]));\n\n                  //lowest axis\n                        svg.append(\"g\")\n                          .attr(\"transform\", \"translate(-7.5,\" + height + \")\")\n                          .call(d3.axisBottom(x)\n                          .tickValues(x.domain().filter(function(d,i){ return !(i%10)})));\n\n                      svg.append(\"line\")\n                          .attr(\"x1\", 0  - overlap)\n                          .attr(\"y1\", height)\n                          .attr(\"x2\", width  + overlap)\n                          .attr(\"y2\", height)\n                          .attr(\"stroke-width\", \"2\");\n                    });\n\n              <\/script>\n            <\/div>\n\n            <div class=\"row d-flex justify-content-center\" style=\"margin-top: -180px;\">\n              <div class=\"col-md-6\">\n                <p class=\"byline\">By Vivek Rao<\/p>\n\n                <p class=\"copy\">The above visualization is based on <a href=\"https://github.com/VIS-SIG/Wonderful-Wednesdays/tree/master/data/2020/2020-08-12\" target=\"_blank\" class=\"copy-link\">clinical trial data<\/a> for an active treatment for eczema compared to placebo in adolescents that are unresponsive to standard care.<\/p>\n\n                <p class=\"copy\">An analysis revealed that more adverse events were recorded for subjects that were assigned to an intervention treatment arm, compared to those assigned to a placebo.<\/p>\n\n                <p class=\"copy\">See some of the insights below:<\/p>\n\n                <div class=\"flourish-embed flourish-hierarchy\" data-src=\"visualisation/3538282\"><\/div>\n                <p class=\"copy\">Of the 61 patients closely followed in the 12-month period, 49 developed adverse effects relating to anemia.<\/p>\n\n                <div class=\"flourish-embed flourish-scatter\" data-src=\"visualisation/3538182\"><\/div>\n                <p class=\"copy\">Subjects assigned to placebo treatment arm that reported an adverse event had their event treated in a duration of 6 days, on average. Participants assigned to interevention treatment, on average, saw the end of their adverse event in 8 days.<\/p>\n\n              <\/div>\n            <\/div>\n\n    <\/body>\n<\/html>\n\nBack to blog\n\nExample 2. Triangles - updated version\n\n\n\nBack to blog\n\nExample 3. Tendril plot\n\n\n# packages\npacman::p_load(tidyverse, rio)\npacman::p_load(lubridate)\npacman::p_load(labelled)\npacman::p_load(Tendril)\npacman::p_load(ggtext)\npacman::p_load(colorspace)\n\n# import\nae <- import(\"https://raw.githubusercontent.com/VIS-SIG/Wonderful-Wednesdays/master/data/2020/2020-08-12/2020-08-12_ae_example_dataset.csv\") %>% \n  mutate(rando_date = ymd(rando_date),\n         aestdat = ymd(aestdat),\n         aeeddat = ymd(aeeddat)) %>% \n  mutate(day = as.numeric(aestdat - rando_date)) %>% \n  as.data.frame()\n\n# Fixed mistake in subject 2011\nae[ae$usubjid == \"2011\", \"arm\"] <- \"Intervention\"\n\n# add labels\nvar_label(ae) <- list(\n  usubjid = \"unique subject identifier\",\n  arm = \"treatment assignment name\",\n  armn = \"treatment assignment numeric (0: placebo; 1:intervention)\",\n  rando_date = \"date of randomisation (yyyymmdd)\",\n  repeatnum = \"unique event identifier within usubjid\",\n  aept = \"adverse event code at preferred term/lower level\",\n  aebodsys = \"adverse event code at body system/higher level\",\n  aesev = \"adverse event severity grade (mild, moderate, severe)\",\n  aesevn = \"adverse event severity grade number (1: mild, 2: moderate, 3: severe)\",\n  aeser = \"serious adverse event (no, yes)\",\n  aesern = \"serious adverse event (0: no, 1: yes)\",\n  aestdat = \"adverse event start date (yyyymmdd)\",\n  aeeddat = \"adverse event end date (yyyymmdd)\",\n  dur = \"adverse event duration (days)\")\n\n# export\nsetwd(\"C:/R/Wonderful-Wednesdays/2020-08-12\")\nexport(ae, \"2020-08-12_ae_example_dataset.rds\")\n\n# Tendril\nsubj <- ae %>%\n  count(usubjid, arm) %>% \n  #add_row(usubjid = 3000, arm = \"Intervention\", n = 0) %>% \n  #add_row(usubjid = 3001, arm = \"Placebo\",      n = 0) %>%\n  select(-n) %>% \n  as.data.frame()\n\npt <- Tendril(mydata = ae,\n              rotations = rep(3, nrow(ae)),\n              AEfreqThreshold = 5,\n              Tag = \"Comment\",\n              Treatments = c(\"Intervention\", \"Placebo\"),\n              Unique.Subject.Identifier = \"usubjid\",\n              Terms = \"aebodsys\",\n              #Terms = \"aept\",\n              Treat = \"arm\",\n              StartDay = \"day\",\n              # SubjList = subj,\n              # SubjList.subject = \"usubjid\",\n              # SubjList.treatment = \"arm\",\n              # filter_double_events = TRUE\n)\n\n# working with terms \nTerms <- pt$data %>% \n  group_by(Terms) %>% \n  summarise(n = n(),\n            x = x[n]) %>% \n  ungroup() %>% \n  arrange(x) %>% \n  mutate(text = str_glue(\"{Terms} (n={n})\")) \n\n# Reorder guides\npt$data$Terms <- fct_relevel(pt$data$Terms,\n                             Terms %>% \n                               pull(Terms) %>% \n                               as.vector()\n)\n\nlevels(pt$data$Terms) <- Terms %>% pull(text) %>% as.vector()\n\n# plot Results\nplot(pt) +\n  geom_point(alpha = 0.25) +\n  geom_path(alpha = 0.25) +\n  geom_vline(xintercept = 0, color = 'gray50', linetype = \"dashed\") +\n  geom_hline(yintercept = 0, color = 'gray50', linetype = \"dashed\") +\n  #scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  scale_color_discrete_qualitative(palette = \"Dark3\")+\n  scale_x_continuous(limits = c(-100, 200)) +\n  labs(title = \"**Tendril Plot** of System Organ Class Adverse Events (AE) having at least 5 incidences\",\n       # caption =\"The Tendril Plot: a novel visual summary of the incidence, significance and temporal aspects of AE in clinical trials (JAMIA 2018; 25(8): 1069-1073)\"\n       caption = \n       \"Each MedDRA adverse event code at body system/higher level is\n       represented by a line (tendril) and each point is an event. Since time runs\n       along each tendril, it is the shape that carries the important information,\n       rather than the x and y coordinates. An event on the Intervention treatment\n       arm will tilt tendril direction to the *right*, and an event on the placebo arm will\n       tilt tendril direction to the *left*.\n       <br>\n       *The Tendril Plot: a novel visual summary of the incidence, significance and temporal aspects of AE in clinical trials (JAMIA 2018; 25(8): 1069-1073)*\"\n       ) +\n  guides(color = guide_legend(title = \"AE at Body System\")) +\n  theme(aspect.ratio = 0.70,\n        plot.title = element_markdown(),\n        plot.caption = element_textbox_simple(\n          size = 8,\n          lineheight = 1,\n          hjust = 0, vjust = 1,\n          padding = margin(1, 1, 1, 1),\n          margin = margin(1, 1, 1, 1)\n        ),\n        plot.caption.position = \"plot\",\n        legend.position       = c(0.99,0.92),\n        legend.justification  = c(1,1),\n        legend.background     = element_rect(fill  = 'gray90'),\n        legend.key            = element_rect(fill  = 'gray90'))\n\nggsave(\"C:/R/Wonderful-Wednesdays/2020-08-12/tendril_plot.png\",\n       width = 7.5, height = 6, units = \"in\")\n\nBack to blog\n\nExample 4. AdEPro app\n\n\nlibrary(adepro)\nlibrary(tidyverse)\nlibrary(lubridate)\n\n#change to the working directory where the files were extracted\nsetwd(\"C:/Users/UHLMALO1/OneDrive - Novartis Pharma AG/My_Data/PSI_visualization/Wonderful_Wednesdays_Webinars/2020-09-09/Einreichungen/Final\")\n\n#Run this code to put the variables in the dataset provided into the correct format\nAE <- read.csv(\"2020-08-12_ae_example_dataset.csv\")%>%\n  mutate(TRTSDT=ymd(rando_date)) %>%\n  mutate(SUBJIDN = usubjid) %>%\n  mutate(AEDECOD = aept) %>%\n  mutate(TRT01A = arm) %>%\n  mutate(TRT01A = if_else(TRT01A==\"Intervention\",\"Experimental\",\"Control\")) %>%\n  mutate(LVDT = 365) %>%\n  mutate(DTHDT = \"NA\") %>%\n  mutate(SAFFN = 1) %>%\n  mutate(AETRTEMN = 1) %>%\n  mutate(AESERN = aesern) %>%\n  mutate(AERELN = 1) %>%\n  mutate(AE_Start = ymd(aestdat)) %>%\n  mutate(AESTDY = AE_Start - TRTSDT + 1)%>%\n  mutate(AEENDY = AESTDY + dur + 1) %>%\n  mutate(AESEVN = aesevn) %>%\n  mutate(TRTSDT=0) %>%\n  mutate(AGE=\"NA\") %>%\n  mutate(SEX=\"NA\") %>%\n  mutate(REGION=\"NA\") %>%\n  select(c(SUBJIDN,AEDECOD,AESTDY, AEENDY,AESEVN,AETRTEMN,AESERN,AERELN, TRT01A, TRTSDT, LVDT, DTHDT,AGE, SEX, REGION, SAFFN))\n\n#write this back to CSV\nwrite.csv(AE,\"AE.csv\",row.names=FALSE)\n\n#Run the following line to run the app.\n#CSV must be loaded into the app\nlaunch_adepro()\n\nBack to blog\n\nExample 5. Adverse event explorer\n\n\nlibrary(safetyexploreR)\nlibrary(tidyverse)\nlibrary(readr)\n\npsi_ae <- read_csv(\"psi-ae.csv\")\n\nADAE_PSI <- \n  psi_ae %>%\n  dplyr::mutate(\n    USUBJID = usubjid,\n    SITEID = 1,\n    RFSTDTC = rando_date,\n    AEDECOD = aept, \n    AESEQ = repeatnum,\n    ASTDT = aeeddat, \n    AEBODSYS = aebodsys, \n    ARM = arm, \n    AESEV = aesev,\n    AESER = aeser,\n    AEREL = 'Y',\n    AEOUT = dur,\n    SEX = 'NA',\n    RACE = 'NA'\n  )\n\naeExplorer(\n  data = ADAE_PSI,\n  filters_event_col = c(\"AESER\", \"AESEV\",\n                        \"AEREL\"),\n  filters_event_label = c(\"Serious?\", \"Severity\",\n                          \"Relationship\")\n)\n\nBack to blog\n\nExample 6. Volcano plots\n\n\n\nBack to blog\n\n\n",
    "preview": "posts/2020-10-17-wonderful-wednesdays-september-2020/./images/volcano BS Phillips.png",
    "last_modified": "2020-11-03T22:04:13+01:00",
    "input_file": {},
    "preview_width": 990,
    "preview_height": 720
  },
  {
    "path": "posts/2020-10-30-wonderful-wednesdays-august-2020/",
    "title": "Wonderful Wednesdays August 2020",
    "description": "In this month’s webinar, we discussed an exacerbation example data set. The data is based on the RISE study for patients with moderate COPD. The primary endpoint is the number of exacerbations during a six month treatment period. Event data – but patients can (and do) have multiple exacerbations. Statistical analysis used a Negative Binomial model. The dataset also included other variables which (may) effect the exacerbation rate: % Predicted Normal of Forced Expiratory Volume in 1 second (FEV1), Exacerbations in previous year, and Region / Gender. The challenge was to produce a data visualisation incorporating the information on the number of exacerbations observed. The discussed visualisations included a straightforward and clear presentation of the number of exacerbations, a Power BI app, longitudinal plots, and a display of patient-level outcomes.",
    "author": [
      {
        "name": "Lorenz Uhlmann",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2020-08-12",
    "categories": [
      "Event data",
      "Wonderful Wednesdays"
    ],
    "contents": "\nEvent data - COPD example data\nChronic Obstructive Pulmonary Disease (COPD) is a respiratory disease characterised by difficulty breathing and has increased mortality. An exacerbation can be life-threatening if not treated promptly. Data is based on the RISE study for patients with moderate COPD.\nThe primary endpoint is the number of exacerbations during a six month treatment period. Event data - but patients can (and do) have multiple exacerbations. Statistical analysis used a Negative Binomial model. here.\n\nExample 1. Dotplot\nhigh-resolution image\nThis is a very clean and clear presentation of the primary endpoint. It is actually a barchart but displayed horizontally. Each group is represented by a different color which makes it very easy to see the differences between the two groups in regards to the primary endpoint. The ICS/LABA group leads to higher values in the category of 0 counts, whereas the LABA group leads to higher percentages in all other categories. Thus, the message becomes very clear and it is easy to communicate the results using this visualization.\nOverall, this is a very good visualisation. The use of color is done in a very sensible way. The colors are already used which makes a lot of sense as well. Furthermore, it is a minimalistic design and, therefore, it focus on the relevant aspects while dropping any clutter (minimizing the ink-to-data ratio). There are more helpful details considered in the visualisation: The bars are labeled directly at each bar and the percentage of ICS/LABA are always above the bar while the percentage of LABA is always below.\nAn altarnative way would have been a waterfall plot. This would emphasize a little more the (change of) differences between the groups over the categories. Another option would have been to add lines between the “bars” in each category to emphasize the difference between the groups. These lines would be color coded to stress the “direction” of the difference.\nlink to code\n\nExample 2. Power BI app\n\nThe app can be found here.\nThis app provides you with a quick overview over several variables at the same time. It provides you with a lot of contextual information that helps you address the question you want to answer. It also has a nice feature: You can just click on a category of one variable and all other plots and numbers will get updated. This can be even done in combination among different variables. It also offers you a “Clear All filters” button which is often missing in other applications.\nSince it is interactive, it is really useful and a nice tool to explore the data. Furthermore, it is nicely organized and it includes several titles and explanations which makes it easy to see what is being displayed. On the top, you have all baseline variables, and on the bottome you see the outcomes. The latter ones are organized in boxed which appear to pop out which is a nice idea to put some emphasis on these variables. Also, the key numbers are being higlighted on the left hand side.\nSomething that could be improved on would be the use of coloring. It is not entirely clear what they represent and it also seems to change over different plots. The coloring in Figure 2.1 is actually great, because it makes you focus on the treatment of interest. However, this coloring scheme is not kept consisent over all visualisations, for example in Figure 2.2. At the same time, you could argue that it is more important there to be able to compare the categories between the two groups and, therefore, they have to be represented in the same color. A last idea for improvement would be add some random noise (horizontally) to the dots in the boxplots to make it easier to see each single observation. Furthemore, in Figure 2.1, the average number instead of the total number could have been displayed. Also, it is not entirely clear why there are numbers on the bottom left instead of additional visualisations.\nlink to code\n\nExample 3. Line plot\nhigh-resolution image\nHere, we are not only focusing on a single endpoint, but we also consider some covariate information. The title helps you to understand right away what this visualisation is showing you. It presents the rate ratio over different age and FEV1 values.\nOverall, this is a great visualisation. The design is minimalistic and chosen wisely. The coloring makes it clear that different aspects are being displayed. Also, the reference lines are really helpful. Another important point is the logarithmic scale on the x-axis which is keeps the confidence intervals / bands symmetric.\nAn aspect that gets not entirely clear is the defintion of the confidence bands. One could argue that we would expect the bands to get wider at both ends. Here the width seems to be absolutely constant. The reason for this is most likely the fact that we only look at overlapping subgroups which is explained in the footnote below the plot. Another point is the interpretation of the rate ratio in the title as a reduction which we could argue about. Furthermore, due to the logarithmic scale on the y axis, it might be a bit challenging to effectively make use of the horizontal grid lines which are not pointing at a specific value on the y axis.\nlink to code\n\nExample 4. Individual data\nhigh-resolution imagehigh-resolution image\nIn these two plots, the individual observations are being displayed which provides you with very detailed information. In addition, the overall effect is shown as median difference.\nAn advantage of this visualisation is that it shows you that despite of an existing treatment effect, we get reminded that there are indeed some patients who do not seem to benefit from the treatment.\nAt the same time, it might be a little bit challenging to get the message out of this visualisation right away. Withouth the lines showing the treatment effect, it might be really hard to see any effect at all. So, this plot might be specifically useful, if you have a big treatment effect - and then it has got huge potential in it. Also, the coloring is chosen wisely and the visualisation looks very clean overall.\nAn alternative way would have been to show the cumulative distribution functions for both groups and then emphasize the difference, for example, by coloring the space in between the two lines (representing the distribution functions). Another option could be Q-Q plots.\nlink to code\nCode\n\nExample 1. Dotplot (R)\n\n\n### Load packages\nlibrary(here)\nlibrary(tidyverse)\nlibrary(ggtext)\n\n### Load data\ndata <- data.frame(read_delim(here(\"2020-07-08-COPD-PSI-data.csv\"), delim=','))\ndata$ANTHONISEN <- fct_rev(factor(data$ANTHONISEN)) # reverse factor for plotting\n\n### Get percentage for number of exacerbations by treatment group\nfreq <- data %>% group_by(RAND_TRT, ANTHONISEN, .drop = F) %>% summarise(n = n()) %>% mutate(freq = 100 * n / sum(n))\nfreq$freq_label <- format(round(freq$freq, 1), nsmall = 1)\n\n### Add N's to treatment group labels\nN <- data %>% group_by(RAND_TRT) %>% summarize(N = n())\n\n### Create label variable including number of subjects\nfreq_n <- merge(freq, N, by = \"RAND_TRT\")\nfreq_n$RAND_TRT_L <- paste0(freq_n$RAND_TRT, \" (N=\", freq_n$N, \")\")\n\n### Colors\nfill <- c(\"#E7B800\", \"#2E9FDF\")\n\n### Plot\nggplot(freq_n, aes(x = ANTHONISEN, y = freq, color = RAND_TRT)) +\n  # Set minimal theme and flip x/y-axes\n  theme_minimal(base_size = 20) +\n  coord_flip() +\n  # Plot points\n  geom_point(position = position_dodge(width = 0), shape = 124, size = 10) +\n  # Plot annotations (different positions by treatment group)\n  geom_text(data = freq[freq$RAND_TRT == \"ICS/LABA\",], aes(label=freq_label, x=ANTHONISEN, y=freq), hjust=0.6, vjust=-1.5, size = 5) +\n  geom_text(data = freq[freq$RAND_TRT == \"LABA\",], aes(label=freq_label, x=ANTHONISEN, y=freq), hjust=0.6, vjust=2.5, size = 5) +\n  # Color treatment group labels in title\n  labs(title = paste(\"Larger proportion exacerbation-free with <span style='color:\", fill[1], \"'>\", unique(freq_n$RAND_TRT_L)[1], \n                     \"<\/span> compared to <span style='color:\", fill[2], \"'>\", unique(freq_n$RAND_TRT_L)[2], \"<\/span>\"),\n       subtitle = \"% of total within treatment groups by number of exacerbations\") +\n  theme(plot.title = element_markdown()) +\n  # Set colors and remove legend (in comments: code to color treatment group labels in legend)\n  #scale_color_manual(labels = paste(\"<span style='color:\", fill, \"'>\", unique(freq$RAND_TRT), \"<\/span>\"), \n  #                   values = fill, name = NULL) +   \n  #theme(legend.text = element_markdown(size = 12), legend.position = c(0.1, 0.89)) +\n  #guides(colour = guide_legend(override.aes=list(size=0))) +\n  scale_color_manual(values = fill) +\n  theme(legend.position = \"none\") +\n  # Remove clutter\n  scale_y_continuous(expand = c(0,1)) +\n  theme(axis.title.x = element_blank(), axis.text.x=element_blank(), \n        panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank()) +\n  scale_x_discrete(name = NULL) +\n  NULL\n\nggsave(file = here(\"dotplot.png\"), width = 35, height = 20, units = \"cm\")\n\nBack to blog\n\nExample 2. Power BI app\n\n\n\nBack to blog\n\nExample 3. Line plot\nR:\n\n\n####################################################################\n# Program name: COPD_exacs_STEPP.R\n# Purpose: To produce a STEPP plot for COPD exacerbations \n#          examining age and FEV1\n#         (for Wonderful Wednesdays Aug 2020)\n# Written by: Steve Mallett\n# Date: 31-Jul-2020\n####################################################################\n\nlibrary(haven)\nlibrary(ggplot2)\nlibrary(grid)\nlibrary(gridExtra)\n\ncopd_age <- read_sas(\"/.../plot_ww2020_08.sas7bdat\") %>%\n  filter(var == \"age_n\")\n  \nplot01 <- ggplot() +\n  geom_ribbon(data = copd_age, aes(x = median, ymin = LowerExp, ymax = UpperExp), fill = \"#b2e2e2\", alpha = .5) +\n  geom_line(data = copd_age, aes(x = median, y = ExpEstimate), color = \"#006d2c\", size = 0.5 ) +  \n  geom_segment(aes(x=53, xend=72, y=0.82, yend=0.82), linetype = 2, color = \"black\") +\n  scale_x_continuous(\"Age (years)\",\n                     # breaks=c(55, 60, 65, 70),\n                     # labels=c(55, 60, 65, 70),\n                     limits=c(53, 72)) +\n  scale_y_log10(\" \",\n                breaks=c(0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6),\n                limits=c(0.4, 1.6)) +\n  theme_minimal() +\n  theme(legend.position=\"none\",\n        text = element_text(size = 15),\n        axis.ticks.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.x =  element_text(size = 20),  \n        axis.text.y =  element_text(size = 20),        \n        axis.title.x = element_text(size = 20),\n        axis.title.y = element_text(size = 20),\n        plot.title = element_text(hjust = 0.5, size = 25),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=0.25),\n        # panel.grid = element_blank(),\n        plot.margin=unit(c(0,0,0,0),\"cm\")) +\n  ggtitle(label = \" \")\n\ncopd_fev <- read_sas(\"/shared/175/arenv/arwork/gsk1278863/mid209676/present_2020_01/code/COPD/plot_ww2020_08.sas7bdat\") %>%\n  filter(var == \"fev1_rv\")\n\nplot02 <- ggplot() +\n  geom_ribbon(data = copd_fev, aes(x = median, ymin = LowerExp, ymax = UpperExp), fill = \"#bdd7e7\", alpha = .5) +\n  geom_line(data = copd_fev, aes(x = median, y = ExpEstimate), color = \"#08519c\", size = 0.5 ) +  \n  # geom_hline(yintercept = 0.82, linetype = 2, color = \"black\", size = 0.5) +\n  geom_segment(aes(x=34, xend=60, y=0.82, yend=0.82), linetype = 2, color = \"black\") +\n  scale_x_continuous(\"FEV1 (% predicted)\",\n                     breaks=c(34, 40, 45, 50, 55, 60),\n                     labels=c(35, 40, 45, 50, 55, 60),\n                     limits=c(34, 60)) +\n  scale_y_log10(\" \",\n                breaks=c(0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6),\n                limits=c(0.4, 1.6)) +\n  theme_minimal() +\n  theme(legend.position=\"none\",\n        text = element_text(size = 15),\n        axis.ticks.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.x =  element_text(size = 20),  \n        axis.text.y =  element_text(size = 20),        \n        axis.title.x = element_text(size = 20),\n        axis.title.y = element_text(size = 20),\n        plot.title = element_text(hjust = 0.5, size = 25),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=0.25),\n        # panel.grid = element_blank(),\n        plot.margin=unit(c(0,0,0,0),\"cm\")) +\n  ggtitle(label = \" \")\n\ng <- grid.arrange(plot01, plot02, ncol =1, nrow = 2,\n                  left = textGrob(\"Rate Ratio (ICS+LABA / LABA)\", rot = 90, gp = gpar(fontsize=20)),\n                  top = textGrob(\"ICS+LABA Reduces COPD Exacerbation Rate by 18 Percent Compared\\n to LABA, Consistently Across Age and Lung Function Values\", gp = gpar(fontsize=25)),\n                  bottom = textGrob(\"\\nAnalysis performed using a negative binomial regression model adjusting for number of previous \\nexacerbations and region. Sliding window STEPP plots, using overlapping subgroups (N=350).\", gp = gpar(fontsize=18)))\n\nggsave(\"/.../plot_ww2020_08.png\", g, width=12, height=12, dpi=300)\n\nSAS:\n\n\nlibname outdata \"H:\\arwork\\gsk1278863\\mid209676\\present_2020_01\\code\\COPD\";\n\nPROC IMPORT OUT= WORK.copd \n            DATAFILE= \"C:\\Users\\sam31676\\OneDrive - GSK\\_Non Project\\Data Visualisation\\PSI data vis SIG\\Wonderful Wednesdays\\2020 08\\ww08.txt\" \n            DBMS=CSV REPLACE;\n     GETNAMES=YES;\n     DATAROW=2; \nRUN;\n\ndata copdx;\n  set copd;\n  fu_years=study_days_n/365.25;\n  logfu=log(fu_years);\nrun;\n\n* Fit overall model;\n\nproc genmod data=copdx;\n  class rand_trt prev_exac region;\n  model anthonisen = rand_trt prev_exac region fev1_rv /dist=negbin link=log offset=logfu type3; \n  lsmeans rand_trt / diff exp cl om;\nrun;\n\n* Main macro to create plot data;\n\n%macro create(id=, var=, class=, covars=);\nproc sort data=copdx;\n  by &var;\nrun;\n\noptions nosymbolgen mprint;\n%let r1=50;\n%let r2=350;\n%let n = 1221;\n\n%macro split;\n%global m;\n%let i = 0;\n%let low = 1;\n%let high = %eval(&r2);\n\n%do %until (&high > &n);\n  %let i = %eval(&i+1);\n\n  data copd&i;\n    set copdx;\n    if _n_ >= &low and _n_ <= &high;\n    group = &i;\n    run;\n\n  %let low = %eval(&low+&r1);\n  %let high = %eval(&low+&r2-1);\n  %let m = &i;\n  %end;\n\n%mend split;\n%split;\n\n%macro combine;\ndata copd_all;\n  set \n  %do i = 1 %to &m;\n    copd&i\n    %end;\n    ;\nrun;\n%mend combine;\n%combine;\n\nproc means data=copd_all noprint;\n  by group;\n  var &var;\n  output out=med(keep=group median) median(&var)=median;\nrun;\n\nods output diffs=diffs;\n\nproc genmod data=copd_all;\n  by group;\n  class &class;\n  model anthonisen = &covars/dist=negbin link=log offset=lnstudyday; \n  lsmeans rand_trt / diff exp cl om;\nrun;\nquit;\n\ndata plot&id;\n  merge diffs(keep=group ExpEstimate lowerexp upperexp) med;\n  by group;\n  var=\"&var\";\nrun;\n%mend create;\n%create(id=1, var=fev1_rv, class=%str(rand_trt prev_exac region), covars=%str(rand_trt prev_exac region));\n%create(id=2, var=age_n, class=%str(rand_trt prev_exac region), covars=%str(rand_trt prev_exac region));\n\ndata outdata.plot_ww2020_08;\n  set plot1 plot2;\nrun;\n\nBack to blog\n\nExample 4. Individual data\n\n\nlibrary(tidyverse)\nlibrary(RColorBrewer)\nlibrary(readxl)\n\n#Colour scheme\nOrange <- \"#EF7F04\"\nGreen <- \"#68B937\"\nBlue <- \"#00A6CB\"\nGrey <- \"#4E5053\"\nDarkblue <- \"#003569\"\nYellow <- \"#FFBB2D\" \nGreyedOut <- \"#D3D3D3\"\n\nsetwd(\"C:/Users/philip.griffiths/OneDrive - OneWorkplace/Documents/Wonderful Wednesday/Exacerbations\")\n\n#Read in a dataset and create a flag value for exacerbations >=1\nexacerbations <- read_csv(\"2020-07-08-COPD-PSI-data.csv\")  %>%\n  mutate(flag = as.numeric(ifelse(ANTHONISEN >= 1, \"1\", \"0\")))\n\n#linear regression to adjust number of exacerbations based on Baseline values\nModel <- lm(ANTHONISEN ~ FEV1_RV + PREV_EXAC + AGE_C + GENDER + SMOKER + AIRFLOW, data = exacerbations)\n\n#logistic regression to determine the probability of >=1 exacerbation adjusted for baseline\nLogisticModel <- glm(flag ~ FEV1_RV + PREV_EXAC + AGE_C + GENDER + SMOKER + AIRFLOW,data = exacerbations,family = binomial)\n\n#Check out the models. I actually removed region. it was highly sig, but I dont have a theoretical reason for that, and also just loads of US\nsummary(Model)\nsummary(LogisticModel)\n\n#Make an \"adjusted\" exacerbation rate and a probability exacerbation\nAdjusted <- predict(Model, data = exacerbations)\nProb <-predict(LogisticModel, type = \"response\")\n\n#add the ajusted and probability columns to the main dataset. make adjusted exacerbations per year\n#Sequence1 is a consecutively ordered variable for the waterfall plot later on\nexacerbations_pred <- add_column(exacerbations, adjust=Adjusted) %>%\n  add_column(prob=Prob) %>%\n  mutate(years=STUDY_DAYS_N/365) %>%\n  mutate(ratio=adjust / years) %>%\n  arrange(ratio) %>%\n  add_column(sequence1 = 1:nrow(exacerbations))\n\n#create two datasets (one for treat and one for control) and test the difference between them\ntreat <-exacerbations_pred %>%\n  filter(RAND_TRT==\"ICS/LABA\")\n\ncontrol <- exacerbations_pred %>%\n  filter(RAND_TRT==\"LABA\")\n  \nwilcox.test(treat$ratio, control$ratio,paired=FALSE)\n\nwhichmedian <- function(x) which.min(abs(x - median(x)))\n\n#Median patient on treatment for reference line\nTreatMed <- exacerbations_pred %>%\n  filter(RAND_TRT==\"ICS/LABA\") %>%\n  slice(whichmedian(ratio))\n\n#Median patient on control for refeence line\nControlMed <- exacerbations_pred %>%\n  filter(RAND_TRT==\"LABA\") %>%\n  slice(whichmedian(ratio))\n\n#create plot\np <- exacerbations_pred %>%\n  ggplot() +\n  geom_col(aes(x=sequence1, y=ratio, fill=RAND_TRT, color=RAND_TRT)) + #column - aes takes seq1 for the x as this is the reordered Ps. Need fill and colour so that the col outlines are the correct colour\n  ggtitle(\"Group level advantage for ICS/LABA patients was replicated at the\\npatient level using demographic adjusted yearly exacerbation rate\") + #titles etc\n  xlab(\"Patients, in order of adjusted exacerbation probability\") +\n  xlab(\"Patients, in order of adjusted exacerbations per year\") + \n  ylab(\"Adjusted exacerbations per year\") +\n  geom_vline(aes(xintercept = sequence1), linetype='dashed', col = Darkblue, TreatMed)  + #reference lines for median treatment response and median control response\n  geom_vline(aes(xintercept = sequence1), linetype='dashed', col = Green, ControlMed)  +\n  scale_fill_manual(values=c(Darkblue, Green), name = \"Condition\", labels = c(\"Treatment\\n(ICS/LABA)\", \"Control\\n(LABA)\")) + #make sure that the col and legend have the chosen colors. Update legend text\n  scale_colour_manual(values=c(Darkblue, Green)) + #make sure the outlines for the cols are also coloured in line with the above\n  guides(color = FALSE, size = FALSE) + # remove legend for the col outline\n  theme(axis.text.x=element_blank(), # remove the participant numbers \n        axis.ticks.x=element_blank()) + # remove x-axis ticks\n  theme (plot.title = element_text(family = \"sans\", color=Grey, face=\"bold\", size=22, hjust=0.5)) + #Edit font\n  theme (axis.title = element_text(family = \"sans\", color=Grey, face=\"bold\", size=22)) + #Edit font\n  theme(panel.background = element_blank()) # blank out the background\n\np + annotate(geom = \"text\", x = (ControlMed$sequence1 + 3), y = 3, label = \"Median difference\", hjust = \"left\", size = 6) + #add text higlighting the median\n  annotate(geom = \"segment\", y = 3, yend = 3, x = (TreatMed$sequence1 + 3), xend = (ControlMed$sequence1 - 3), \n           arrow = arrow(length = unit(3, \"mm\"))) + #this controls the arrow heads\n  annotate(geom = \"segment\", y = 3, yend = 3, x = (ControlMed$sequence1 - 3), xend = (TreatMed$sequence1 + 3), \n           arrow = arrow(length = unit(3, \"mm\")))\n\n#additional manipulation to reorder the dataset based on probability of exacerbation and creaion of a consecutive numbering (sequence2)\nexacerbations_pred <- exacerbations_pred %>%\n  arrange(prob) %>%\n  add_column(sequence2 = 1:nrow(exacerbations))\n\n#create two datasets (one for treat and one for control) and test the difference between them\ntreat <-exacerbations_pred %>%\n  filter(RAND_TRT==\"ICS/LABA\")\n\ncontrol <- exacerbations_pred %>%\n  filter(RAND_TRT==\"LABA\")\n\nwilcox.test(treat$prob, control$prob,paired=FALSE)\n\n#Median patient on treatment for ref line\nTreatMed <- exacerbations_pred %>%\n  filter(RAND_TRT==\"ICS/LABA\") %>%\n  slice(whichmedian(prob))\n\n#Median patient on control for ref line\nControlMed <- exacerbations_pred %>%\n  filter(RAND_TRT==\"LABA\") %>%\n  slice(whichmedian(prob))\n\n#see above plot for comments\nq <- exacerbations_pred %>%\n  ggplot() +\n  geom_col(aes(x=sequence2, y=prob, fill=RAND_TRT, color=RAND_TRT)) +\n  ggtitle(\"Group level advantage for ICS/LABA patients was replicated at the patient \\n level showing higher probability of Exacerbations for Control patients\") + \n  ylab(\"Adjusted probability of >=1 exacerbation\") +\n  xlab(\"Patients, in order of adjusted exacerbation probability\") + \n  geom_vline(aes(xintercept = sequence2), linetype='dashed', col = Darkblue, TreatMed)  +\n  geom_vline(aes(xintercept = sequence2), linetype='dashed', col = Green, ControlMed)  +\n  scale_fill_manual(values=c(Darkblue, Green), name = \"Condition\", labels = c(\"Treatment\\n(ICS/LABA)\", \"Control\\n(LABA)\"))+\n  scale_colour_manual(values=c(Darkblue, Green)) + \n  guides(color = FALSE, size = FALSE) +\n  theme(axis.text.x=element_blank(), \n        axis.ticks.x=element_blank()) + \n  theme (plot.title = element_text(family = \"sans\", color=Grey, face=\"bold\", size=22, hjust=0.5)) + \n  theme (axis.title = element_text(family = \"sans\", color=Grey, face=\"bold\", size=22)) + \n  theme(panel.background = element_blank()) \n\n \nq + annotate(geom = \"text\", x = (ControlMed$sequence2 + 3), y = 0.6, label = \"Median difference\", hjust = \"left\", size = 6) +\n  annotate(geom = \"segment\", y = 0.6, yend = 0.6, x = (TreatMed$sequence2 + 3), xend = (ControlMed$sequence2 - 3), \n           arrow = arrow(length = unit(3, \"mm\"))) +\n  annotate(geom = \"segment\", y = 0.6, yend = 0.6, x = (ControlMed$sequence2 - 3), xend = (TreatMed$sequence2 + 3), \n           arrow = arrow(length = unit(3, \"mm\")))\n\nBack to blog\n\n\n",
    "preview": "posts/2020-10-30-wonderful-wednesdays-august-2020/./images/dotplot - Markus Vogler.png",
    "last_modified": "2020-11-01T13:17:38+01:00",
    "input_file": {},
    "preview_width": 4133,
    "preview_height": 2362
  },
  {
    "path": "posts/2020-09-20-wonderful-wednesdays-july-2020/",
    "title": "Wonderful Wednesdays July 2020",
    "description": "This month's challenge was to summarise changes in haemoglobin (Hgb) concentration over time in patients with anaemia associated with Chronic Kidney Disease (CKD). An experimental medicine was compared with a control group, but in addition to demonstrating efficacy, there was a special interest in visualising intra-individual variability, as large changes in Hgb are a potential safety concern. The visualisations presented ranged from grouped line plots over time, Sankey-diagrams and line plots with quantile bands for summary views and a lasagna plot for the display of individual data. Some general hints were given on how to define suitable color palettes for graphs depending on the type of data. Presented by Steve Mallett.",
    "author": [
      {
        "name": "Steve Mallett",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2020-07-01",
    "categories": [
      "Longitudinal",
      "Continuous data",
      "Wonderful Wednesdays"
    ],
    "contents": "\nHaemoglobin in Anaemia\nThis month’s example dataset comprised haemoglobin (hgb) concentrations over time from a simulated randomised trial in anaemia patients, comparing an experimental treatment with an active control group. The main study objective was to demonstrate a mean hgb value within a target range at the end of the study (week 24). However anaemia treatments have a known safety issue in that large or rapid increases in hgb levels are associated with increased cardiovascular risk. Therefore a successful treatment should also demonstrate stability and control in hgb levels, with increases in hgb over a 4 week period being ideally limited to <1 g/dl, with increases >2 g/dl being considered a safety risk. The challenge was to produce data visualizations that provide insights into the variability of hgb in addition to the efficacy.\nA more detailed description and link to the data can be found here.\n\nExample 1. Trellis Plot\n\nlink to codehigh-resolution image\nThis is a good example of a Trellis plot; in this example the left and right panels represent subgroups of patients with high and low hgb variability, respectively. High and low hgb variability in this case has been defined in terms of whether each subject had a change in hbg level of >2 g/dl between any two consecutive visits. The legend includes the number of patients in each treatment group (n), and before even considering the plot itself, the values of ‘n’ tell a story in that more patients with high hgb variability can be found in the control group, and more patients with lower hgb variability were in the experimental treatment group. The title plot clearly tells us the ‘story’ behind the plot in that the mean hgb in the control group did not achieve the target range in the low variability panel. In the left (high variability) panel, control group patients did achieve the target range, but at the expense of increased hgb variability (and therefore cardiovascular safety risk).\nSome good graphics principles were used, i.e. consistent use of colour across different areas of the graph to represent treatment group (although having the treatment labels closer to the line graphs would be an improvement). The target range was clearly labeled, although a band of light colour or grey may have provided further emphasis. Removing some of the unnecssary elements may have improved the visual impact of the graph, i.e. removing the non-inferiority boundary line, and simplifying the X-axis labels.\nThere were some ideas for further enhancements: in representing variability in a data visualisation, it’s often more meaningful to show the distribution of the data (for example error bars representing standard deviation rather than standard error of the mean). The plot may also have worked better by stacking the display panel vertically rather than horizontally. (These latter two points are adequately addressed in Example 4.)\n\nExample 2. Sankey Plot\n\nlink to codehigh-resolution image\nUnlike the previous example, this graph is entirely focused on showing us the relative changes in hgb levels rather than absolute values. Each panel in the graph includes a series of stacked bars charts over time, with categories defined in terms of change in hgb since the previous visit. The title has a clear message, and the higher variability in the control group is readily observed, with the bars in left panel (control group) showing more patients in the higher variability (2-3 g/dl and >3 g/dl) categories, and fewer patients in the low variability (<1 g/dl and 1-2 g/dl) categories. The Sankey plot includes the additional feature of enabling the viewer to visualise the shifting of patients from one category to another (or remaining in the same category) across visits.\nA few issues with the plot were discussed. A Sankey plot might be easier to interpret if the categories represented absolute hgb levels, so that the graph is showing shifts between different hbg levels. The graph is much harder to interpret when the categories themselves are representing hgb changes. Another issue is that increased versus decreased hgb levels have a different clinical interpretation, i.e. large decreases in hgb represent lack of efficacy, while increases are associated with a safety concern. For this reason, it would have been better to separate out the increases and decreases in hgb, i.e. defining separate categories for decrease >3 g/dl and increase >3 g/dl etc.\nAnother drawback is that it’s not possible to follow individual patients across the study (e.g. how many patients with good hbg control at week 4 also maintained good control at week 12, 16 …?). An alternative approach might be to define categories in terms of patients who were “stable” (e.g. defined as change in hgb <1 g/dl) at each visit and all preceding visits (versus patients with hgb change in hgb >= 1 g/dl at that visit or any preceding visit). This would address the question of whether patients achieved and sustained hgb control.\n\nExample 3. Lasagna Plot\n\nlink to code high-resolution image\nA lasagna plot can be a useful means for visualising longitudinal data with a continuous endpoint. Like its pasta-related cousin the spaghetti plot, data for each individual patient are shown with time represented on the X-axis. The main difference is that the spaghetti plot represents the continuous outcome variable on the Y-axis, while the lasagna plot uses a fixed point on the Y-axis for each patient, with values at different time points being mapped to a colour scale. The lasagna plot overcomes a drawback of the spaghetti plot where overlapping of the different patient “trajectories” can lose information, and the plot can be difficult to interpret if there are more than a small number of patients.\nA traditional lasagna plot uses solid areas of colour to represent outcomes at different time points for each patient, but the variation shown here has added some interpolation or blending, which gives a more blurred effect. Assuming the audience has received some instruction on how to interpret the graph, the overall message is quite obvious as the lower panel (control group) is clearly showing more areas of blue (representing decreases in hbg) and red (increases in hgb) since the previous visit, compared to the experimental treatment. Unlike the previous Sankey plot, the colour scheme makes a distinction between decreases and increases in hgb. Although colour hue or intensity is not the most effective attribute for encoding numeric values (see this link), this graph works quite well in providing an overall, qualitative impression of trends in the data where there is a strong and clearly defined effect.\nA possible improvement to the graph would be to sort the patients in a meaningful way, for example ordering by time to first increase in hgb (and even superimposing a survivor function curve), or ordering the patients by the length of time hgb stability was achieved at the end of the study.\n\nExample 4. Plot of Hgb Distribution Over Time\n\nlink to codehigh-resolution image\nThis plot shows the efficacy of each treatment (i.e. hgb levels compared to the target range) and additionally includes information on the distribution of the data. The median value is plotted along with a series of bands representing different percentages around the median, i.e. +/- 5%, 10% etc. This is more relevant information, in terms of showing the variability of individual patient outcomes, compared to a standard plot showing means and 95% confidence intervals. The title is telling a clear story, which is supported by the data visualisation showing that more patients in the control group were outside the hgb target range for long periods during the study. The plot is showing within-group variability, in contrast to the lasagna plot which was displaying within-patient variability. There is a natural trade-off between these two measures, and it would be challenging to show them both in the same plot; the choice of graph would depend on the clinical question of interest.\nFinally, the vertical stacking of the last two graphs was viewed as a good design choice, as in both cases this enables a simplified and clearer design by removing redundant X-axis labels.\nCode\n\nExample 1. Trellis Plot (R)\n\n\n## PSI Wonderful Wednesday June \n## Mean plots by change > 2 v1_0\n## Abi Williams\n\n## Load packages\n\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(plotrix)\nlibrary(metR) \n\n## Add chosen colours\n\nOrange <- \"#EF7F04\"\nGreen <- \"#68B937\"\nBlue <- \"#00A6CB\"\nGrey <- \"#4E5053\"\nDarkblue <- \"#003569\"\nYellow <- \"#FFBB2D\"\n\n# Read in data ====\n\nrawdat <- read_csv(\"hgb_data.csv\")\nsankdat <- read_csv(\"Sankey.csv\")\n\n## add visit and treatment names to sankey data\n\nsankdat2 <- sankdat %>% \n  left_join(rawdat) %>% \n  replace_na(list(CHG = 0, CHG_FROM_BL = 0))\n\nsankdat2$TRT01P <- as.factor(sankdat2$TRT01P)\nsankdat2$AVISIT <- as.factor(sankdat2$AVISIT)\n\nsankdat2$AVISIT <- fct_relevel(sankdat2$AVISIT, \"Week 4\", \"Week 8\", after = 1)\n\n\n## Create flag for patients who have change >2 at any point =====\n\npatsub1 <- sankdat2 %>% \n  filter(CHG > 2) %>% \n  select(USUBJID) %>% \n  distinct() %>% \n  mutate(anychg2FLN = 1) %>% \n  mutate(anychg2FLC = \"Change > 2 between any two consecutive visits\")\n\n\nflagged_dat <- sankdat2 %>% \n  left_join(patsub1) %>% \n  replace_na(list(anychg2FLN = 0, anychg2FLC = \"No change > 2 between any two consecutive visits\"))\n\n\n\nsummary_flagged <- flagged_dat %>%\n  group_by(AVISIT, TRT01P, anychg2FLC) %>% \n  summarise(mean_chg_BL = mean(CHG_FROM_BL),\n            mean_chg_BL_ci   = std.error(CHG_FROM_BL),\n            mean_chg_vis = mean(CHG),\n            mean_chg_vis_ci = std.error(CHG),\n            mean_raw = mean(AVAL),\n            mean_raw_ci = std.error(AVAL),\n            n = n())\n\n\nref <- summary_flagged %>% \n  filter(TRT01P == \"Treatment C\") %>% \n  ungroup() %>% \n  mutate(mean_raw = mean_raw - 0.75) %>% \n  mutate(TRT01P = \"Non-inferiority boundary\") %>% \n  mutate(mean_raw_ci = 0)\n\n\ndata <- summary_flagged %>% \n  ungroup() %>% \n  add_row(ref)\n\ndata$TRT01P <- as.factor(data$TRT01P) \n\ndata$TRT01P <- fct_relevel(data$TRT01P, \"Non-inferiority boundary\", after = Inf)\n\n## Make base plot ====\n\nmeanplot <- ggplot(data = data, aes(x = AVISIT, y = mean_raw, group = TRT01P, color = TRT01P)) ## plot object\n\npd <- position_dodge(width = 0.1) ## position adjustment to use\n\nplota <- meanplot +\n  # Line plot and error bars\n  geom_line(aes(linetype = TRT01P), show.legend = FALSE, position = pd) +\n  geom_errorbar(aes(ymin = mean_raw - mean_raw_ci, ymax = mean_raw + mean_raw_ci),\n                width = .1, linetype = 1, position = pd) +\n  geom_point(position = pd) +\n  \n  facet_wrap(vars(anychg2FLC)) +\n  # Add chosen colours\n  scale_color_manual(name = \"Treatment\", values = c(Blue, Green, Grey)) +\n  scale_linetype_manual(name = \"Treatment 2\", values = c(1,1,2)) +\n  \n  \n  # Title and labels\n  ggtitle(\"Target Haemoglobin level is (on average) not reached on Treatment C without concerning (>2 Hgb g/dL) level of change between visits\") +\n  ylab(\"Mean (Standard Error) haemoglobin level [g/dL]\") +\n  xlab(\"Visit\") +\n  \n  # Add lines/text for target range\n  geom_hline(yintercept = c(10, 11.5), colour = Darkblue, linetype = 2, size = .5) +\n  annotate(geom = \"text\", x = c(1.5), y = c(10.75), colour = Darkblue, label = \"Target Range\", fontface = 2) +\n  \n  # Add interpretation arrows (https://stackoverflow.com/questions/17032393/how-to-draw-arrow-in-ggplot2-with-annotation)\n  annotate(geom = \"segment\", x = 1.2, y = c(10.6, 10.9), xend = 1.2, yend = c(10.2, 11.3), colour = Darkblue, size = 1.25,\n           arrow = arrow(length = unit(0.4, \"cm\"))) +\n  \n  # Specify theme\n  theme_bw()\n# theme(plot.margin = unit(c(1,3,7,5), \"lines\")) \n\n## Add some n labels =====\ndat_text <- data.frame(\n  label = c(\"\\n\\n  Treatment C (n = 91)\", \"\\n  Treatment E (n = 12)\", \"Non-inferiority boundary (Control - 0.75)\", \"\\n\\nTreatment C (n = 59)\", \"\\nTreatment E (n = 138)\"),\n  anychg2FLC   = c(rep(\"Change > 2 between any two consecutive visits\", times = 3), rep(\"No change > 2 between any two consecutive visits\", times=2)),\n  TRT01P = c(\"Treatment C\", \"Treatment E\", \"Non-inferiority boundary\", \"Treatment C\", \"Treatment E\"),\n  xx = rep(3.5, times =5),\n  yy = rep(8.5, times = 5)\n)\n\n## Combine plot with text ====\nplota + geom_text(\n  data    = dat_text,\n  mapping = aes(x = xx, y = yy, label = label, colour = TRT01P),\n  hjust   = -0.1,\n  vjust   = -1,\n  inherit.aes = FALSE,\n  show.legend = FALSE\n) +\n  guides(colour = \"none\")\n\nBack to blog\n\nExample 2. Sankey Plot (R)\n\n\nlibrary(ggalluvial)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(RColorBrewer)\n\nOrange <- \"#EF7F04\"\nGreen <- \"#68B937\"\nBlue <- \"#00A6CB\"\nGrey <- \"#4E5053\"\nDarkblue <- \"#003569\"\nYellow <- \"#FFBB2D\"\n\n\nsankey <- read.csv('Sankey.csv')\nsankey$CHG_CAT <- as.factor(sankey$CHG_CAT)\nsankey$BROAD_CHG_CAT <- as.factor(sankey$BROAD_CHG_CAT)\nsankey$AVISITN <- as.factor(sankey$AVISITN)\nsankey$TRT01P <- as.factor(sankey$TRT01P)\nsankey$TARGET <- as.factor(sankey$TARGET)\n\np <- sankey %>%\n#  filter(TRT01PN==1) %>%\n ggplot(aes(x = AVISITN, stratum = CHG_CAT, alluvium=USUBJID, fill = CHG_CAT)) +\n  scale_fill_brewer(type = \"qual\", palette = \"Set2\") +\n  geom_flow(color = \"darkgray\", aes.flow = \"backward\") +\n  geom_stratum() +\n  theme(legend.position = \"bottom\") \n\n\n\np + scale_fill_manual(values = c(\"white\", \"#3FFDBE\", \"#39E3DA\", \"#4AD5FA\", \"#3991E3\"), limits=c(\"1. Baseline\", \"2. <1g/dl\", \"3. 1-2g/dl\", \"4. 2-3g/dl\",\"5. >3g/dl\"), name=\"Change in Hemoglobin \\n since previous visit\") + \n  scale_x_discrete(\"Visit\", labels = c(\"10\" = \"Baseline\",\n                                       \"20\" = \"Week 4\",\n                                       \"30\" = \"Week 8\",\n                                       \"40\" = \"Week 12\",\n                                       \"50\" = \"Week 16\",\n                                       \"60\" = \"Week 20\",\n                                       \"70\" = \"Week 24\"\n)) +\n  scale_y_continuous(\"Number of patients\") +\n  facet_grid(.~ TRT01P) +\n  ggtitle(label = \"Hemoglobin change across observation period was more variable in the control group\", subtitle = \"often fluctuating by more than 2g/dl\") +\n  theme(\n    plot.title = element_text(size = 28, face = \"bold\"),\n    plot.subtitle = element_text(size = 20, face = \"bold\"),\n    legend.title = element_text(size = 18),\n    legend.text = element_text(size = 18),\n    legend.key.size = unit(3, \"line\"))\n\nBack to blog\n\nExample 3. Lasagna Plot (R)\n\n\n####################################################################\n# Program name: hgb_lasagna_f.R\n# Purpose: To produce lasagna plot individual Hgb values at each\n#         visit (for Wonderful Wednesdays July 2020)\n# Written by: Steve Mallett\n# Date: 12-Jun-2020\n####################################################################\n\nlibrary(haven)\nlibrary(stringr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(cowplot)\n\n# flag variables for Hgb changes since previous visit were added prior to import (using SAS)\n\nhgb1 <- read_sas(\"hgb_sim2.sas7bdat\") %>%\n  filter(TRT01PN == 1 & AVISITN != 10) %>%\n  mutate(id = as.numeric(str_extract(USUBJID, \"[^.]+$\")))\n\nplot01 <- ggplot() +\n  geom_raster(data = hgb1, aes(x=AVISITN, y=id, fill=factor(flag)),  interpolate = TRUE, hjust = 0, vjust = 0) +\n  scale_x_continuous(\" \",\n                     breaks=c(20, 30, 40, 50, 60, 70),\n                     labels=c(\"4\", \"8\", \"12\", \"16\", \"20\", \"24\"),\n                     limits=c(10, 70)) +\n  scale_y_continuous(\" \") +\n  scale_fill_manual(\n    values=c(\"#0066CC\", \"#99CCFF\", \"#E0E0E0\", \"#FF9999\", \"#CC0000\"), \n    name=\"Hgb \\nExcursion\\ng/dL\",\n    breaks=c(\"-2\", \"-1\", \"0\", \"1\", \"2\"),\n    labels=c(\"<-2\", \"<-1\", \"None\", \">1\", \">2\")\n    ) +\n  theme_minimal() +\n  theme(legend.position=\"none\",\n        text = element_text(size = 15),\n        axis.ticks.x = element_blank(),\n        axis.text.x =  element_text(size = 15),  \n        axis.text.y =  element_blank(),        \n        axis.ticks.y = element_blank(),\n        axis.title.x = element_text(size = 15),\n        plot.title = element_text(hjust = 0.5, size = 25),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=0.25),\n        panel.grid = element_blank(),\n        plot.margin=unit(c(0,0,0,0),\"cm\")) +\n  ggtitle(label = \"Treatment: E\")\n\nhgb2 <- read_sas(\"hgb_sim2.sas7bdat\") %>%\n  filter(TRT01PN == 2 & AVISITN != 10) %>%\n  mutate(id = as.numeric(str_extract(USUBJID, \"[^.]+$\")))\n\nplot02 <- ggplot() +\n  geom_raster(data = hgb2, aes(x=AVISITN, y=id, fill=factor(flag)),  interpolate = TRUE, hjust = 0, vjust = 0) +\n  scale_x_continuous(\"Week\",\n                     breaks=c(20, 30, 40, 50, 60, 70),\n                     labels=c(\"4\", \"8\", \"12\", \"16\", \"20\", \"24\"),\n                     limits=c(10, 70)) +\n  scale_y_continuous(\" \") +\n  scale_fill_manual(\n    values=c(\"#0066CC\", \"#99CCFF\", \"#E0E0E0\", \"#FF9999\", \"#CC0000\"), \n    name=\"Hgb Change\\nSince Last Visit\\ng/dL\",\n    breaks=c(\"-2\", \"-1\", \"0\", \"1\", \"2\"),\n    labels=c(\"<-2\", \"<-1\", \"None\", \">1\", \">2\")\n  ) +\n  theme_minimal() +\n  theme(legend.position=\"bottom\",\n    text = element_text(size = 15),\n    axis.ticks.x = element_blank(),\n    axis.text.x =  element_text(size = 15),  \n    axis.text.y =  element_blank(),        \n    axis.ticks.y = element_blank(),\n    axis.text = element_text(size = 15),\n    axis.title = element_text(size = 20),\n    plot.title = element_text(hjust = 0.5, size = 25),\n    panel.border = element_rect(colour = \"black\", fill=NA, size=0.25),\n    panel.grid = element_blank(),\n    legend.title=element_text(size=15),\n    legend.text=element_text(size=15),\n    plot.margin=unit(c(0,0,0,0),\"cm\")) +\n  ggtitle(label = \"Treatment: C\")\n\np <- plot_grid(plot01, plot02, align = \"v\", nrow = 2, rel_heights = c(1, 1.19))\n\ntitle <- ggdraw() + draw_label(\"Lasagna Plot of Individual Haemoglobin\\n Changes Since Previous Visit\\n\", size = 25)\n\np2 <- plot_grid(title, p, ncol=1, rel_heights = c(1, 10))  \n\nggsave(\"hgb_lasagna_plot.png\", p2, width=12, height=12, dpi=300)\n\nBack to blog\n\nExample 4. Plot of Hgb Distribution Over Time (R)\n\n\n####################################################################\n# Program name: hgb_quantiles_f.R\n# Purpose: To produce plot summarising spread of Hgb values at each\n#         visit (for Wonderful Wednesdays July 2020)\n# Written by: Steve Mallett\n# Date: 12-Jun-2020\n####################################################################\n\nlibrary(haven)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(cowplot)\n\n# Get Hgb data (Group E)\n\nhgb1 <- read_sas(\"hgb_data.sas7bdat\") %>%\n  filter(TRT01PN == 1)\n\nquant1 <- hgb1 %>% group_by(AVISITN) %>%\n  do(quant = quantile(.$AVAL, probs = seq(0.2,0.8,.05)), probs = seq(0.2,0.8,.05)) %>%\n  unnest(cols=c(quant, probs)) %>%\n  mutate(delta = 2*round(abs(.5-probs)*100)) %>% \n  group_by(AVISITN, delta) %>%\n  summarize(quantmin = min(quant), quantmax= max(quant))\n\n# Derive median Hgb\n\nhgb_med1 <- hgb1 %>% \n  group_by(AVISITN) %>% \n  summarise(hgb.median = median(AVAL)) \n\n# Produce plot for group E\n\nplot01 <- ggplot() +\n  geom_ribbon(data = quant1, aes(x = AVISITN, ymin = quantmin, ymax = quantmax,\n                                    group = reorder(delta, -delta), fill = as.numeric(delta)),\n              alpha = .5) +\n  geom_line(data = hgb_med1, aes(x = AVISITN, y = hgb.median, color = \"dark blue\"), size = 2 ) +  \n  geom_segment(aes(x=10, xend=70, y=10, yend=10), linetype = 2, color = \"blue\") +\n  geom_segment(aes(x=10, xend=70, y=11.5, yend=11.5), linetype = 2, color = \"blue\") +\n  scale_x_continuous(\" \",\n                     breaks=c(10, 20, 30, 40, 50, 60, 70),\n                     limits=c(10, 70)) +\n  scale_y_continuous(\"Hgb (g/dL)\",\n                     breaks=c(8, 9, 10, 11, 12),\n                     limits=c(8, 12),\n                     ) +\n   scale_fill_gradient(low = \"#000080\",\n                       high = \"#87CEFA\",) +\n  scale_color_identity(name = \" \",\n                       guide=legend,\n                       labels = \" \") + \n  theme_minimal() +\n  theme(legend.position=\"none\",\n        axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank(),\n        axis.text.y.left =  element_text(color = 'blue'),        \n        plot.title = element_text(hjust = 0.5, size = 25),\n        text = element_text(size = 15),\n        axis.text = element_text(size = 20),\n        axis.title = element_text(size = 25),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=1),\n        plot.margin=unit(c(1,0,0,0),\"cm\")) +\n  ggtitle(label = \"Treatment Group: E\")\n\n# Get Hgb data (control)\n\nhgb2 <- read_sas(\"hgb_data.sas7bdat\") %>%\n  filter(TRT01PN == 2)\n\nquant2 <- hgb2 %>% group_by(AVISITN) %>%\n  do(quant = quantile(.$AVAL, probs = seq(0.2,0.8,.05)), probs = seq(0.2,0.8,.05)) %>%\n  unnest(cols=c(quant, probs)) %>%\n  mutate(delta = 2*round(abs(.5-probs)*100)) %>% \n  group_by(AVISITN, delta) %>%\n  summarize(quantmin = min(quant), quantmax= max(quant))\n\n# Derive median Hgb\n\nhgb_med2 <- hgb2 %>% \n  group_by(AVISITN) %>% \n  summarise(hgb.median = median(AVAL)) \n\nplot02 <- ggplot() +\n  geom_ribbon(data = quant2, aes(x = AVISITN, ymin = quantmin, ymax = quantmax,\n                                    group = reorder(delta, -delta), fill = as.numeric(delta)),\n              alpha = .5) +\n  geom_line(data = hgb_med2, aes(x = AVISITN, y = hgb.median, color = \"dark blue\"), size = 2) + \n  geom_segment(aes(x=10, xend=70, y=10, yend=10), linetype = 2, color = \"blue\") +\n  geom_segment(aes(x=10, xend=70, y=11.5, yend=11.5), linetype = 2, color = \"blue\") +\n  scale_x_continuous(\"Week\",\n                     breaks=c(10, 20, 30, 40, 50, 60, 70),\n                     labels=c(\"0\", \"4\", \"8\", \"12\", \"16\", \"20\", \"24\"),\n                     limits=c(10, 70)) +\n  scale_y_continuous(\"Hgb (g/dL)\",\n                     breaks=c(8, 9, 10, 11, 12),\n                     limits=c(8, 12),\n                     ) +\n  scale_fill_gradient(\n                      low = \"#000080\",\n                      high = \"#87CEFA\") +\n  scale_color_identity(name = \"Median\",\n                       guide=legend,\n                       labels = \" \") + \n  labs(fill = \"Hgb (% patients in band)\") +\n  theme_minimal() +\n  theme(legend.position=\"bottom\",\n        plot.title = element_text(hjust = 0.5, size = 25),\n        text = element_text(size = 15),\n        axis.text = element_text(size = 20),\n        axis.title = element_text(size = 25),\n        axis.text.y.left =  element_text(color = 'blue'),\n        legend.text=element_text(size=14),\n        legend.title=element_text(size=20),\n        legend.key.size = unit(1.2, \"cm\"),        \n        panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  guides(colour = guide_legend(override.aes = list(size=3))) +\n  ggtitle(label = \"Treatment Group: C\")\n\np <- grid.arrange(arrangeGrob(plot01, ncol=1, nrow=1),\n                  arrangeGrob(plot02, ncol=1, nrow=1),\n                  heights = c(1,1.32))\n\ntitle <- ggdraw() + draw_label(\"Treatment E Stabilises Haemoglobin Within Target Range\\n With Reduced Variability\", size = 25)\n\np2 <- plot_grid(title, p, ncol=1, rel_heights = c(1, 10))  \n\nggsave(\"hgb_plot_quantiles.png\", p2, width=12, height=12, dpi=300)\n\nBack to blog\n\n\n",
    "preview": "posts/2020-09-20-wonderful-wednesdays-july-2020/./images/June_PSI_AW_v1_0.png",
    "last_modified": "2020-10-30T20:01:56+01:00",
    "input_file": {},
    "preview_width": 1268,
    "preview_height": 507
  },
  {
    "path": "posts/2020-09-11-wonderful-wednesdays-june-2020/",
    "title": "Wonderful Wednesdays June 2020",
    "description": "This month the discussion is about visualizations of the satisfaction data using cumulative distribution functions, a tree plot, staggered bar plots, a power BI dashboard and two interactive funnel plots using plotly and RShiny. These examples nicely demonstrate that different displays support different purposes. Some visualizations are telling a story about the data and others help to explore the data. Presented by Bodo Kirsch.",
    "author": [
      {
        "name": "Markus Vogler",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2020-06-10",
    "categories": [
      "Wonderful Wednesdays",
      "Subgroups",
      "Discrete endpoint"
    ],
    "contents": "\nThe example dataset for this month’s webinar was based on a survey of overall satisfaction performed in Germany in 2014 and published in 2016. The primary endpoint was overall satisfaction with life.\nThe question posed to the participants was: “How would you rate your satisfaction with your life overall on a scale from 0-10?”, where 10 means completely satisfied. There was only one observation per participant and no treatment groups, as no treatment was administered.\nThe objective of this survey was to explore the most relevant factors for satisfaction in life. Several factors, such as smoking status, working hours per week or number of doctor visits per year were collected. The dataset and its specification can be found here here. \nWe received a variety of submissions and we would like to thank everyone for their contributions. The visualizations that were presented during the June 2020 Wonderful Wednesday webinar are described below, with a few discussion points highlighted. To see the full discussion around each of the visualizations, check out the webinar recording in the PSI Video-on-Demand library. The subtitles contain the timestamps of the webinar recording, in case you would like to listen to the discussion around a specific visualization.\n\nExample 1. CDF plot (03:10 - 08:50)\nPlot 1link to codehigh-resolution image\nThe first submission discussed during this webinar was a cumulative distribution function (CDF) plot with the cumulative proportion of subjects on the vertical axis and the satisfaction with life on the horizontal axis. This horizontal axis has been reversed, ranging from highest satisfaction (10; on the left) to lowest satisfaction (0; on the right). This is also highlighted by the arrow labelled “Less satisified”, which is very helpful. The curves show the proportion of subjects reaching a certain level of satisfaction or higher. The difference between non-smokers and smokers can be clearly seen in this graph, with non-smokers being more satisfied with life than smokers. This message is also communicated in the title of the graph.\nThe graph is very well designed with little to no visual clutter, which helps to focus on the actual data. A suggestion for improvement would be to place the subgroup labels directly next to the lines and to use the same color for the subgroup labels that was used for the lines which would allow removing the legend symbols.\nTo further highlight the difference between the two groups, it could be helpful to fill the area between the two curves using the color of the more satisfied group (or vice versa). This could even be shown as an additional bar chart below this visualization. This would facilitate comparing subgroup differences at the various cut-offs.\nIn summary, this graph is very effective for communicating a simple and clear message and could be used in a presentation. It appears that the creator of this graph already went through the process of exploring the data to reach the conclusion that smoking status is a relevant factor for satisfaction of life. Examples for exploratory visualizations that could help with reaching such a conclusion were also submitted and are discussed further below.\n\nExample 2. Treeplot (08:50 - 12:10)\nPlot 2link to codehigh-resolution image\nThe second submission discussed during the webinar was a treeplot. The title contains the question that was posed to the participants and the subtitle describes that the tile sizes are proportional to the subgroup sizes. The mean satisfaction within subgroups is color-coded, as shown in the legend.\nThis plot gives a quick overview of the subgroups, allowing to see all the data visually in one place, which is great. The use of the font size could be improved. At first glance, it appears that it was coded with the data, but it seems it has more to do with the space constraints and the size of the tiles. For example, the font size for smoking status “N” and “Y” is the same but the size of the tiles indicates that the non-smoker group is much larger compared to the smoker group.\n\nExample 3. Bar plots (12:10 - 17:20)\nPlot 3link to codehigh-resolution image\nThe next visualization was specifically designed for a presentation. It starts of with a question (“How meaningful is a mean difference?”) and tries answering that question through a series of bar plots, looking at the data in different ways. This submission focuses on one single factor (smoking status), as already seen in the CDF plot above.\nThe first bar plot in the top left shows a statistically significant mean difference on an adapted scale from 6 to 8. In the top right we can see a very similar plot but this time on the complete scale from 0 to 10, which makes the magnitude of the difference appear much smaller. The stacked bar plot at the bottom shows a significant difference between the two response distributions instead of only comparing the means. Like the CDF plot, this visualization shows that non-smokers are performing better than smokers, regardless of the cut-off that is chosen.\nInterestingly, a divergent color scheme was used in the stacked bar chart. A suggestion to make the comparisons in the stacked bar chart even easier would be to add reference lines connecting the different areas/cut-offs.\nIn summary, this is a well thought through visualization example.\n\nExample 4. Power BI dashboard (17:20 - 26:45)\nPlot 4link to codehigh-resolution image\nThis submission is an interactive Power BI dashboard. The number of participants and overall mean is given in the top left. A stacked bar chart as well as a classic bar plot show the distribution of the satisfaction responses. The factors are shown in supplementary bar plots below. In these bar plots a subgroup can be selected and all the other plots will adapt automatically. Check out the recording of the webinar here (starting at 17:20) to see how the interactivity works in practice.\nThis can be a very useful and easy tool to explore the data, replacing many tables. The arrangement of the different tiles on the dashboard seems also well thought through, starting with the main results in the top left and finishing with the summary results in the bottom right.\nIt is not entirely clear why some of the bar plots are vertical while others are horizontal. A horizontal presentation can be useful when labels are long to increase readibility, however, a consistent approach could be chosen.\n\nExample 5. Funnel plot (26:45 - 37:20)\nPlot 5link to codehigh-resolution image\nThe next submission is an interactive visualization as well. In this funnel plot, each dot represents a subgroup estimate. This is the first visualization that does not only explore the factors in isolation, but also looks at all possible combination of subgroups. The overall mean with 95% prediction intervals is also shown. The vertical axis represents the average satisfaction ranging from 0 to 10 and the horizontal axis the subgroup size, i.e., larger subgroups are shown more to the right.\nThe name, the size and the mean of a specific subgroup becomes visible by hovering over a dot. This tool is specifically useful to explore extreme values. Check out the recording of the webinar here (starting at 26:45) to see how the interactivity works in practice.\nMost data points are squeezed towards the top left of the plot, given that the full scale is shown on both axes, causing a lot of white space. The visualization does include an interactive zooming option. A couple of other suggestions to allow zooming in are: 1) the subgroup size could be shown on a logarithmic scale; 2) apply a minimum threshold to the subgroup size because the very small subgroups are usually not of interest.\nAdditional interesting interactive tools could be: 1) highlight all subgroups related to a certain factor, e.g., all subgroups relevant for smoking status. This would allow quicker identification of relevant factors. 2) when hovering over one subgroup, the complement of this subgroup could be highlighted as well.\nIn summary, this is a great, innovative idea to explore subgroups.\n\nExample 6. Funnel plot (37:20 - 48:45)\nPlot 6link to codehigh-resolution image\nThis submission is similar to the funnel plot seen above but providing additional features, such as:\nSpecific subgroups can be highlighted. For example, by selecting the non-smokers, it becomes apparent that most subgroups including non-smokers lie above the mean reference line.\nThe shading of the dots is linked to the number of subgroup levels. The white dots represent single-level factors while the more transparent dots represent higher level subgroups. The number of subgroup levels displayed can also be controlled (e.g., only 1-factorial subgroups could be displayed).\nAll parent subgroups of a selected subgroup can be highlighted. This could be used to explore the driving factors among a combination of factors forming a subgroup.\nCheck out the recording of the webinar here (starting at 37:20) to see more details.\nCode\n\nExample 1. CDF plot (R)\n\n\n### Load packages\nlibrary(here)\nlibrary(tidyverse)\n\n### Load data\ndata <- data.frame(read_delim(here(\"Satisfaction_wW2005.csv\"), delim=';'))\ndata$smoker <- ifelse(data$smoker == \"Y\", \"Smoker\", ifelse(data$smoker == \"N\", \"Non-smoker\", NA))\n\n### Only keep non-missing data\ndata_nonmiss <- na.omit(data[, c(\"satisfaction\", \"smoker\")])\n\n### Derive number of subjects within subgroups\nn <- data_nonmiss %>% group_by(smoker) %>% summarize(n = n())\n  \n### Create label variable including number of subjects\ndata_n <- merge(data_nonmiss, n, by = \"smoker\")\ndata_n$group <- paste0(data_n$smoker, \" (n = \", data_n$n, \")\")\n  \n### Plot\nggplot(data = data_n, aes(x = satisfaction, colour = group)) +\n  stat_ecdf(size = 1, alpha = 0.5) +\n  theme_minimal(base_size = 15) +\n  scale_x_reverse(name = \"Satisfaction with life\", breaks = seq(0, 10, 1), minor_break = NULL) +\n  scale_y_continuous(name = \"Cumulative proportion of subjects\", breaks = seq(0, 1, 0.25), minor_break = NULL) +\n  scale_color_manual(name = NULL, values = c(\"#E7B800\", \"#2E9FDF\")) +\n  theme(legend.position = c(0.15, 0.85)) +\n  geom_segment(aes(x = 4.5, y = 0.5, xend = 2.5, yend = 0.5), colour = \"black\", size = 1, arrow = arrow(length = unit(0.5, \"cm\"))) +\n  annotate(\"text\", x = 3.5, y = 0.53, label = \"Less satisfied\", size = 5, colour = \"black\") +\n  ggtitle(\"Non-smokers more satisfied with life than smokers\") +\n  NULL\n\nggsave(file = here(\"cdf_smoker.png\"), width = 35, height = 20, units = \"cm\")\n\nBack to blog\n\nExample 2. Treeplot (R)\n\n\nlibrary(ggplot2)\nif (!require('treemapify')) install.packages('treemapify');\nif (!require('dplyr')) install.packages('dplyr');\nif (!require('RColorBrewer')) install.packages('RColorBrewer');\nlibrary(treemapify)\nlibrary(dplyr)\nlibrary(RColorBrewer)\n\n# read data\ndata <- read.csv(url('https://raw.githubusercontent.com/VIS-SIG/Wonderful-Wednesdays/master/data/2020/2020-05-13/Satisfaction_wW2005.csv'), na.strings = c(\".\", \"\"), header = TRUE)\n\nfoo_summarize<- function(dat = data, my_var = NULL, group_label = \"NA\"){\n    \n   suppressWarnings(\n     ans<- dat %>%\n        filter(!is.na(satisfaction)) %>%\n        group_by({{my_var}}) %>%\n        summarize(n = n(), \n                  mean_satisfaction = mean(satisfaction)) %>%\n        mutate(percent = n / sum(n)*100) %>%\n        mutate(group = group_label) %>%\n        rename(Variable = names(.)[1])\n   )\n  \n   return(ans)\n}\n\n#age\nd_age<- foo_summarize(dat=data, my_var=age, group_label = \"Age\")\nd_bmi<- foo_summarize(dat=data, my_var=bmi, group_label = \"BMI\")\nd_w_hours<- foo_summarize(dat=data, my_var=w_hours, group_label = \"Working hours\")\nd_todoctor<- foo_summarize(dat=data, my_var=todoctor, group_label = \"Doctor visits per year\")\nd_income<- foo_summarize(dat=data, my_var=income, group_label = \"Net income\")\nd_smoker<- foo_summarize(dat=data, my_var=smoker, group_label = \"Smoker\")\nd_gender<- foo_summarize(dat=data, my_var=gender, group_label = \"Gender\")\nd_employed<- foo_summarize(dat=data, my_var=employed, group_label = \"Employment status\")\nd_graduat<- foo_summarize(dat=data, my_var=graduat, group_label = \"Graduation\")\nd_graduat_f<- foo_summarize(dat=data, my_var=graduat_f, group_label = \"Graduation of father\")\nd_graduat_m<- foo_summarize(dat=data, my_var=graduat_m, group_label = \"Graduation of mother\")\nd_high_grad<- foo_summarize(dat=data, my_var=high_grad, group_label = \"Highest educational grade\")\nd_high_grad_f<- foo_summarize(dat=data, my_var=high_grad_f, group_label = \"Highest educational grade (father)\")\nd_high_grad_m<- foo_summarize(dat=data, my_var=high_grad_m, group_label = \"Highest educational grade (mother)\")\n\nd_all<- do.call(rbind, list(d_age, d_bmi, d_w_hours, d_todoctor, d_income, d_smoker, d_gender, d_employed, d_graduat,\n                            d_graduat_f, d_graduat_m, d_high_grad, d_high_grad_f, d_high_grad_m))\n\n# replace NA with a category: Missing. Only explanatory vars are affected. Response (satisfaction) has no missings\nd_all$Variable<- as.character(d_all$Variable)\nd_all$Variable[which(is.na(d_all$Variable))]<- \"Missing\"\n\n# create descrete response variable to display colors in the plot better\nd_all$satisfation_categories<- cut(d_all$mean_satisfaction, \n                                   breaks=seq(round(min(d_all$mean_satisfaction)), round(max(d_all$mean_satisfaction)), 0.5), \n                                   labels=c(\"(6,6.5]\", \"(6.5,7]\", \"(7,7.5]\", \"(7.5,8]\", \"(8,8-5]\", \"(8.5-9]\"), right = TRUE)\n\n# create response with label\nd_all$satisfaction_lab<- paste(d_all$Variable, \" (\", round(d_all$mean_satisfaction, 1), \")\", sep = \"\")\n\n# colors for plot\ncol_palette<- display.brewer.pal(n = 6, name = 'RdYlBu')\npalette<- brewer.pal(n = 6, name = 'RdYlBu')\n\n\n\n# plot\nggplot(d_all, aes(area=percent, label = Variable, fill = satisfation_categories, subgroup = group)) + \n            geom_treemap() + \n            geom_treemap_subgroup_border(size = 1.5, color = \"black\") +\n            geom_treemap_text(grow = T, reflow = T, place = \"topleft\", layout = \"scol\", min.size = 1,\n                              color = \"Darkblue\", size = 10) +\n            scale_fill_manual(values = palette) + \n            facet_wrap( ~ group) + \n            theme(legend.position = \"bottom\", \n                  legend.text = element_text(color=\"black\", size = 18), \n                  legend.title = element_text(size = 18),\n                  plot.title = element_text(size = 24),\n                  plot.subtitle = element_text(size = 20), \n                  plot.caption = element_text(size = 14),\n                  strip.text = element_text(size = 14, face = \"bold\", color = \"Darkblue\")) +\n            labs(title = 'How would you rate your satisfaction with your life overall on a scale from 0-10? (10=completely satisfied)',\n                 subtitle = 'Descriptive analysis by subgroup: tiles are proportional to rel. frequencies of the choices within a subgroup',\n                 caption =\"Created with ggplot2-treemapify\",\n                 fill = \"Mean Satisfaction\")\n\n\nggsave(\"treeplot_may2020.png\", width = 24, height = 12, units=\"in\", dpi = 300)\n\nBack to blog\n\nExample 3. Bar plots (R)\n\n\nlibrary(tidyverse)\nlibrary(Stack)\nlibrary(viridis)\nlibrary(IOHanalyzer)\nlibrary(car)\nlibrary(RColorBrewer)\ndisplay.brewer.all(colorblindFriendly = TRUE)\nlibrary(cowplot)\nlibrary(dgof)\n\n#Colour Scheme\nOrange <- \"#EF7F04\"\nGreen <- \"#68B937\"\nBlue <- \"#00A6CB\"\nGrey <- \"#4E5053\"\nDarkblue <- \"#003569\"\nYellow <- \"#FFBB2D\"\n\n#Load in data and make satisfaction and all other variables a factor. Also make a numeric version of satisfation for use late\nCohort <- read_csv('Cohort.csv') %>%\n  mutate(satisfaction = factor(satisfaction, level=c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))) %>%\n  mutate_all(factor) %>%\n  mutate(NumSat = as.numeric(satisfaction)) %>%\n  mutate(NumSat = NumSat-1) #To put it back on a 0-10 scale\n\n#Calculate means for the groups\nmeans <- Cohort %>%\n  group_by(smoker) %>% \n  summarise(\n    NumSat = mean(NumSat, na.rm = TRUE) \n  ) %>%\n  filter(!is.na(smoker)) #filter out the means for patients without a value for smoking (some implicit NA's)\n\n#Significance test of mean differences\nmodel <- lm(NumSat ~ smoker, data = Cohort)\nsummary(model)\n\n#test of distributions\nSmokerSat <- Cohort %>%\n  select(smoker, NumSat) %>%\n  filter(smoker==\"Y\")\n\nNonSmokerSat <- Cohort %>%\n  select(smoker, NumSat) %>%\n  filter(smoker==\"N\")\n\nKS <- ks.test(SmokerSat$NumSat, NonSmokerSat$NumSat)\n\n\n#Make plot of means, \np <- ggplot(means, aes(x=smoker, y=NumSat)) +\n  geom_bar(stat=\"identity\", fill=Darkblue, color=\"black\", xpd = FALSE) +\n  scale_y_continuous(name = \"Satisfaction (0-10)\") +\n  scale_x_discrete(name = \"Smoking History\", \n                   labels=c(\"Non-Smoker\",\"Current Smoker\"))\n\n\n#Fake plot for  aesthetic purporposes (remove the bar going below \"6\" on the chart with the reduced y axis)\n   #Start with fake dataset\nsmoker <- c(\"N\", \"Y\")\nNumSat <-c(6,6)\nfake.data <- data.frame(smoker,NumSat)\n\n\n# make plot 1 where the scale is changed to emphasize difference\nplot1 <- p+coord_cartesian(ylim=c(6,8.1))+\n  theme_classic() +\n  theme(line = element_blank()) +\n  geom_bar(data=fake.data,stat=\"identity\", fill=\"white\", color=\"white\") +  #Add a white rectangle below the \"6.0\" line using fake data\n  ggtitle(\"A statistically significant difference in Satisfaction between Non-smokers and Smokers \\n highlighted by using misleading axis... \\n\") +\n  theme (plot.title = element_text(family = \"sans\", color=Grey, face=\"bold\", size=14, hjust=0.5)) + #Edit font\n  annotate(\"segment\", x = \"N\", xend = \"Y\", y = 8.0, yend = 8.0,\n           colour = \"black\") +\n  annotate(\"segment\", x = \"N\", xend = \"N\", y = 8.0, yend = 7.9,\n           colour = \"black\") +\n  annotate(\"segment\", x = \"Y\", xend = \"Y\", y = 8.0, yend = 7.9,\n           colour = \"black\") + \n  annotate(\"segment\", x = 1.5, xend = 1.58, y = 8.0, yend = 8.1,\n           colour = \"black\") +\n  annotate(geom = \"text\", x = 1.6, y = 8.05, label = \"Significant!\", hjust = \"left\", vjust = \"bottom\", size = 6) +\n  annotate(geom = \"text\", x = 2.0, y = 8.05, label = \"(p<0.001)\", hjust = \"left\", vjust = \"bottom\", size = 2) \n  \n\n# make plot 2 which uses oringinal 0-10 scale\nplot2 <- p+coord_cartesian(ylim=c(0,10)) +\n  theme_classic() +\n  theme(line = element_blank()) + \n  ggtitle(\".. But when plotted using the 0-10 scale, the true (small) magnitude of \\n this difference is apparent \\n \") +\n  theme (plot.title = element_text(family = \"sans\", color=Grey, face=\"bold\", size=14, hjust=0.5)) + #Edit font\n  annotate(\"segment\", x = \"N\", xend = \"Y\", y = 9.6, yend = 9.6,\n           colour = \"black\") +\n  annotate(\"segment\", x = \"N\", xend = \"N\", y = 9.6, yend = 9.1,\n           colour = \"black\") +\n  annotate(\"segment\", x = \"Y\", xend = \"Y\", y = 9.6, yend = 9.1,\n           colour = \"black\") + \n  annotate(\"segment\", x = 1.5, xend = 1.33, y = 9.6, yend = 10,\n           colour = \"black\") +\n  annotate(geom = \"text\", x = 1.3, y = 9.8, label = \"Meaningful?\", hjust = \"right\", vjust = \"bottom\", size = 6) \n\n\n\n# make plot 3 - a staked bar chart to show distributional changes\nCohort$smoker %>% mutate(fct_reorder(smoker, NumSat, .fun=\"mean\"))\n\n\nplot3 <- ggplot(data=subset(Cohort, !is.na(smoker)), aes(y = reorder(smoker, NumSat))) +\n  geom_bar(aes(fill = satisfaction), position = position_fill(reverse = TRUE)) +\n  scale_fill_brewer(palette=\"BrBG\") +\n  guides(fill = guide_legend(nrow = 1)) +\n  ggtitle(\"Significant difference between the two response distributions \\n (D=0.14, p<.001)\") +\n  theme_classic() +\n  theme(line = element_blank()) +\n  theme(legend.position = \"bottom\", legend.box = \"horizontal\")+\n  xlab(\"Proportion of participants selecting each 'Satisfaction' value\") + \n  scale_y_discrete(name = \"Smoking History\", \n                   labels=c(\"Current Smoker\",\"Non-Smoker\")) +\n  scale_x_continuous(breaks = c(0, .25, .50, .75, 1.00))\n  ggtitle(\"The response distribution shows that smokers reported lower satisfaction scores (0-5) more often than non-smokers \\n and higher satisfaction scores (9-10) less often than non-smokers\") +\n  theme (plot.title = element_text(family = \"sans\", color=Grey, face=\"bold\", size=18, hjust=0.5))  #Edit font\n  \n#plot3 <- plot3 +  annotate(geom = \"curve\", x = 0.50, y = 2.60, xend = 0.65, yend = 2.45, \n#           curvature = -.25, arrow = arrow(length = unit(3, \"mm\"))\n#  ) +\n#  annotate(geom = \"text\", x = 0.5, y = 2.55, label = \"Significant difference in distributions \\n (D=0.14, p<.001)\", hjust = \"center\", size = 3)\n\n#design layout\n  # Make a title\ntitle <- ggdraw() + \n  draw_label(\n    \"How Meaningful is a Mean Difference?\",\n    fontface = 'bold',\n    x = 0,\n    hjust = 0,\n    size = 22\n  ) +\n  theme(\n    # add margin on the left of the drawing canvas,\n    # so title is aligned with left edge of first plot\n    plot.margin = margin(0, 0, 0, 7)\n  )\n\ntop_row <- plot_grid(plot1, plot2, labels = c(\"A\", \"B\"), align = \"h\")\nFaceted_graphs <- plot_grid(top_row, plot3, labels = c(' ', 'C'), label_size = 12, ncol = 1)\n\nplot_grid(title, Faceted_graphs,  \n          ncol = 1,\n          # rel_heights values control vertical title margins\n          rel_heights = c(0.1, 1)\n  )\n\nBack to blog\n\nExample 4. Power BI dashboard\n\n\nPSI survey\n\nhttps://app.powerbi.com/view?r=eyJrIjoiOTZkOTVkYTEtMzE3OC00YTAzLWIyZGYtODZhZWYwYzM5MzQ1IiwidCI6ImY1NTgwM2MzLTRmYTktNDIzMy1hOGFiLTIxM2I3ZWI3MjEzNCJ9\n\nBack to blog\n\nExample 5. Funnel plot (R)\n\n\n##### code for funnel plot for submittion\nlibrary(doParallel)\nlibrary(data.table)\nlibrary(plotly)\nlibrary(tidyverse)\n\ndata_transform <- function(x, \n                           labels = c(\"low\", \"high\"), \n                           except = NULL, \n                           threshold = 0.1, \n                           explicit_conv = NULL, \n                           explicit_conv_override = FALSE, \n                           binary_categories = FALSE, \n                           n_binary_categories=1, \n                           verbose = FALSE) {\n  \n  x_new <- x\n  cutoff <- floor(threshold * nrow(x_new)) # if number of unique values is less than 10% of overall dataset size, treat corresponding covariate as categorical\n  if(!is.null(explicit_conv) && explicit_conv_override){\n    cutoff <- Inf\n  }\n  for (column in colnames(x_new)[!colnames(x_new) %in% except]) {\n    fac <- as.factor(x[, column])\n    if ((nlevels(fac) > cutoff) || column %in% explicit_conv) {\n      if (!binary_categories) {\n        n_quant <- length(labels) # number of quantiles\n        quant <- quantile(x_new[, column], probs = 0:n_quant / n_quant, na.rm = TRUE)\n        if (verbose) {message(sprintf(\"Transforming %s to categorical using following quantiles\", column))}\n        if (verbose) {message(paste0(capture.output(quant), collapse = \"\\n\"))}\n        x_new[, column] <- cut(x_new[, column], quant, include.lowest = TRUE, labels = labels)\n      } else {\n        n_quant <- n_binary_categories+1 # number of quantiles\n        quant <- quantile(x_new[, column], probs = 0:n_quant / n_quant, na.rm = TRUE)\n        if (verbose) {message(sprintf(\"Transforming %s to binary categorical columns using following quantiles\", column))}\n        if (verbose) {message(paste0(capture.output(quant), collapse = \"\\n\"))}\n        for (j in 2:(length(quant) - 1)) {\n          x_new[, sprintf(\"%s_q%s\", column, substr(names(quant)[j], 1, 2))] <-\n            as.factor(cut(x_new[, column], c(quant[1], quant[j], quant[length(quant)]), include.lowest = TRUE, labels = FALSE))\n          levels(x_new[, sprintf(\"%s_q%s\", column, substr(names(quant)[j], 1, 2))]) <- c(0, 1)\n        }\n        # remove orignal column\n        x_new[, column] <- NULL\n      }\n    }\n    else if (typeof(x[, column]) != \"integer\") {\n      if (verbose) {message(sprintf(\"Convert %s to factors\", column))}\n      x_new[, column] <- as.factor(x[, column])\n    }\n  }\n  \n  return(x_new)\n}\n\n\n\n\nreturn_subgroups <- function(x, \n                             eval_fun, \n                             covs, \n                             packages=NULL, \n                             comb = 3, \n                             comb_lowerbound = 1, \n                             n_cores = 1, \n                             first_N = Inf, \n                             verbose = !(first_N==Inf)) {\n  \n  \n  \n  data_cov_comb <- function(vec, k, n = length(vec),verbose = FALSE) {\n    # returns all n over k combinations of elements in vec\n    # n should be size of vec and k<=n\n    if(verbose){message(sprintf(\"Computing %s combinations out of\",k))}\n    if(verbose){message(paste0(capture.output(vec), collapse = \"\\n\"))}\n    return(gtools::combinations(n, k, vec))\n  }\n  \n  \n  data_level_comb <- function(x, covs) {\n    # takes a dataframe x where every column is of type integer/factor and computes all combinations between all the levels of covariates specified in covs\n    return(tidyr::expand(x, x[covs]))\n  }\n  \n  compute_eval <- function(x, covs, eval_fun, first_N_active = FALSE) {\n    # computes the evaluation function on all subgroup combination of given covariates in covs (vector of strings)\n    # returns a list with number of entrys equal to the number of possible covariate level combinations.\n    # Each entry consits of two elements:\n    # first entry contains the filtered dataset containing only subgroup datapoints\n    # second entry contains single line dataframe output of eval_func augmented by subgroup labels\n    comb <- data_level_comb(x, covs)\n    \n    if (first_N_active) {\n      if (first_N_count <= nrow(comb)) {\n        comb <- comb[1:first_N_count, ]\n        first_N_count <<- 0\n      } else {\n        first_N_count <<- first_N_count - nrow(comb)\n      }\n    }\n    \n    subframes <- foreach(i = 1:nrow(comb)) %do% {\n      x_filtered <- x\n      for (j in 1:length(covs)) {\n        x_filtered <- dplyr::filter(x_filtered, x_filtered[covs[j]] == as.character(unlist(comb[i, j])))\n      }\n      result <- eval_fun(x_filtered)\n      result[covs] <- comb[i, ]\n      \n      return(result)\n    }\n    return(subframes)\n  }\n  \n  #check if provided covs are contained in x\n  for (name in covs) {\n    if (!(name %in% colnames(x))) {\n      stop(sprintf(\"Variable %s was not found in %s\", name, toString(substitute(x))))\n    }\n  }\n  \n  #turn on verbose if first_N != Inf \n  if (first_N!=Inf){verbose <- TRUE} \n  \n  cl <- makeCluster(n_cores)\n  registerDoParallel(cl)\n  \n  if(verbose){message(sprintf(\"Number of cores: %s\", getDoParWorkers()))}\n  \n  # computes the evaluation function on all subgroup combination of given covariates in covs (vector of strings) for 1,2 and 3 combinations(general: comb_lowerbound:comb)\n  if (first_N == Inf) {\n    results <- foreach(i = comb_lowerbound:comb, .combine = c) %do% {\n      covs_comb <- data_cov_comb(covs, i,verbose=verbose)\n      track_time <- system.time({\n        result <- foreach(j = lapply(as.list(1:dim(covs_comb)[1]), function(x) covs_comb[x[1],]), .combine = c, .packages = c(\"foreach\", packages)) %dopar% {\n          compute_eval(x, j, eval_fun)\n        }\n      })\n      if(verbose){message(paste0(capture.output(track_time), collapse = \"\\n\"))}\n      return(result)\n    }\n  } else {\n    if(verbose){message(sprintf(\"Computing first %d subgroups using single core\", first_N))}\n    first_N_count <<- first_N\n    results <- foreach(i = comb_lowerbound:comb, .combine = c) %do% {\n      covs_comb <- data_cov_comb(covs, i,verbose=verbose)\n      track_time <- system.time({\n        result <- foreach(j = 1:min(nrow(covs_comb), first_N), .combine = c, .packages=c(packages)) %do% {\n          if (first_N_count == 0) {\n            return()\n          }\n          res <- compute_eval(x, covs_comb[j, ], eval_fun, first_N_active = TRUE)\n        }\n      })\n      if(verbose){message(paste0(capture.output(track_time), collapse = \"\\n\"))}\n      return(result)\n    }\n  }\n  \n  stopCluster(cl)\n  \n  return(dplyr::bind_rows(results))\n}\n\n############################################################################################\n############# read data\ndat <- read.csv(\"./Satisfaction_wW2005.csv\") %>%\n  as.data.frame() %>% dplyr::select(-X, -ID) \n\n### global mean and se\ndat_mean <- mean(dat$satisfaction)\ndat_se <- sd(dat$satisfaction)/sqrt(nrow(dat))\ndat_sd <- sd(dat$satisfaction)\n\nfit <- function(x) {\n  cf1 <- tryCatch({\n    cf <- mean(x$satisfaction)\n    se <- sd(x$satisfaction)/sqrt(nrow(x))\n    c(cf, se,nrow(x))\n  },\n  warning = function(w) { #warning handling\n    NA\n  }, error = function(w) { #error handling\n    c(dat_mean,dat_se,0)\n  }\n  )\n  return(data.frame(av = cf1[1], se = cf1[2], N = cf1[3]))\n}\n\nsubgroups <- return_subgroups(dat, \n                              fit,\n                              comb = 3, \n                              comb_lowerbound = 1,\n                              covs = colnames(dat)[1:14],\n                              # first_N = 100, \n                              n_cores = 4,\n                              verbose = TRUE)\n# head(subgroups)\n\nnams <- names(subgroups)[-c(1:3)]\nsubgroups$text <- NULL\nsubgroups$text <- apply(subgroups, 1, function(x){\n  covs <- x[-c(1:3)]\n  ind <- which(!is.na(covs))\n  p1 <- NULL\n  for(i in 1:length(ind)){\n    p1 <- c(p1, sprintf(\"%s=%s\", nams[ind[i]], covs[ind[i]]))\n  }\n  p1 <- paste(p1, collapse=\",\")\n  p2 <- sprintf(\"|satisfaction=%.1f, N=%d\", as.numeric(x[1]),as.numeric(x[3]))\n  paste0(p1, p2)\n})\n\n\n## calculate dfs (assuming balance)\nn_start <- 2\nN <- n_start:nrow(dat)\nq95 <- qt(0.975, df= N - 1)\nci <- data.frame(N = N,\n                 lb = dat_mean - q95*dat_sd/sqrt(N),\n                 ub = dat_mean + q95*dat_sd/sqrt(N))\n\nfig <- subgroups %>% filter(N >= n_start) %>% \n  plot_ly(x = ~ N, y = ~av) %>%\n  add_markers(name = 'Subgroup Estimates',text = ~text, hoverinfo = \"text\",\n              color = I(\"blue\"), alpha=0.2)%>%\n  add_markers(x = nrow(dat), y = dat_mean,\n              name = 'Overall Estimates',text = I(paste0(\"satisfaction = \",round(dat_mean,2))), \n              hoverinfo = \"text\",color = I(\"red\"),alpha=0.2)%>%\n  add_lines(x = ~ ci$N, y = ~ ci$lb, name = 'Lower 95% PI', hoverinfo = 'skip', \n            color = I(\"black\"), alpha=0.5) %>%\n  add_lines(x = ~ ci$N, y = ~ ci$ub, name = 'Upper 95% PI', hoverinfo = 'skip', \n            color = I(\"black\"), alpha=0.5) %>%\n  add_lines(x = I(n_start:nrow(dat)), y = dat_mean, \n            name = \"Overall mean\",hoverinfo = 'skip', color = I(\"red\"),alpha=0.5) %>%\n  layout(xaxis = list(range = c(n_start,(nrow(dat)+4)),title = \"Subgroup size\"),\n         yaxis = list(range = c(1, 10),title = \"Average satisfication\"))\nfig\nhtmlwidgets::saveWidget(fig, \"./funnel_satisfaction.html\")\n\nBack to blog\n\nExample 6. Funnel plot (R)\n\n\n###############################################################################\n# Bayer AG\n# Study            :\n# Proj/Subst/GIAD  :\n###############################################################################\n# Name of program #############################################################\n# Name             : SGS_WW2005.R\n#\n# Purpose          : Run subgroup screening  \n# Programming Spec :\n# Validation Level : 1 - Verification by Review\n# R Version        : 4.0.0 (64 bit) on simulation server\n###############################################################################\n# Pre-conditions   : data source: ALLBUS dataset 2014/subset\n# Post-conditions  :\n# Comments         :\n###############################################################################\n# Author(s)        : Bodo Kirsch  03JUN2020\n# Reference prog   : SGS\n###############################################################################\n# Changed by       : \n# Reason           :\n###############################################################################\n\n\n\n### delete workspace\nrm(list=ls())\n\n\n### AutoSub and load libraries\n#setwd(\"c:/temp\")\n\n\nlibrary(shiny)\nlibrary(subscreen)\n\n\n### import data\nD=read.csv2(file=\"Data_wW2005.csv\", sep=\",\", dec=\".\", header=TRUE)\n\n\nauwe <- function(D){\n  \n    # --- satisfaction mean ----------------------------------------------------------------\n  \n      satisfact  <- round(mean(D$satisfaction, na.rm = TRUE), 2)   # TRUE:  NA values stripped before the computation proceeds\n      \n      number.of.subjects     <- sum(!is.na(D$satisfaction))\n  \n    return(data.frame(number.of.subjects, satisfact))\n}\n\n\nHH <- subscreencalc(data=D,\n           eval_function = auwe,\n           endpoints   = \"satisfaction\",  \n           treat       = \"\",            \n           subjectid   = \"ID\",\n           factors     = c(\"gender\", \"employed\", \"smoker\", \"graduat\", \"graduat_f\", \"graduat_m\", \n                           \"high_grad\", \"high_grad_f\", \"high_grad_m\", \"age\", \"w_hours\", \"todoctor\", \"bmi\", \"income\") ,\n           min_comb    = 1,\n           max_comb    = 3,\n           verbose     = T)\n\n\n\n#write.csv(HH$sge, file = \"Data_H.csv\", na=\"\")    \n\nsubscreenshow(HH, \n              host = \"0.0.0.0\", port = 1234)\n\nBack to blog\n\n\n",
    "preview": "posts/2020-09-11-wonderful-wednesdays-june-2020/./plots/cdf.png",
    "last_modified": "2020-10-30T20:02:33+01:00",
    "input_file": {},
    "preview_width": 4133,
    "preview_height": 2362
  },
  {
    "path": "posts/2020-09-10-wonderful-wednesday-april-2020/",
    "title": "Wonderful Wednesday April 2020",
    "description": "In this webinar we discuss the first submissions looking at some great ways to visualise a categorical response variable over time. We talk about what the SIG members like about each plot and give some pointers on areas we think could be improved. More specifically, we talk about: the value of a title with conclusions, the use of colour, the benefits of animation to display time, ways to declutter your graph and examples of clean design, enclosure to highlight important parts of the data, the benefits of the sankey diagram, how different charts help to answer different questions, and many more aspects of great visualizations.",
    "author": [
      {
        "name": "Steve Mallett",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2020-04-09",
    "categories": [
      "survival data",
      "Kaplan-Meier",
      "Wonderful Wednesdays"
    ],
    "contents": "\nThis month’s challenge involved a classic survival dataset example. You can download the dataset here. This simulated example dataset was based on a phase III clinical trial in breast cancer, you can read more about this study here. To summarise, this was a four-arm study, where participants were randomised to receive either one of two monotherapies or one of two combination therapies for 1 year with 4 years post treatment follow-up. The primary outcome was progression free survival and we wanted you to explore different ways of visualising this time-to-event outcome. The dataset contained information that allowed you to explore subgroups, patterns of events and individual patient profiles. More information on the dataset is available here.\nWe received a variety of submissions in this round including both static and interactive plots and we would like to thank everyone for their contributions. In the webinar members of the VIS SIG discussed the merits of each and picked out key elements they felt would make the ‘ultimate plot’. We summarise the discussions for each submission below.\n\nExample 1\nPlot 1link to codehigh-resolution image\nOn the left this plot displays the proportion of participants that are event free over time by treatment arm and on the right we can see the cumulative number of events over time by treatment arm. Inclusion of both of these figures into one image gives a view of the data which we don’t often see. Inclusion of uncertainty is also not often seen in Kaplan-Meier plots (but has been advocated in this recent publication from Morris et al.) but is extremely useful and the clutter from the overlap of the confidence bands is perhaps less problematic with inclusion of the cumulative plot on the right. The team liked the inclusion of the tables of numbers at risk and the cumulative number of events at the bottom of each plot, this is important information, and we felt this approach didn’t overload or create a cluttered image. We thought there was a nice use of colour.\nWhilst there is clear labelling of the axis and the inclusion of a common legend ensures clarity this image would benefit from inclusion of some extra details to allow it to stand-alone, for example it would benefit from inclusion of a title. In terms of creating a clearer image we also felt that the dashes to indicate censoring in the image on the left could be omitted given the information on numbers at risk are available at the bottom of the plot.\nThis is a nice example of an exploratory type plot that statisticians can use to understand the data but if the aim is to communicate a message to stakeholders then we would suggest presenting less information in a simpler graphic.\n\nExample 2\nPlot 2link to codehigh-resolution image\nThis presentation of the data displays the cumulative proportion of participants experiencing an event. It includes a separate plot for each treatment arm and the inclusion of subtitles ensures clarity. This plot is being used to tell a story, which the title guides us towards. Inclusion of a reference line at an important time point is helpful to guide the audience’s attention. Labelling the x and y-axis only once prevents clutter and in combination with the inclusion of the reference lines makes this a clear presentation of the data. This demonstrates an effective use of graduation of saturation and clear annotation.\nThe team noted that there are six colours of grey in the legend but that it was difficult to pick out all six groups in the image. This was because one of the groups is very small. However, it’s tricky to pick out which group this is so we caution potential users to be mindful of this in their own plots.\nThis is an original, well thought through presentation of survival data which we commend and think would work well where the is a natural ordering of the groups.\n\nExample 3\nPlot 3link to codehigh-resolution image\nThis is a very nice, interactive visual presentation of a growing or developing Kaplan-Meier plot link. This image included some really nice design points that update as the image progresses that can help to tell a story. These included:\nThe percentages on right y-axis changing as the video plays,\nThe inclusion of an additional x-axis at the top of the plot that is populated as it progresses,\nThe developing reference lines that follow the data as the plot progresses.\nThe team felt that this interactive approach could help understanding and interpretation amongst those not so familiar with Kaplan-Meier plots. It’s a potentially useful way to force the viewer to take the entire time period into consideration and not just the final time point when there is often the most uncertainty.\nWith some additional information on the right y-axis such as estimates of treatment effects this could be a really powerful design choice. A minor point was that it would be nice to include treatment labels with the numbers on the right y-axis so the audience do not have to keep referring back to the legend as the image progresses.\n\nExample 4\nPlot 4link to codehigh-resolution image\nThis is a very flexible tool to display Kaplan-Meier plots that explores the subgroup element of the challenge link. It allows the user to change what is presented e.g. displaying information on different treatment groups, different subgroups, or restricting information presented by the age range of participants. Including the legend within the plot and use of grid lines both help audiences to interpret this image.\nThis is a nice way to present the data for exploratory purposes. It would be nice to include sample sizes and confidence intervals within this tool to represent the uncertainty and minimise the risk of making incorrect conclusions.\n\nExample 5\nPlot 5link to codelink to html filehigh-resolution image\nThe use of a heat map to present survival data is a new idea to the group. At first some of us found it difficult to understand but with some thought it definitely becomes clearer. Given the novelty of this plot it probably needs more information to explain what is going on but could be very useful to help deliver a message to audiences. Inclusion of a clear message in the title and the ordering of the data in a way that the image portrays this really helps i.e. the white stripe representing the median helps show differences between treatment arms.\nAs well as a ‘big picture’ message from the changes in colour there is also an interactive element to this plot allowing more detailed information to be provided, as the user hovers over different points on the plot information on the survival function at that time point is displayed. Similarly hovering over the reference lines displays further information.\n\nExample 6\nPlot 6link to codehigh-resolution image\nThis image displays a Kaplan-Meier plot for each treatment arm with accompanying confidence bands with inclusion of other treatment arms in grey for comparison. This is simple, clear plot exhibiting use of good data visualisation principles. We liked the clear message in the title, inclusion of numbers at risk for each plot rather than in a table and the use of grid lines. The team felt that this plot would be good for communicating a message.\nMinor adjustments we recommend are: including a more prominent grid line at 52 weeks, including a legend clearly explaining what the red line and reference bands are and changing the scale from days to weeks or months.\nCode\n\nExample 1 (R)\n\n\n### Purpose: create TTE KM plots\n\n### Load packages\nlibrary(readr)\nlibrary(survival)\nlibrary(survminer)\nlibrary(stringr)\n\n### Load data\nsetwd('C:/Users/XXXXXXXXXXXXX')\nADTTE <- read_delim('2020-04-08-psi-vissig-adtte.csv', delim=';')\n\n### AVAL is given in days; transform into weeks\nADTTE$AVAL_wk = ADTTE$AVAL / 7\n\n### Create survival curves\nsurv_curve <- survfit(Surv(AVAL_wk, CNSR == 0) ~ TRT01P, data = ADTTE)\n\n### Adjust treatment group labels in surv_curve\nnames(surv_curve$strata) <- str_remove(names(surv_curve$strata), \"TRT01P=\") \n\n### Theme for plots\ntheme_table <- theme_minimal(base_size = 18) %+replace% \n  theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(),  # remove vertical gridlines\n        panel.grid.major.y = element_blank(),  # remove horizontal gridlines\n        axis.title.y = element_blank(), axis.title.x = element_blank(),  # remove axis titles\n        axis.text.x = element_blank(), axis.ticks.x = element_blank())  # remove x-axis text and ticks\n\ntheme_gg <- theme_minimal(base_size = 18) %+replace% \n  theme(panel.grid.minor.y = element_blank(), panel.grid.minor.x = element_blank(),  # remove minor gridlines\n        legend.title = element_blank())  # remove legend title\n\n### Plot \nplots <- list()\n# Proportion event-free\nplots[[1]] <- ggsurvplot(fit = surv_curve,  # survfit object\n                         data = ADTTE,  # data used to fit survival curves. \n                         break.y.by = 0.2,  # y-axis breaks\n                         risk.table = T,  # show risk table.\n                         conf.int = T,  # show confidence intervals\n                         xlim = c(0, 160),  # present narrower X axis\n                         break.time.by = 20,  # x-axis breaks\n                         ggtheme = theme_gg,  # use theme defined above\n                         risk.table.y.text = F, # show bars instead of names in text annotations in legend of risk table\n                         xlab = \"Week\",\n                         ylab = \"Proportion event-free\",\n                         legend = c(0.7, 0.15),  # legend position\n                         tables.theme = theme_table)  # use them defined above for risk table\n\n# Cumulative proportion with event\nplots[[2]] <- ggsurvplot(fit = surv_curve,\n                         data = ADTTE,\n                         fun = \"event\",  # show event probability instead of survival probability\n                         ylim = c(0, 0.6),  # do not include full scale (0-1) to allow to better discriminate between treatments\n                         break.y.by = 0.1,\n                         cumevents = T,  # show cumulative number of events\n                         conf.int = F,\n                         xlim = c(0, 160),\n                         break.time.by = 20,\n                         ggtheme = theme_gg,\n                         cumevents.y.text = FALSE,\n                         xlab = \"Week\",\n                         ylab = \"Cumulative proportion with event\",\n                         legend = \"none\",\n                         tables.theme = theme_table)\n\n# Save plot\nggsave(filename = \"2020-04-08-markusv_km.png\",\n       plot = arrange_ggsurvplots(plots, print = T, ncol = 2, nrow = 1),\n       width = 19.3, height = 9, units = \"in\")\n\nBack to blog\n\nExample 2 (R)\n\n\n### Purpose: create TTE area plot\n\n### Load packages\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(zoo)\n\n### Load data\nsetwd('C:/Users/XXXXXXX')\nADTTE <- read_delim('2020-04-08-psi-vissig-adtte.csv', delim=';')\n\n### AVAL is given in days; transform into weeks\nADTTE$AVAL_wk = ADTTE$AVAL / 7\n\n### Derive number of subjects per treatment group\nADTTE_ntrt <- ADTTE %>% group_by(TRT01PN, TRT01P) %>% mutate(N=n())\n\n### Derive cumulative number (percentage) of subjects with event / censoring\nADTTE_cum <- ADTTE_ntrt %>% group_by(TRT01PN, TRT01P, N, EVNTDESC, AVAL_wk) %>% \n  summarise(n = n()) %>% mutate(n = cumsum(n), pct = n / N)\n\n### Create grid to ensure all groups have a value at each timepoint (necessary for geom_area())\ngrid <- with(ADTTE_cum, expand.grid(TRT01PN = unique(TRT01PN), EVNTDESC = unique(EVNTDESC), \n                                    AVAL_wk = unique(AVAL_wk)))\nADTTE_grid <- merge(grid, ADTTE_cum, by = c(\"TRT01PN\", \"EVNTDESC\", \"AVAL_wk\"), all = T)\n\n### Fill in NA values with last non-NA value and remove leading NA rows\nADTTE_locf <- ADTTE_grid %>% group_by(TRT01PN, EVNTDESC) %>% do(na.locf(.))\n\n### Control order (show events at bottom and censoring above)\nADTTE_locf$EVNTDESC <- factor(ADTTE_locf$EVNTDESC, levels = c(\"Lost to follow-up\", \"No next-line therapy initiated\",\n                                                              \"Second next-line therapy initiated\",\n                                                              \"Ongoing on first next-line therapy\", \"PD\", \"Death\"))\n\n### Add N to treatment label and order by TRT01PN\nADTTE_locf$TRT01P_label <- with(ADTTE_locf, paste0(TRT01P, \" (N=\", N, \")\"))\nADTTE_locf$TRT01P_label <- reorder(ADTTE_locf$TRT01P_label, ADTTE_locf$TRT01PN)\n\n### Stacked area chart\nggplot(data = ADTTE_locf, aes(x = AVAL_wk, y = pct, fill = EVNTDESC)) +\n  geom_area(alpha = 0.6) +\n  facet_wrap(TRT01P_label ~ .) +\n  scale_x_continuous(limits = c(0, 160), breaks = seq(0, 160, by = 20), name = \"Week\") +\n  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2), \n                     name = \"Cumulative proportion with event / censoring\", expand = c(0, 0)) +\n  geom_vline(xintercept = 52, alpha = 0.3) +\n  theme_minimal(base_size = 18) +\n  scale_fill_grey(start = 0.8, end = 0.2) +\n  theme(legend.position = c(0.15, 0.85), legend.title = element_blank(),  # remove legend title and set legend position\n        panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(),  # remove vertical gridlines\n        panel.grid.minor.y = element_blank()) +  # remove horizontal minor gridlines\n  ggtitle(\"Combination of tablemab + vismab leads to less deaths during first 52 weeks of study treatment\")\n\nggsave(filename = \"2020-04-08-markusv_area.png\", width = 19.3, height = 9, units = \"in\")\n\nBack to blog\n\nExample 3 (SAS)\n\n\nfilename urlFile url 'https://raw.githubusercontent.com/VIS-SIG/Wonderful-Wednesdays/master/data/2020/2020-04-08/2020-04-08-psi-vissig-adtte.csv';\n*--------------------------------\nImport Procedure\n---------------------------------;\n\n\ndata ADTTE \n    (label='Time-to-Event'\n     compress=yes\n);\n\ninfile urlFile \n  delimiter = ',' \n  missover \n  dsd \n  lrecl=32767 \n  firstobs=2;\nattrib \n    STUDYID length=$20 format=$20. informat=$20. label='the study identifier'\n    SUBJID length=8 format=8. informat=8. label='subject identifier'\n    USUBJID length=$40 format=$40. informat=$40. label='unique subject iddentifier'\n    AGE length=8 format=8. informat=8. label='age at randomisation (years)'\n    STR01 length=$8 format=$8. informat=8. label='Hormone receptor status at randomisation'\n    STR01N length=3 format=3. informat=3. label='Hormone receptor positive (Numeric)'\n    STR01L length=$30 format=$30. informat=$30. label='Hormone receptor positive (Long format)'\n    STR02 length=$30 format=$30. informat=$30. label='Prior Radiotherapy at randomisation'\n    STR02N length=3 format=3. informat=3. label='Prior Radiotherapy at randomisation (Numeric)'\n    STR02L length=$40 format=$40. informat=$40. label='Prior Radiotherapy at randomisation (Long format)'\n    TRT01P length=$40 format=$40. informat=$40. label='Planned treatment assigned at randomisation'\n    TRT01PN length=8 format=8. informat=8. label='Planned treatment assigned at randomisation (Numeric)'\n    PARAM length=$40 format=$40. informat=40. label='Analysis parameter - Progression free survival'\n    PARAMCD length=$10 format=$10. informat=$10. label='Analysis parameter code'\n    AVAL length=8 format=8. informat=8. label='Analysis value (time to event [days])'\n    CNSR length=3 format=3. informat=3. label='Censoring (0 = Event, 1 = censored)'\n    EVNTDESC length= $34 format=$34. informat=$34. label='Event description'\n    CNSDTDSC length=$33 format=$33. informat=$34. label='Censoring description'\n    DCTREAS length=$25 format=$25. informat=34. label='Discontinuation from study reason'\n;\ninput\n  STUDYID SUBJID USUBJID AGE STR01 STR01N STR01L    \n  STR02 STR02N STR02L   TRT01P TRT01PN PARAM PARAMCD    \n  AVAL CNSR EVNTDESC CNSDTDSC DCTREAS;\nrun;\n\n\ndata TIME_TO_EVENT\n( keep =  Patient Age_at_Start Age_Group Age_at_End Survival_Days Survival_Weeks\n          Full_Years Hormone_Receptor_Status Prior_Radiotherapy\n        Treatment_No Treatment Censoring Death Discontinuation Discontinuation_Reason\n);\n\nattrib\n    Patient length=8 \n    Age_at_Start length=8\n    Age_Group length=$5\n    Age_at_End length=8\n    Survival_Days length=8 label='Survival Days'\n    Full_Years length=8\n    Hormone_Receptor_Status length=$8 \n    Prior_Radiotherapy length=$1\n    Treatment_No length=8\n    Treatment length=$40\n    Censoring length=8\n    Death length=8\n    Discontinuation length=$1\n    Discontinuation_Reason length=$25 \n;\nset RECD.ADTTE;\n\n    Patient = SUBJID;\n    Age_at_Start = AGE;\n    Survival_Days = AVAL;\n    Survival_Weeks = int(Survival_Days/7);\n    Full_Years = int(Survival_Days/365.25);\n    Age_at_End = Age_at_Start + Full_Years;\n    Hormone_Receptor_Status = STR01;\n    Prior_Radiotherapy = ifc(STR02N=1,'Y','N');\n    Treatment_No = TRT01PN;\n    Treatment = TRT01P;\n    Censoring = CNSR;\n    Death = ifc(EVNTDESC = 'Death',1,0);\n    Discontinuation = ifc(DCTREAS = 'NA','N','Y');\n    Discontinuation_Reason = propcase(DCTREAS);\n\n    if Discontinuation = 'N' then Discontinuation_Reason = 'Not applicable';\n\n    if Age_at_Start <= 50 then Age_Group = '25-50';\n    else if 51 <= Age_at_Start <= 60 then Age_Group = '51-60' ;\n    else if 61 <= Age_at_Start <= 70 then Age_Group = '61-70' ;\n    else if 71 <= Age_at_Start <= 80 then Age_Group = '71-80' ;\n    else  Age_Group = '81+' ;\nrun;\n\n\nods _all_ close;\nods graphics on;\n\nods output Survivalplot=SurvivalPlotData;\nproc lifetest data=TIME_TO_EVENT plots=survival(atrisk=0 to 2000 by 10); \n    time Survival_Days * Death(0);\n    strata Treatment/ test=logrank adjust=sidak;\nrun; \n\n\n\n\n\n\nproc sql;\ncreate table time\nas\nselect distinct time\nfrom SurvivalPlotData;\nquit;\n\n\ndata time;\nset time end=eof;\ni=_n_;\nif eof then call symput('n',_n_);\nrun;\n\n\n%macro km;\n%do i=1 %to &n+10;\n\nproc sql noprint;\nselect max(Time) into: Time\nfrom Time\nwhere i <= &i.;\nquit;\n\ndata SPD;\nset SurvivalPlotData (where=(Time le &Time.));\nrun;\n\nproc sql;\ncreate table Survival_Pct\nas\nselect      StratumNum,\n            min(Survival) as Survival,\n            compress(put(min(Survival),percent8.1)) as Survival_txt\nfrom        SPD \nwhere       Survival not=.\ngroup by    StratumNum;\nquit;\n\ndata _null_;\nset Survival_Pct;\nif StratumNum = 1 then do;\n    call symput('Trt_val_1',Survival);\n    call symputx('Trt_txt_1',Survival_txt);\nend;\nif StratumNum = 2 then do;\n    call symput('Trt_val_2',Survival);\n    call symputx('Trt_txt_2',Survival_txt);\nend;\nif StratumNum = 3 then do;\n    call symput('Trt_val_3',Survival);\n    call symputx('Trt_txt_3',Survival_txt);\nend;\nif StratumNum = 4 then do;\n    call symput('Trt_val_4',Survival);\n    call symputx('Trt_txt_4',Survival_txt);\nend;\nrun;\n\ntitle j=center font=calibri height=10pt \"Survival Day = &Time\";\nproc sgplot data=SPD noborder nowall;\n styleattrs datacontrastcolors=(CX003469 CX69b937 CXef7d04 CX00a6cb);\n step x=time y=survival / group=stratum name='s';\n  scatter x=time y=censored / markerattrs=(symbol=plus) name='c';\n  scatter x=time y=censored / markerattrs=(symbol=plus) GROUP=stratum;\n\n  keylegend 'c' / location=inside position=topright valueattrs = (family=calibri size=10pt);\n  keylegend 's' / linelength=20 valueattrs = (family=calibri size=10pt);\n  xaxis\n    values = (0 to 2000 by 30)\n    valueattrs = (family=calibri size=10pt) \n    labelattrs = (family=calibri size=10pt) \n    label = 'x - Survival Days / y - *Survival Probability'\n  ;\n  yaxis \n    valueattrs = (family=calibri size=10pt) \n    labelattrs = (family=calibri size=10pt) \n    values = (0 to 1 by 0.1)\n    labelpos = top\n    label='*'\n  ;\n\n%if &Time. ge 84 %then %do;\nrefline 84 / axis=x \n    lineattrs=(pattern=dash color=lightgrey) label='12 Weeks' labelattrs=(family=calibri size=10pt);\n%end;\n\n%if &Time. ge 365 %then %do;\nrefline 365 / axis=x \n    lineattrs=(pattern=dash color=lightgrey) label='52 Weeks / 1 Year' labelattrs=(family=calibri size=10pt);\n%end;\n\n%if &Time. ge 730 %then %do;\nrefline 730 / axis=x  \n    lineattrs=(pattern=dash color=lightgrey) label='2 Years' labelattrs=(family=calibri size=10pt);\n%end;\n\n%if &Time. ge 1095 %then %do;\nrefline 1095 / axis=x \n    lineattrs=(pattern=dash color=lightgrey) label='3 Years' labelattrs=(family=calibri size=10pt)  ;\n%end;\n\n%if &Time. ge 1461 %then %do;\nrefline 1461 / axis=x \n    lineattrs=(pattern=dash color=lightgrey) label='4 Years' labelattrs=(family=calibri size=10pt)  ;\n%end;\n\n%if &Time. ge 1826 %then %do;\nrefline 1826 / axis=x \n    lineattrs=(pattern=dash color=lightgrey) label='5 Years' labelattrs=(family=calibri size=10pt)  ;\n%end;\n\nrefline &Trt_val_1. / axis=y\n    lineattrs=(pattern=thindot color=CX003469) label=\"&Trt_txt_1\" labelattrs=(family=calibri size=10pt color=CX003469);\n\nrefline &Trt_val_2. / axis=y\n    lineattrs=(pattern=thindot color=CX69b937) label=\"&Trt_txt_2\" labelattrs=(family=calibri size=10pt color=CX69b937);\n\nrefline &Trt_val_3. / axis=y\n    lineattrs=(pattern=thindot color=CXef7d04) label=\"&Trt_txt_3\" labelattrs=(family=calibri size=10pt color=CXef7d04);\n\nrefline &Trt_val_4. / axis=y\n    lineattrs=(pattern=thindot color=CX00a6cb) label=\"&Trt_txt_4\" labelattrs=(family=calibri size=10pt color=CX00a6cb);\nrun;\n\ntitle;\n\n\n%end;\n%mend;\n\n/* Create the combined graph. */\n\n\noptions papersize=a4 printerpath=gif animation=start animduration=0.05 animloop=no noanimoverlay nodate nonumber spool;\nods printer file=\"c:\\temp\\KM_Treatment.gif\";\n\nods graphics / width=10in height=10in  scale=on imagefmt=GIF;\n%km;\n\noptions printerpath=gif animation=stop;\nods printer close;\n\nBack to blog\n\nExample 4 (R and readme.txt)\n\n\n## PSI_April_KM_v1_0\n\n## load in packages\nlibrary(shiny)\nlibrary(shinyWidgets)\nlibrary(tidyverse)\nlibrary(shinycssloaders)\nlibrary(broom)\nlibrary(survival)\nlibrary(survminer)\nlibrary(plotly)\n\n\ntick <- icon(\"check\")\n\nOrange <- \"#EF7F04\"\nGreen <- \"#68B937\"\nBlue <- \"#00A6CB\"\nGrey <- \"#4E5053\"\nDarkblue <- \"#003569\"\nYellow <- \"#FFBB2D\"\n\nADTTE <- read_csv('2020-04-08-psi-vissig-adtte_v2.csv')\n\nADTTE$EVNTDESC <- as.factor(ADTTE$EVNTDESC)\nADTTE$STR01L <- as.factor(ADTTE$STR01L)\nADTTE$STR02L <- as.factor(ADTTE$STR02L)\nADTTE$TRT01P <- as.factor(ADTTE$TRT01P)\nADTTE$AGE <- as.integer(ADTTE$AGE)\n\nADTTE2 <- ADTTE\n# Define UI for app that draws a bar chart in ggplot ----\n\n# Use a fluid Bootstrap layout\nui <- fluidPage(    \n  \n  # Give the page a title\n  titlePanel(\"Interactive Kaplan-Meier Plot\"),\n\n  # Generate a row with a sidebar\n  sidebarLayout(\n\n    # Define the sidebar with inputs for each plot separately\n    sidebarPanel(\n      ## Conditional panels- only see first set of filters on first tab\n      conditionalPanel(condition = \"input.tabset == 'withn'\",\n                       strong(\"Filters for Plot:\"),\n                       prettyCheckboxGroup(\"Strat1\", \"Hormone receptor status:\", \n                                           choices=levels(ADTTE$STR01L), \n                                           selected = levels(ADTTE$STR01L),\n                                           inline = TRUE, icon = tick),\n                       prettyCheckboxGroup(\"Strat2\", \"Prior radiotherapy at randomisation:\",\n                                           choices= levels(ADTTE$STR02L),\n                                           selected = levels(ADTTE$STR02L),\n                                           inline = TRUE, icon = tick),\n                       prettyCheckboxGroup(\"Trt\", \"Treatment Arm:\",\n                                           choices= levels(ADTTE$TRT01P),\n                                           selected = levels(ADTTE$TRT01P),\n                                           inline = TRUE, icon = tick),\n                       sliderInput(\"ptAGE\", \"Age Range:\",\n                                   min = min(ADTTE$AGE), max = max(ADTTE$AGE),\n                                   value = c(\"min\",\"max\"))),\n      \n      ## Conditional panels- only see second set of filters on second tab\n      conditionalPanel(\n        condition = \"input.tabset == 'QuantComp'\",\n        strong(\"Filters for Plot A:\"),\n        prettyCheckboxGroup(\"Strat1a\", \"Hormone receptor status:\", \n                            choices=levels(ADTTE$STR01L), \n                            selected = levels(ADTTE$STR01L),\n                            inline = TRUE, icon = tick),\n        prettyCheckboxGroup(\"Strat2a\", \"Prior radiotherapy at randomisation:\",\n                            choices= levels(ADTTE$STR02L),\n                            selected = levels(ADTTE$STR02L),\n                            inline = TRUE, icon = tick),\n        prettyCheckboxGroup(\"Trta\", \"Treatment Arm:\",\n                            choices= levels(ADTTE$TRT01P),\n                            selected = levels(ADTTE$TRT01P),\n                            inline = TRUE, icon = tick),\n        sliderInput(\"ptAGEa\", \"Age Range:\",\n                    min = min(ADTTE$AGE), max = max(ADTTE$AGE),\n                    value = c(\"min\",\"max\")),\n        br(),\n        hr(),\n        br(),\n        \n        strong(\"Filters for Plot B:\"),\n        prettyCheckboxGroup(\"Strat1b\", \"Hormone receptor status:\", \n                            choices=levels(ADTTE$STR01L), \n                            selected = levels(ADTTE2$STR01L),\n                            inline = TRUE, icon = tick),\n        prettyCheckboxGroup(\"Strat2b\", \"Prior radiotherapy at randomisation:\",\n                            choices= levels(ADTTE$STR02L),\n                            selected = levels(ADTTE$STR02L),\n                            inline = TRUE, icon = tick),\n        prettyCheckboxGroup(\"Trtb\", \"Treatment Arm:\",\n                            choices= levels(ADTTE$TRT01P),\n                            selected = levels(ADTTE$TRT01P),\n                            inline = TRUE, icon = tick),\n        sliderInput(\"ptAGEb\", \"Age Range:\",\n                    min = min(ADTTE$AGE), max = max(ADTTE$AGE),\n                    value = c(\"min\",\"max\")),\n        \n      ),\n      \"Events are defined as death or disease progression.\"\n    ),\n    \n    \n    \n    \n    \n    # Create a spot for the plot\n    mainPanel(\n      ## Creates two separate panels- one for KM plot and number of patients, one for two KM plots to allow comparisons\n      tabsetPanel(type = \"tabs\",\n                  id = \"tabset\",\n                  tabPanel(\"KM plot with number of patients\", plotOutput(\"PlotA\"), br(), hr(), br(), plotOutput(\"PlotB\"), value = \"withn\"),\n                  \n                  \n                  tabPanel(\"KM plots to compare between subgroups\", plotOutput(\"PlotC\"), br(), hr(), br(), plotOutput(\"PlotD\"), value = \"QuantComp\")\n                  \n                  \n      )\n      \n    )  \n  )\n  \n)  \n\n\n# Define a server for the Shiny app\n\n\nserver <- function(input, output) {\n  \n  # Create four separate plots based on inputs\n  \n  ## Fit model and plot KM curve for first tab\n  output$PlotA <- renderPlot({\n    \n    #Filter and Subset Data\n    \n    plotdata <- ADTTE %>% filter(STR01L %in% input$Strat1, STR02L %in% input$Strat2,\n                                 TRT01P %in% input$Trt)\n    plotdata2 <- subset(plotdata,\n                        AGE  >= input$ptAGE[1] & AGE <= input$ptAGE[2])  \n    \n\n    \n    fita <- survfit(Surv(AVAL, CNSR == 0) ~ TRT01P, data = plotdata2)\n    plot <-        ggsurvplot(fita,\n                              risk.table = TRUE,\n                              data = plotdata2,\n                              # size = 0.0001,\n                              censor.shape = \"\",\n                              palette = c(\"TRT01P=tablemab + vismab 52 weeks\" = Darkblue,\"TRT01P=tablemab x 12 week -> vismab 34 weeks\" = Green, \n                                          \"TRT01P=tablemab x 52 weeks\" = Blue, \"TRT01P=vismab x 52 weeks\" = Orange),\n                              # risk.table = 'nrisk_cumcensor',\n                              # tables.theme = theme_cleantable(),\n                              # risk.table.col = \"strata\",\n                              # # cumevents = TRUE,\n                              title = \"Interactive Kaplan-Meier plot: Explore time to event across 4 treatment arms\",\n                              xlab = \"Time (days)\",\n                              ylab = \"Event free survival\",\n                              legend = c(.18,.25),\n                              legend.title = \"Treatment Group\",\n                              \n                              # legend.labs = c(\"Control\", \"Treatment\"),\n                              break.x.by = 90,\n                              xlim = c(0, 1980),\n                              ggtheme = theme_classic()) \n    plot$plot + ggplot2::geom_vline(xintercept=365, linetype='dotted', col = \"black\") +\n      ggplot2::geom_vline(xintercept=1095, linetype='dashed', col = \"black\") +\n      ggplot2::geom_vline(xintercept=1825, linetype='solid', col = \"black\") +\n      ggplot2::annotate(geom = \"text\", x = 375, y = 0, label = \"Year 1\", hjust = \"left\", size = 4.5) +\n      ggplot2::annotate(geom = \"text\", x = 1105, y = 0, label = \"Year 3\", hjust = \"left\", size = 4.5) +\n      ggplot2::annotate(geom = \"text\", x = 1835, y = 0, label = \"Year 5\", hjust = \"left\", size = 4.5) \n    \n  })\n  \n  ## Filter data and pull out number of patients for n's at bottom of first tab\n  output$PlotB <- renderPlot({\n    plotdata <- ADTTE %>% filter(STR01L %in% input$Strat1, STR02L %in% input$Strat2,\n                                 TRT01P %in% input$Trt)\n    plotdata2 <- subset(plotdata,\n                        AGE  >= input$ptAGE[1] & AGE <= input$ptAGE[2])  \n    \n    \n    \n    fita <- survfit(Surv(AVAL, CNSR == 0) ~ TRT01P, data = plotdata2)\n    plot2 <-        ggsurvplot(fita,\n                               data = plotdata2,\n                               # size = 0.0001,\n                               censor.shape = \"\",\n                               palette = c(\"TRT01P=tablemab + vismab 52 weeks\" = Darkblue,\"TRT01P=tablemab x 12 week -> vismab 34 weeks\" = Green, \n                                           \"TRT01P=tablemab x 52 weeks\" = Blue, \"TRT01P=vismab x 52 weeks\" = Orange),\n                               # risk.table = 'nrisk_cumcensor',\n                               # tables.theme = theme_cleantable(),\n                               # risk.table.col = \"strata\",\n                               # # cumevents = TRUE,\n                               #title = \"Interactive Kaplan-Meier plot: Explore time to event across 4 treatment arms\",\n                               title = \"Interactive Kaplan-Meier plot: Explore time to event across 4 treatment arms\",\n                               xlab = \"Time (days)\",\n                               ylab = \"Event free survival\",\n                               legend = c(.18,.25),\n                               legend.title = \"Treatment Group\",\n                               break.x.by = 180,\n                               xlim = c(0, 1980),\n                               ggtheme = theme_classic(),\n                               risk.table = TRUE, \n                               risk.table.col = \"strata\",  \n                               risk.table.title=\"Patients remaining in study\"\n    ) \n    plot2$table + theme(\n      axis.text.y = element_blank(),\n      axis.ticks.y = element_blank(),\n      legend.position = \"none\"\n    )\n    \n  })  \n## Filter data and create KM plot for top of second tab\n  output$PlotC <- renderPlot({\n    \n    #Filter and Subset Data\n    \n    plotdatc <- ADTTE %>% filter(STR01L %in% input$Strat1a, STR02L %in% input$Strat2a,\n                                 TRT01P %in% input$Trta)\n    plotdata2c <- subset(plotdatc,\n                         AGE  >= input$ptAGEa[1] & AGE <= input$ptAGEa[2])  \n    \n    \n    \n    fitc <- survfit(Surv(AVAL, CNSR == 0) ~ TRT01P, data = plotdata2c)\n    plotb <-        ggsurvplot(fitc,\n                               risk.table = TRUE,\n                               data = plotdata2c,\n                               # size = 0.0001,\n                               censor.shape = \"\",\n                               censor = FALSE,\n                               palette = c(\"TRT01P=tablemab + vismab 52 weeks\" = Darkblue,\"TRT01P=tablemab x 12 week -> vismab 34 weeks\" = Green, \n                                           \"TRT01P=tablemab x 52 weeks\" = Blue, \"TRT01P=vismab x 52 weeks\" = Orange),\n                               # risk.table = 'nrisk_cumcensor',\n                               # tables.theme = theme_cleantable(),\n                               # risk.table.col = \"strata\",\n                               # # cumevents = TRUE,\n                               title = \"Plot A:\",\n                               xlab = \"Time (days)\",\n                               ylab = \"Event free survival\",\n                               legend = c(.18,.25),\n                               legend.title = \"Treatment Group\",\n                               \n                               # legend.labs = c(\"Control\", \"Treatment\"),\n                               break.x.by = 90,\n                               xlim = c(0, 1980),\n                               ggtheme = theme_classic()) \n    plotb$plot + ggplot2::geom_vline(xintercept=365, linetype='dotted', col = \"black\") +\n      ggplot2::geom_vline(xintercept=1095, linetype='dashed', col = \"black\") +\n      ggplot2::geom_vline(xintercept=1825, linetype='solid', col = \"black\") +\n      ggplot2::annotate(geom = \"text\", x = 375, y = 0, label = \"Year 1\", hjust = \"left\", size = 4.5) +\n      ggplot2::annotate(geom = \"text\", x = 1105, y = 0, label = \"Year 3\", hjust = \"left\", size = 4.5) +\n      ggplot2::annotate(geom = \"text\", x = 1835, y = 0, label = \"Year 5\", hjust = \"left\", size = 4.5)\n    \n  })\n  \n  \n## Filter data and create KM plot for bottom of second tab  \n  output$PlotD <- renderPlot({\n    \n    #Filter and Subset Data\n    \n    plotdatad <- ADTTE %>% filter(STR01L %in% input$Strat1b, STR02L %in% input$Strat2b,\n                                  TRT01P %in% input$Trtb)\n    plotdata2d <- subset(plotdatad,\n                         AGE  >= input$ptAGEb[1] & AGE <= input$ptAGEb[2])  \n    \n    \n    \n    fitd <- survfit(Surv(AVAL, CNSR == 0) ~ TRT01P, data = plotdata2d)\n    plotd <-        ggsurvplot(fitd,\n                               risk.table = TRUE,\n                               data = plotdata2d,\n                               censor = FALSE,\n                               # size = 0.0001,\n                               censor.shape = FALSE,\n                               palette = c(\"TRT01P=tablemab + vismab 52 weeks\" = Darkblue,\"TRT01P=tablemab x 12 week -> vismab 34 weeks\" = Green, \n                                           \"TRT01P=tablemab x 52 weeks\" = Blue, \"TRT01P=vismab x 52 weeks\" = Orange),\n                               # risk.table = 'nrisk_cumcensor',\n                               # tables.theme = theme_cleantable(),\n                               # risk.table.col = \"strata\",\n                               # # cumevents = TRUE,\n                               title = \"Plot B:\",\n                               xlab = \"Time (days)\",\n                               ylab = \"Event free survival\",\n                               legend = c(.18,.25),\n                               legend.title = \"Treatment Group\",\n                               # legend.labs = c(\"Control\", \"Treatment\"),\n                               break.x.by = 90,\n                               xlim = c(0, 1980),\n                               ggtheme = theme_classic()) \n    plotd$plot +  ggplot2::geom_vline(xintercept=365, linetype='dotted', col = \"black\") +\n      ggplot2::geom_vline(xintercept=1095, linetype='dashed', col = \"black\") +\n      ggplot2::geom_vline(xintercept=1825, linetype='solid', col = \"black\") +\n      ggplot2::annotate(geom = \"text\", x = 375, y = 0, label = \"Year 1\", hjust = \"left\", size = 4.5) +\n      ggplot2::annotate(geom = \"text\", x = 1105, y = 0, label = \"Year 3\", hjust = \"left\", size = 4.5) +\n      ggplot2::annotate(geom = \"text\", x = 1835, y = 0, label = \"Year 5\", hjust = \"left\", size = 4.5)\n    \n    \n    \n    \n  })\n}    \n\n\n\n\n\n# Create Shiny app ----\nshinyApp(ui = ui, server = server)\n\n\n\nInteractive Kaplan Meier\n\n- Overall, this app produces a standard Kaplan Meier curve and associated data table \n- The app contains two tabs:\n    - \"KM Plot with number of patients\"\n    - This tab displays a standard plot and data table. The options in the left hand bar allow for updates to the chart in real time.\n    - the data table is colour coded to match the legend in the chart\n    - Labels not presented on the Y-axis so that the chart and the table align\n    - \"KM Plots to compare between subgroups\"\n    - two plots are displayed vertically\n    - use options on the left hand panel to compare information between different scenarios\n    - future improvements include:\n        - Displaying N at start of treatment on the chart for the selected scenarios\n        - adding a \"hover\" to indicate the N remaining at each timepoint for the selected scenarios\n\nOnline file\nOpens as a webpage/hosted shiny app from shortcut or link- https://avpco.shinyapps.io/PSI_April_KM_v1_0\n\nR file\n1. Click \"run app\" (with data saved as 2020-04-08-psi-vissig-adtte_v2.csv in the same folder/working directory)\n\nVideo file\nVideo demonstration of the Rshiny app\n\nBack to blog\n\nExample 5 (R and readme.txt)\n\n\n## Heatmap for PSI Wonderful Wednesday - April\n\n## Load required packages ====\n\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(survival)\n\n## Read in data and assign colours ====\n\nOrange <- \"#EF7F04\"\nGreen <- \"#68B937\"\nBlue <- \"#00A6CB\"\nGrey <- \"#4E5053\"\nDarkblue <- \"#003569\"\nYellow <- \"#FFBB2D\"\n\n## Assumes data saved in same working directory\nADTTE <- read_csv('2020-04-08-psi-vissig-adtte_v2.csv')\n\n## change variable types as necessary\nADTTE$STR01L <- as.factor(ADTTE$STR01L)\nADTTE$STR02L <- as.factor(ADTTE$STR02L)\nADTTE$TRT01P <- as.factor(ADTTE$TRT01P)\nADTTE$DCTREAS <- as.factor(ADTTE$DCTREAS)\nADTTE$EVNTDESC <- as.factor(ADTTE$EVNTDESC)\n\n\n## Fit survival model and reformat ====\nfita <- survfit(Surv(AVAL, CNSR == 0) ~ TRT01P, data = ADTTE)\n\n## Pull out survival function data\nsurv <- as.data.frame(fita$surv)\n\n## Add treatment to survival data\ntreatment <- c(rep(\"TMB+VMB 52wks\", times = 433), \n               rep(\"TMB 12wks,VMB 34wks\", times = 454), \n               rep(\"TMB 52wks\", times = 427), \n               rep(\"VMB 52wks\", times = 445))\n\n## Combine survival function data, treatment arm and time\nsurv_time <- surv %>%\n  add_column(Days=fita$time) %>%\n  add_column(Treatment_Arm=treatment) %>%\n  rename(survival=`fita$surv`) %>%\n  arrange(Days)\n\n## create shell with all possible days in\n\nshell <- tibble(Days = rep(1:1944, times = 4),\n                Treatment_Arm = c(rep(\"TMB+VMB 52wks\", times = 1944), \n                                  rep(\"TMB 12wks,VMB 34wks\", times = 1944), \n                                  rep(\"TMB 52wks\", times = 1944), \n                                  rep(\"VMB 52wks\", times = 1944)))\n\n## merge on from surv time for when we have a survival value\n## Add 1 for first day at each (nobody's dead yet)\n## Copy survival function values down into empty rows to replicate KM curve horizontal line\n\nfull_surv <- shell %>% \n  left_join(surv_time) %>% \n  mutate(survival = if_else(Days == 1, 1, survival)) %>% ## add 1 for first day as all alive\n  group_by(Treatment_Arm) %>%  ## make sure we don't copy from one trt to the next\n  arrange(Days, .by_group = TRUE) %>%  ## make sure in correct analysis day order\n  fill(survival) %>%  ## fills in empty survival function values\n  ungroup()\n\ntestdf <- full_surv %>% \n  pivot_wider(id_cols = Days, names_from = Treatment_Arm, values_from = survival)\n\nFlag <-  case_when(\n  testdf$`TMB 12wks,VMB 34wks`> testdf$`TMB 52wks` & \n    testdf$`TMB 12wks,VMB 34wks`> testdf$`TMB+VMB 52wks` & \n    testdf$`TMB 12wks,VMB 34wks`> testdf$`VMB 52wks` ~ 3,\n  \n  testdf$`TMB 52wks`> testdf$`TMB 12wks,VMB 34wks` & \n    testdf$`TMB 52wks`> testdf$`TMB+VMB 52wks` & \n    testdf$`TMB 52wks`> testdf$`VMB 52wks` ~ 1,\n  \n  testdf$`TMB+VMB 52wks`> testdf$`TMB 12wks,VMB 34wks` & \n    testdf$`TMB+VMB 52wks`> testdf$`TMB 52wks` & \n    testdf$`TMB+VMB 52wks`> testdf$`VMB 52wks` ~ 4,\n  \n  testdf$`VMB 52wks`> testdf$`TMB 12wks,VMB 34wks` & \n    testdf$`VMB 52wks`> testdf$`TMB 52wks` & \n    testdf$`VMB 52wks`> testdf$`TMB+VMB 52wks` ~ 2\n)\n\n\n\n## Creating text labels for hover functionality ====\n## Add in text for labels, adding extra blank space for alignment\nfull_surv2 <- full_surv %>% \n  mutate(text1 = paste(Treatment_Arm, round(survival, digits = 4), sep = \": \")) %>% \n  mutate(text2 = if_else(condition = Treatment_Arm == \"TMB 12wks,VMB 34wks\", paste(Treatment_Arm, round(survival, digits = 4), sep = \":\"),\n                         false = if_else(condition = Treatment_Arm == \"TMB+VMB 52wks\", paste(Treatment_Arm, round(survival, digits = 4), sep = \":          \"),\n                                         false = if_else(Treatment_Arm == \"VMB 52wks\", paste(Treatment_Arm, round(survival, digits = 4), sep = \":                   \"),\n                                                         false = paste(Treatment_Arm, round(survival, digits = 4), sep = \":                   \")))))\n\n\n## Remove survival values (now in text2) and reformat data to wide format\nfull_surv3 <- full_surv2 %>% \n  select(-survival) %>% \n  pivot_wider(id_cols = Days, names_from = Treatment_Arm, values_from = text2) \n\nfull_surv3$Flag <- Flag\n\nfull_surv3 <- full_surv3 %>% \n  mutate(Flag = replace_na(Flag, 99))\n\n## Merge formatted labels (full_surv3) back to data with survival values (so all labels for each observation) \n## Combines label with /n separator to ensure each on different line\n## Makes the value that is hovered over bold\n\nfull_surv4 <- full_surv2 %>% \n  left_join(full_surv3) %>% \n  mutate(text2 = paste(`TMB 52wks`,`VMB 52wks`,`TMB 12wks,VMB 34wks`,  `TMB+VMB 52wks`, sep = \"\\n\")) %>% \n  mutate(boldtrt = paste(\"<b>\", if_else(Flag ==1, `TMB 52wks`, \n                                        false = if_else(Flag==2, `VMB 52wks`, \n                                                        false = if_else(Flag==3, `TMB 12wks,VMB 34wks`,\n                                                                        false = if_else(Flag==4,`TMB+VMB 52wks`,\n                                                                                        false = \"\")))),\"<\/b>\", sep = \"\")) %>% \n  mutate(text3 = if_else(Flag == 1, paste(boldtrt, `VMB 52wks`,`TMB 12wks,VMB 34wks`,  `TMB+VMB 52wks`, sep = \"\\n\"),\n                         false = if_else(Flag == 2, paste(`TMB 52wks`,boldtrt,`TMB 12wks,VMB 34wks`,  `TMB+VMB 52wks`, sep = \"\\n\"),\n                                         false = if_else(Flag == 3, paste(`TMB 52wks`,`VMB 52wks`,boldtrt,  `TMB+VMB 52wks`, sep = \"\\n\"),\n                                                         false = if_else(Flag == 4, paste(`TMB 52wks`, `VMB 52wks`,`TMB 12wks,VMB 34wks`,  boldtrt, sep = \"\\n\"),\n                                                                         false = paste(`TMB 52wks`,`VMB 52wks`,`TMB 12wks,VMB 34wks`, `TMB+VMB 52wks`, sep = \"\\n\"))))))\n\n## Reorder factors so that axis will match with label order ====\nfull_surv4$Treatment_Arm <- as.factor(full_surv4$Treatment_Arm)\n\nfull_surv4$Treatment_Arm <- fct_relevel(full_surv4$Treatment_Arm, \"TMB+VMB 52wks\", \"TMB 12wks,VMB 34wks\", \"VMB 52wks\",\"TMB 52wks\")\n\n## Create plot ====\n\n## Create ggplot object\nplot <- ggplot(data = full_surv4, aes(x = Days, y = Treatment_Arm, text = text3)) +\n  ggplot2::scale_fill_gradient2(\n    low = Darkblue,\n    high = Green,\n    mid = 'white', \n    midpoint = 0.5,\n    limits = c(0, 1),\n    name = \"Survival\\nFunction\") +\n  labs(y = \"Treatment Arm\") +\n  theme_minimal() +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())\n\n## Create static heatmap and add titles\nplot <- plot + geom_tile(aes(fill = survival))\n\nplot <-  plot + \n  annotate(geom = \"text\", x = 1000, y = 5.2, label = \" \", hjust = \"centered\", vjust = \"top\", size=7) + \n  annotate(geom = \"text\", x = 1000, y = 5.05, label = \"Combining therapies leads to better outcomes after one year\", hjust = \"centered\", vjust = \"top\", size=7) +\n  annotate(geom = \"text\", x = 1000, y = 4.6, label = \"...but simultaneous treatment has a better overall median survival\", hjust = \"centered\", vjust = \"top\", size=6) +\n  geom_segment(x=365, xend=365, y=0.5, yend=4.5, linetype='dotted', col = \"black\") +\n  geom_segment(x=1095, xend=1095, y=0.5, yend=4.5, linetype='dashed', col = \"black\") +\n  geom_segment(x=1825, xend=1825, y=0.5, yend=4.5, linetype='solid', col = \"black\") +\n  annotate(geom = \"text\", x = 375, y = 0.4, label = \"Year 1\", hjust = \"left\", vjust = \"bottom\", size = 3) +\n  annotate(geom = \"text\", x = 1105, y = 0.4, label = \"Year 3\", hjust = \"left\", vjust = \"bottom\", size = 3) +\n  annotate(geom = \"text\", x = 1835, y = 0.4, label = \"Year 5\", hjust = \"left\", vjust = \"bottom\", size = 3) +\n  annotate(geom = \"text\", x = 1835, y = 0.3, label = \" \", hjust = \"left\", vjust = \"bottom\", size = 3) \n\n\n## Transform to plotly to add hover text\n\nggplotly(plot, tooltip = c(\"text3\")) %>% layout(hoverlabel = list(align = \"left\"))\n\n\n\nHeatMap-Lan Meier\n\n- The HeatMap-Lan Meier uses survival functions from a Kaplan Mier curve to show the transition in the proportion of events. \n- The benefit of the KM information in this format is that it \"separates\" the curves while supplying the same information. Overlaps which obsure data are now not an issue\n- The \"proportion\" with events is not as intuitive using a colour coded heat map. As such we have included a hover function. \n    - Placing the mouse over any element of the chart will show the survival function for all treatment arms.\n    - The treatment arm and associated survival function in _BOLD_ represent the most favourable condition at the selected timepoint.  \n\nHTML File\nOpens heat map as a webpage\n\nR file\n1. Save dataset (as 2020-04-08-psi-vissig-adtte_v2.csv) in same folder/working directory as code\n\n2. Install associated packages\n\n3. Run the R code\n\nBack to blog\n\nExample 5 (R)\n\n\nlibrary(tidyverse)    \nlibrary(broom)\nlibrary(survival)\nlibrary(here)\n\n# load data\nADTTE <- read_csv(here(\"data\", '2020-04-08-psi-vissig-adtte.csv'))\n\n\n# Set up meta data for the report\n#-------------------------------------------------\ntitle <- \"Evidence of improved progression-free survival for combo over monotherapy\"\nsubtitle <- \"Kaplan-Meier estimates over time including 95% uncertainty interval\"\nsource <- \"*The number of patients at risk (and events) are displayed the time point reference.\nData source: https://github.com/VIS-SIG/Wonderful-Wednesdays/tree/master/data/2020/2020-04-08\"\ny_axis <- \"Progression free survival\"\nx_axis <- \"Time [days]*\"\n\n\n############################################\n## Survival model for KM and risk set\n############################################\n\nfit <- survfit(Surv(AVAL, CNSR == 0) ~ TRT01P, data = ADTTE, conf.type = 'log-log' ) \nsumfit <- summary(fit, times = c(0, 250, 500, 750, 1000, 1250, 1500, 1750, 2000)) \n\n\n# tidy KM curve by treatment for plotting\n#-------------------------------------------\nkm <-\n  survfit(Surv(AVAL, CNSR == 0) ~ TRT01P,\n          data = ADTTE,\n          conf.type = 'log-log')  %>%\n  broom::tidy(fit) %>%\n  dplyr::mutate(group = stringr::str_remove(strata, \"TRT01P=\")) %>%\n  dplyr::mutate(group = factor(\n    group,\n    levels = c(\n      \"tablemab + vismab 52 weeks\",\n      \"tablemab x 12 week -> vismab 34 weeks\",\n      \"vismab x 52 weeks\",\n      \"tablemab x 52 weeks\"\n    )\n  ))\n\n# tidy KM curve by treatment for small multiples\n# this is a second data set to pass in for plotting\n# ghost lines of each treatment \n#-------------------------------------------\nkm_sm <- km %>%\n  mutate(group2 = group)\n\n\n# Calculate risk set for annotations\n#------------------------------------------\nrisk_data <-\n  tibble(\n    time =  sumfit$time,\n    group = sumfit$strata,\n    n.risk =   sumfit$n.risk,\n    n.events = sumfit$n.event\n  ) %>%\n  dplyr::mutate(\n    group = stringr::str_remove(group, \"TRT01P=\"),\n    label = paste0(n.risk, \" (\", n.events, \")\"),\n    y_pos = 0.01\n  )\n\n\n############################################\n## Create the plot\n############################################\n\nplot <-\n  km %>% ggplot(aes(x = time, y = estimate, group = group)) +\n  ## draw the ghost lines of each treatment by facet. Force the group facet to null\n  geom_step(\n    data = transform(td2, group = NULL),\n    aes(time, estimate, group = group2),\n    size = 0.75,\n    color = \"#000000\",\n    alpha = 0.15\n  ) +\n  \n  ## draw km lines\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.1, fill = \"red\") +\n  geom_step(color = \"red\") +\n  \n  ## draw risk set\n  geom_text(data = risk_data, mapping = aes(x = time, y = y_pos, label = label, group = group, fill = NULL), size = 2.5) +\n  \n  ## asthetics of the plot\n  scale_x_continuous(breaks = c(0, 250, 500, 750, 1000, 1250, 1500, 1750, 2000)) +\n  scale_y_continuous(breaks = c(0, 0.25, 0.50, 0.75, 1), limits = c(0, 1)) +\n\n  ## annotations\n  labs(title = title,\n       subtitle = subtitle,\n       caption = source) +\n  xlab(x_axis) +\n  ylab(y_axis) +\n  \n  # set up basic theme \n  theme_minimal(base_size = 12) +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.title.y = element_blank(),\n    legend.position = \"none\"\n  ) +\n  \n  # Set the entire chart region to a light gray color\n  theme(panel.background = element_rect(fill = color_background, color = color_background)) +\n  theme(plot.background = element_rect(fill = color_background, color = color_background)) +\n  theme(panel.border = element_rect(color = \"grey\", fill = NA, size = 0.35)) +\n  facet_wrap(~ group, scales = 'free', ncol = 2) \n\n# Save plot to file\n#-----------------------------------------\nggsave(\n  file = here(\"figs\", \"ww-km-plot.png\"),\n  width = 35, height = 20, units = \"cm\")\n\nBack to blog\n\n\n",
    "preview": "posts/2020-09-10-wonderful-wednesday-april-2020/plots/plot01.png",
    "last_modified": "2020-10-30T20:08:07+01:00",
    "input_file": {},
    "preview_width": 5790,
    "preview_height": 2700
  },
  {
    "path": "posts/2020-10-27-wonderful-wednesdays-march-2020/",
    "title": "Wonderful Wednesdays March 2020",
    "description": "The VIS SIG is happy to introduce a new initiative called “Wonderful Wednesdays”. This initiative will provide the participants to not only learn theoretically about visualisation principles but also apply them to relevant examples from the field of healthcare and the development of new therapies. This webinar kicks off the webinar series by giving an introduction into principles of visualization and an overview of the process. The first dataset is also introduced.",
    "author": [
      {
        "name": "Daniel Saure",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2020-03-11",
    "categories": [
      "Wonderful Wednesdays"
    ],
    "contents": "\nWelcome to the first blog entry of the Wonderful Wednesdays (WW) initiative! The aims of WW comprise to raise awareness about the opportunities in VIS and aims to increase the visualization expertise. Also, a gallery of relevant examples will be created.\nWhy is visualization important?\nWe presented a couple of (famous) examples which show the importance of visualization. For example, based on summary statistics only, you most likely cannot fully understand the data ( Anscombe’s quartet), but you need a graphical perspective as well. Also, we can see that there is a already some history of visualization: high-resolution image\nSee more in the webinar!\nLearn about principles of visualization\nEffective visualization is effective visual communication! The following three laws aim to improve visual communication: \nhigh-resolution image\nFirstly, have a clear purpose, i.e. ask yourself WHY you are doing the visualization, look WHAT is the quantitative evidence to support the purpose, identify WHO is the audience, and WHERE the visualization will be shown. The second law is to show the data clearly: Determine the best type of plot to support your aim and show the right scale of your data Lastly, make the message obvious (e.g. use informative labels or use color only if it adds value). A good overview of principles of effective communication can be found here\nHow you can participate in Wonderful Wednesdays\nThe WW (wonderful Wednesdays) is a learning community which aims to improve data visualizations. The participation is free for everybody and the process is as follows: \nhigh-resolution image\nThe data can be accessed and downloaded here. You can then submit your proposal (visualization + code) via this google form # Data example The first data set is based on a clinical trial for the treatment of Psoriasis in aduts. The primary outcomes is measured in terms of PASI improvement relative to baseline, i.e. we are interested in at least 75% (PASI75), at least 90% (PASI90), and 100% (PASI100) reduction compared to baseline. A more detailed description and link to the data can be found here.\n\n\n",
    "preview": "posts/2020-10-27-wonderful-wednesdays-march-2020/./images/ww1.gif",
    "last_modified": "2020-10-30T20:05:49+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-09-09-wonderful-wednesdays-overview/",
    "title": "Wonderful Wednesdays Overview",
    "description": "This provides a short overview of our Wonderful Wednesdays Webinars.",
    "author": [
      {
        "name": "VIS SIG",
        "url": "https://www.psiweb.org/sigs-special-interest-groups/visualisation"
      }
    ],
    "date": "2020-03-04",
    "categories": [
      "Wonderful Wednesdays",
      "Overview"
    ],
    "contents": "\nLearn and Apply Key Principles of Data Visualisations\nThe data visualization special interest group (VIS SIG) was recently founded under the umbrella of EFSPI and PSI. Learn more about the VIS SIG.\nThe SIG is happy to introduce a new initiative called “Wonderful Wednesdays”. This initiative will provide the participants to not only learn theoretically about visualisation principles but also apply them to relevant examples from the field of healthcare and the development of new therapies.\nInspired by ‘Makeover Monday’ and ‘Tidy Tuesday’, we will present on a monthly basis a data set reflecting the properties of a usual data set from a clinical trial or some other relevant study. This data set will come along with a description of the objectives for the data visualisation and relevant background information.\nNow the audience can share how they would visually communicate the objectives of the data set and submit the visualisation (along with the code) to receive feedback from the SIG members. Both, the presentation of the dataset and the visualisation as well as the feedback will be given in webinars. These 60 minutes webinars will occur every 2nd Wednesday of the month at 5pm CET.\nIn the first webinar you will learn about visualization principles by visualization experts being active in the SIG. In addition, we will discuss the first visualization to improve on.\nPlease find below the timelines for the next cycle: * Webinar to present the case study: July 8th * Timeline to submit improved visualizations: August 5th * Webinar to provide feedback on the submitted visualizations: August 12th\nYou will be able to submit your improvements for feedback via a Google Form on the homepage of the SIG after the webinar. These submissions need to include code (which is well documented and executable) as well as the file of the visualization itself.\nData Submission\nThe data can be accessed and downloaded via this link: https://github.com/VIS-SIG/Wonderful-Wednesdays. Please submit your material via this Google Form.\nWe will make the submissions available to the community together with highlights of the strength and limitations. Over time, this will lead to a gallery of visualizations for others to learn from.\n\n\n",
    "preview": {},
    "last_modified": "2020-10-27T20:58:31+01:00",
    "input_file": {}
  }
]
